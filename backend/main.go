package main

import (
	"bytes"
	"encoding/json"
	"flag"
	"fmt"
	"image"
	"image/jpeg"
	_ "image/png"
	"io"
	"log"
	"math"
	"math/rand"
	"net/http"
	"os"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/golang-jwt/jwt/v5"
	"golang.org/x/crypto/bcrypt"
)

var (
	jwtSecret              = []byte("jotmo-secret-key-medieval-2024")
	dataFile               = "jotmo_data.json"
	dataMutex              sync.RWMutex
	dashscopeAPIKey        = os.Getenv("DASHSCOPE_API_KEY")
	skipNameGen            = false // è·³è¿‡åˆ†ç±»åç§°ç”Ÿæˆï¼ˆç”¨äºç¦»çº¿é‡èšç±»ï¼‰
	activeCorridorProcess  = make(map[int]bool) // è·Ÿè¸ªæ´»è·ƒçš„æ—¶å…‰å›å»Šå¤„ç†ä»»åŠ¡
	pausedCorridorProcess  = make(map[int]bool) // è·Ÿè¸ªæš‚åœçš„æ—¶å…‰å›å»Šå¤„ç†ä»»åŠ¡
	corridorProcessMutex   sync.RWMutex
)

func getEnv(key, defaultVal string) string {
	if val := os.Getenv(key); val != "" {
		return val
	}
	return defaultVal
}

// ============ æ•°æ®ç»“æ„ ============

type User struct {
	ID       int    `json:"id"`
	Username string `json:"username"`
	Password string `json:"password"`
}

type Note struct {
	ID          int       `json:"id"`
	UserID      int       `json:"user_id"`
	Content     string    `json:"content"`
	CreatedAt   string    `json:"created_at"`
	Embedding   []float32 `json:"embedding,omitempty"`
	CategoryID  int       `json:"category_id"`
	ThemeID     int       `json:"theme_id"`      // ç”¨æˆ·è‡ªå®šä¹‰ä¸»é¢˜
	CatResponse string    `json:"cat_response"`  // çŒ«å’ªå›å¤
}

// Theme ç”¨æˆ·è‡ªå®šä¹‰çš„ä¸»é¢˜ï¼ˆæ‰‹åŠ¨æ•´ç†ï¼‰
type Theme struct {
	ID        int    `json:"id"`
	UserID    int    `json:"user_id"`
	Name      string `json:"name"`
	Color     string `json:"color"`     // ä¸»é¢˜é¢œè‰²
	CreatedAt string `json:"created_at"`
}

type Category struct {
	ID        int       `json:"id"`
	UserID    int       `json:"user_id"`
	Name      string    `json:"name"`
	ParentID  int       `json:"parent_id"` // 0 è¡¨ç¤ºä¸€çº§åˆ†ç±»
	Centroid  []float32 `json:"centroid"`
	NoteCount int       `json:"note_count"`
	CreatedAt string    `json:"created_at"`
}

type Data struct {
	Users          []User     `json:"users"`
	Notes          []Note     `json:"notes"`
	Categories     []Category `json:"categories"`
	Themes         []Theme    `json:"themes"`
	NextUserID     int        `json:"next_user_id"`
	NextNoteID     int        `json:"next_note_id"`
	NextCategoryID int        `json:"next_category_id"`
	NextThemeID    int        `json:"next_theme_id"`
	// æŒä¹…åŒ–ç¼“å­˜
	UserInsights   map[int]*InsightReport   `json:"user_insights,omitempty"`
	UserStarlight  map[int]*StarlightCache  `json:"user_starlight,omitempty"`
	UserBiography  map[int]*BiographyReport `json:"user_biography,omitempty"`
	// æ—¶å…‰å›å»Š - å¿«è®°å›¾ç‰‡
	NoteImages     map[int]*NoteImage       `json:"note_images,omitempty"`
	// æ—¶å…‰å›å»Šæ‰¹é‡å¤„ç†çŠ¶æ€
	CorridorStatus map[int]*CorridorProcessStatus `json:"corridor_status,omitempty"`
}

// NoteImage å¿«è®°ç”Ÿæˆçš„åœºæ™¯å›¾ç‰‡
type NoteImage struct {
	NoteID        int    `json:"note_id"`
	ImageURL      string `json:"image_url"`       // å›¾ç‰‡ URLï¼ˆDashScope ä¸´æ—¶é“¾æ¥æˆ–æœ¬åœ°å­˜å‚¨è·¯å¾„ï¼‰
	LocalPath     string `json:"local_path"`      // æœ¬åœ°å­˜å‚¨è·¯å¾„
	ThumbnailPath string `json:"thumbnail_path"`  // ç¼©ç•¥å›¾è·¯å¾„
	Prompt        string `json:"prompt"`          // ç”Ÿæˆä½¿ç”¨çš„ prompt
	Status        string `json:"status"`          // pending, generating, completed, failed, not_suitable
	TaskID        string `json:"task_id"`         // DashScope ä»»åŠ¡ ID
	GeneratedAt   string `json:"generated_at"`    // ç”Ÿæˆæ—¶é—´
	Error         string `json:"error"`           // é”™è¯¯ä¿¡æ¯
}

// CorridorProcessStatus æ—¶å…‰å›å»Šæ‰¹é‡å¤„ç†çŠ¶æ€
type CorridorProcessStatus struct {
	Status           string `json:"status"`            // idle, processing, paused, completed, interrupted, error
	TotalNotes       int    `json:"total_notes"`       // æ€»å¿«è®°æ•°
	ProcessedNotes   int    `json:"processed_notes"`   // å·²å¤„ç†æ•°
	SuccessCount     int    `json:"success_count"`     // æˆåŠŸç”Ÿæˆæ•°
	FailedCount      int    `json:"failed_count"`      // å¤±è´¥æ•°
	NotSuitableCount int    `json:"not_suitable_count"` // ä¸é€‚åˆç”Ÿæˆå›¾ç‰‡çš„æ•°é‡
	LastProcessedAt  string `json:"last_processed_at"` // æœ€åå¤„ç†æ—¶é—´
	StartedAt        string `json:"started_at"`        // å¼€å§‹æ—¶é—´
	Error            string `json:"error"`             // é”™è¯¯ä¿¡æ¯
}

// StarlightCache Starlight æŠ¥å‘Šç¼“å­˜
type StarlightCache struct {
	Report      string `json:"report"`
	GeneratedAt string `json:"generated_at"`
	NoteCount   int    `json:"note_count"`
}

// BiographyGenerationStatus ä¼ è®°ç”ŸæˆçŠ¶æ€ï¼ˆå†…å­˜ä¸­ï¼Œä¸æŒä¹…åŒ–ï¼‰
type BiographyGenerationStatus struct {
	Status      string `json:"status"`       // idle, generating, completed, error
	Phase       string `json:"phase"`        // å½“å‰é˜¶æ®µæè¿°
	Progress    int    `json:"progress"`     // è¿›åº¦ç™¾åˆ†æ¯” 0-100
	CurrentStep int    `json:"current_step"` // å½“å‰æ­¥éª¤
	TotalSteps  int    `json:"total_steps"`  // æ€»æ­¥éª¤æ•°
	StartedAt   string `json:"started_at"`   // å¼€å§‹æ—¶é—´
	Error       string `json:"error"`        // é”™è¯¯ä¿¡æ¯
}

// å…¨å±€ç”ŸæˆçŠ¶æ€ mapï¼ˆå†…å­˜ä¸­ï¼‰
var biographyGenStatus = make(map[int]*BiographyGenerationStatus)
var biographyGenMutex sync.RWMutex

type LoginRequest struct {
	Username string `json:"username"`
	Password string `json:"password"`
}

type NoteRequest struct {
	Content string `json:"content"`
}

type ImportNoteRequest struct {
	Content   string `json:"content"`
	CreatedAt string `json:"created_at"`
}

type ImportRequest struct {
	Notes []ImportNoteRequest `json:"notes"`
}

// ============ æ´è§æ¨¡å—æ•°æ®ç»“æ„ ============

type InsightReport struct {
	MBTI         MBTIAnalysis    `json:"mbti"`
	Emotions     EmotionAnalysis `json:"emotions"`
	Keywords     []Keyword       `json:"keywords"`
	Future       FutureForecast  `json:"future"`
	PersonalNote string          `json:"personal_note"`
	GeneratedAt  string          `json:"generated_at"`
	NoteCount    int             `json:"note_count"`
}

type MBTIAnalysis struct {
	Type        string      `json:"type"`        // e.g., "INFP"
	TypeName    string      `json:"type_name"`   // e.g., "è°ƒåœè€…"
	TypeEmoji   string      `json:"type_emoji"`  // e.g., "ğŸŒ¸"
	Dimensions  []Dimension `json:"dimensions"`  // E/I, S/N, T/F, J/P scores
	Description string      `json:"description"` // æ¸©æš–çš„æè¿°
	Traits      []string    `json:"traits"`      // æ ¸å¿ƒç‰¹è´¨æ ‡ç­¾
	Evidences   []string    `json:"evidences"`   // æ¥è‡ªå¿«è®°çš„è¯æ®
}

type Dimension struct {
	Name   string `json:"name"`   // e.g., "E-I"
	Left   string `json:"left"`   // e.g., "å¤–å‘"
	Right  string `json:"right"`  // e.g., "å†…å‘"
	Score  int    `json:"score"`  // 0-100, 50ä¸ºä¸­é—´
	Lean   string `json:"lean"`   // "left" or "right"
}

type EmotionAnalysis struct {
	Dominant     string         `json:"dominant"`     // ä¸»å¯¼æƒ…ç»ª
	DomEmoji     string         `json:"dom_emoji"`    // ä¸»å¯¼æƒ…ç»ªemoji
	Distribution []EmotionItem  `json:"distribution"` // æƒ…ç»ªåˆ†å¸ƒ
	Trend        string         `json:"trend"`        // æƒ…ç»ªèµ°åŠ¿æè¿°
	Insight      string         `json:"insight"`      // æƒ…ç»ªæ´å¯Ÿ
}

type EmotionItem struct {
	Name    string `json:"name"`
	Emoji   string `json:"emoji"`
	Count   int    `json:"count"`
	Percent int    `json:"percent"`
	Color   string `json:"color"` // ç”¨äºç¯å½¢å›¾
}

type Keyword struct {
	Word    string `json:"word"`
	Count   int    `json:"count"`
	Size    int    `json:"size"`    // 1-5, ç”¨äºè¯äº‘å¤§å°
	Emotion string `json:"emotion"` // positive/neutral/reflective/concern
}

// æœªæ¥é¢„è§ç›¸å…³ç»“æ„
type FutureForecast struct {
	EmergingInterests []InterestItem  `json:"emerging_interests"` // å…´è¶£èŒèŠ½
	GrowthTrajectory  TrajectoryItem  `json:"growth_trajectory"`  // å‘å±•è¶‹åŠ¿
	HiddenPotential   []PotentialItem `json:"hidden_potential"`   // æ½œåŠ›å‘ç°
	Summary           string          `json:"summary"`            // æ•´ä½“å±•æœ›
}

type InterestItem struct {
	Topic      string `json:"topic"`      // å…´è¶£ä¸»é¢˜
	Emoji      string `json:"emoji"`      // ä»£è¡¨emoji
	Signal     string `json:"signal"`     // ä»å“ªäº›è®°å½•ä¸­å‘ç°çš„ä¿¡å·
	Suggestion string `json:"suggestion"` // æ¢ç´¢å»ºè®®
}

type TrajectoryItem struct {
	FromState string `json:"from_state"` // è¿‡å»çš„çŠ¶æ€
	ToState   string `json:"to_state"`   // æ­£åœ¨è½¬å‘çš„çŠ¶æ€
	Evidence  string `json:"evidence"`   // æ”¯æŒè¿™ä¸ªåˆ¤æ–­çš„è¯æ®
	Meaning   string `json:"meaning"`    // è¿™æ„å‘³ç€ä»€ä¹ˆ
}

type PotentialItem struct {
	Ability     string `json:"ability"`     // æ½œåœ¨èƒ½åŠ›
	Emoji       string `json:"emoji"`       // ä»£è¡¨emoji
	Evidence    string `json:"evidence"`    // ä»å“ªäº›è®°å½•ä¸­çœ‹å‡º
	Affirmation string `json:"affirmation"` // è‚¯å®šçš„è¯è¯­
}

// ============ æˆ‘çš„ä¼ å¥‡ - ä¸ªäººä¼ è®°æ¨¡å— ============

// BiographyReport ä¸ªäººä¼ è®°æŠ¥å‘Š
type BiographyReport struct {
	// å°é¢
	Title      string `json:"title"`       // ä¼ è®°æ ‡é¢˜
	Subtitle   string `json:"subtitle"`    // å‰¯æ ‡é¢˜
	CoverEmoji string `json:"cover_emoji"` // å°é¢emoji

	// äººç‰©ç”»åƒ
	Portrait Portrait `json:"portrait"`

	// äººç”Ÿç¯‡ç« 
	Chapters []Chapter `json:"chapters"`

	// äººç”Ÿä¸»é¢˜
	LifeThemes []LifeTheme `json:"life_themes"`

	// é‡‘å¥é›†
	Quotes []Quote `json:"quotes"`

	// äººç”Ÿè½¨è¿¹
	Timeline []TimelineEvent `json:"timeline"`

	// å°¾å£°
	Epilogue string `json:"epilogue"`

	// å…ƒæ•°æ®ï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
	GeneratedAt   string `json:"generated_at"`
	LastUpdatedAt string `json:"last_updated_at"`
	LastNoteID    int    `json:"last_note_id"` // æœ€åå¤„ç†çš„å¿«è®°ID
	NoteCount     int    `json:"note_count"`
	Version       int    `json:"version"`
}

// Portrait äººç‰©ç”»åƒ
type Portrait struct {
	Tagline      string   `json:"tagline"`       // ä¸€å¥è¯å®šä¹‰
	Essence      string   `json:"essence"`       // æ ¸å¿ƒç‰¹è´¨æè¿°
	Strengths    []string `json:"strengths"`     // é—ªå…‰ç‚¹
	Quirks       []string `json:"quirks"`        // ç‹¬ç‰¹ä¹‹å¤„
	DrivingForce string   `json:"driving_force"` // å†…å¿ƒé©±åŠ¨åŠ›
	Spirit       string   `json:"spirit"`        // ç²¾ç¥å›¾è…¾
}

// Chapter äººç”Ÿç¯‡ç« 
type Chapter struct {
	ID         int      `json:"id"`
	Title      string   `json:"title"`
	Subtitle   string   `json:"subtitle"`
	Emoji      string   `json:"emoji"`
	Period     string   `json:"period"`
	Opening    string   `json:"opening"`
	Narrative  string   `json:"narrative"`
	KeyMoments []string `json:"key_moments"`
	Emotions   []string `json:"emotions"`
	Growth     string   `json:"growth"`
	Closing    string   `json:"closing"`
}

// LifeTheme äººç”Ÿä¸»é¢˜
type LifeTheme struct {
	Theme          string   `json:"theme"`
	Emoji          string   `json:"emoji"`
	Description    string   `json:"description"`
	Manifestations []string `json:"manifestations"`
	Evolution      string   `json:"evolution"`
}

// Quote é‡‘å¥
type Quote struct {
	Text    string `json:"text"`
	Source  string `json:"source"`
	Emoji   string `json:"emoji"`
	Meaning string `json:"meaning"`
}

// TimelineEvent æ—¶é—´çº¿äº‹ä»¶
type TimelineEvent struct {
	Date         string `json:"date"`
	Title        string `json:"title"`
	Description  string `json:"description"`
	Emoji        string `json:"emoji"`
	Significance string `json:"significance"`
}

// BiographyUpdate å¢é‡æ›´æ–°ç»“æ„
type BiographyUpdate struct {
	UpdateType        string          `json:"update_type"` // none, minor, major
	PortraitUpdate    *PortraitUpdate `json:"portrait_update,omitempty"`
	ChapterUpdates    []ChapterUpdate `json:"chapter_updates,omitempty"`
	NewChapter        *Chapter        `json:"new_chapter,omitempty"`
	NewThemes         []LifeTheme     `json:"new_themes,omitempty"`
	ThemeUpdates      []ThemeUpdate   `json:"theme_updates,omitempty"`
	NewQuotes         []Quote         `json:"new_quotes,omitempty"`
	NewTimelineEvents []TimelineEvent `json:"new_timeline_events,omitempty"`
	EpilogueUpdate    string          `json:"epilogue_update,omitempty"`
	UpdateSummary     string          `json:"update_summary"`
}

type PortraitUpdate struct {
	EssenceAddition string   `json:"essence_addition,omitempty"`
	NewStrengths    []string `json:"new_strengths,omitempty"`
	NewQuirks       []string `json:"new_quirks,omitempty"`
}

type ChapterUpdate struct {
	ChapterID         int      `json:"chapter_id"`
	NarrativeAddition string   `json:"narrative_addition,omitempty"`
	NewKeyMoments     []string `json:"new_key_moments,omitempty"`
	GrowthUpdate      string   `json:"growth_update,omitempty"`
}

type ThemeUpdate struct {
	Theme              string   `json:"theme"`
	EvolutionUpdate    string   `json:"evolution_update,omitempty"`
	NewManifestations  []string `json:"new_manifestations,omitempty"`
}

// DashScope API è¯·æ±‚/å“åº”
type DashScopeMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type DashScopeInput struct {
	Messages []DashScopeMessage `json:"messages"`
}

type DashScopeParameters struct {
	MaxTokens   int     `json:"max_tokens,omitempty"`
	Temperature float64 `json:"temperature,omitempty"`
}

type DashScopeRequest struct {
	Model      string              `json:"model"`
	Input      DashScopeInput      `json:"input"`
	Parameters DashScopeParameters `json:"parameters,omitempty"`
}

type DashScopeChoice struct {
	Message DashScopeMessage `json:"message"`
}

type DashScopeOutput struct {
	Choices []DashScopeChoice `json:"choices"`
	Text    string            `json:"text,omitempty"`
}

type DashScopeResponse struct {
	Output DashScopeOutput `json:"output"`
}

var data Data

// ============ æ•°æ®åŠ è½½/ä¿å­˜ ============

func loadData() {
	dataMutex.Lock()
	defer dataMutex.Unlock()

	file, err := os.ReadFile(dataFile)
	if err != nil {
		data = Data{
			Users:          []User{},
			Notes:          []Note{},
			Categories:     []Category{},
			NextUserID:     1,
			NextNoteID:     1,
			NextCategoryID: 1,
		}
		return
	}

	json.Unmarshal(file, &data)

	// ç¡®ä¿ Categories ä¸ä¸º nil
	if data.Categories == nil {
		data.Categories = []Category{}
	}
	if data.NextCategoryID == 0 {
		data.NextCategoryID = 1
	}
}

func saveData() {
	file, _ := json.MarshalIndent(data, "", "  ")
	os.WriteFile(dataFile, file, 0644)
}

// ============ CORS & Auth ============

func enableCORS(next http.HandlerFunc) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
		w.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization")

		if r.Method == "OPTIONS" {
			w.WriteHeader(http.StatusOK)
			return
		}

		next(w, r)
	}
}

func generateToken(userID int, username string) (string, error) {
	token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{
		"user_id":  userID,
		"username": username,
		"exp":      time.Now().Add(time.Hour * 72).Unix(),
	})
	return token.SignedString(jwtSecret)
}

func validateToken(tokenString string) (int, string, error) {
	token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
		return jwtSecret, nil
	})
	if err != nil {
		return 0, "", err
	}

	if claims, ok := token.Claims.(jwt.MapClaims); ok && token.Valid {
		userID := int(claims["user_id"].(float64))
		username := claims["username"].(string)
		return userID, username, nil
	}
	return 0, "", jwt.ErrSignatureInvalid
}

// ============ åµŒå…¥å’Œå‘é‡æ“ä½œ ============

// DashScope åµŒå…¥ API è¯·æ±‚/å“åº”
type DashScopeEmbedInput struct {
	Texts []string `json:"texts"`
}

type DashScopeEmbedRequest struct {
	Model      string              `json:"model"`
	Input      DashScopeEmbedInput `json:"input"`
	Parameters map[string]string   `json:"parameters,omitempty"`
}

type DashScopeEmbedData struct {
	TextIndex int       `json:"text_index"`
	Embedding []float32 `json:"embedding"`
}

type DashScopeEmbedOutput struct {
	Embeddings []DashScopeEmbedData `json:"embeddings"`
}

type DashScopeEmbedResponse struct {
	Output DashScopeEmbedOutput `json:"output"`
}

func getEmbedding(text string) ([]float32, error) {
	embeddings, err := getBatchEmbeddings([]string{text})
	if err != nil {
		return nil, err
	}
	if len(embeddings) == 0 {
		return nil, fmt.Errorf("no embeddings returned")
	}
	return embeddings[0], nil
}

func getBatchEmbeddings(texts []string) ([][]float32, error) {
	if len(texts) == 0 {
		return nil, nil
	}

	if dashscopeAPIKey == "" {
		return nil, fmt.Errorf("DASHSCOPE_API_KEY not set")
	}

	// DashScope åµŒå…¥ API æ¯æ¬¡æœ€å¤š 10 æ¡
	var allEmbeddings [][]float32
	batchSize := 10

	for i := 0; i < len(texts); i += batchSize {
		end := i + batchSize
		if end > len(texts) {
			end = len(texts)
		}
		batch := texts[i:end]

		reqBody := DashScopeEmbedRequest{
			Model: "text-embedding-v3",
			Input: DashScopeEmbedInput{
				Texts: batch,
			},
			Parameters: map[string]string{
				"dimension": "512",
			},
		}

		jsonData, err := json.Marshal(reqBody)
		if err != nil {
			return nil, err
		}

		req, err := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/embeddings/text-embedding/text-embedding", bytes.NewBuffer(jsonData))
		if err != nil {
			return nil, err
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)

		client := &http.Client{Timeout: 60 * time.Second}
		resp, err := client.Do(req)
		if err != nil {
			return nil, fmt.Errorf("DashScope embedding API error: %v", err)
		}
		defer resp.Body.Close()

		if resp.StatusCode != http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			return nil, fmt.Errorf("DashScope embedding API returned %d: %s", resp.StatusCode, string(body))
		}

		var dsResp DashScopeEmbedResponse
		if err := json.NewDecoder(resp.Body).Decode(&dsResp); err != nil {
			return nil, err
		}

		// æŒ‰ text_index æ’åº
		batchEmbeddings := make([][]float32, len(batch))
		for _, emb := range dsResp.Output.Embeddings {
			if emb.TextIndex < len(batchEmbeddings) {
				batchEmbeddings[emb.TextIndex] = emb.Embedding
			}
		}

		allEmbeddings = append(allEmbeddings, batchEmbeddings...)
	}

	return allEmbeddings, nil
}

func cosineSimilarity(a, b []float32) float32 {
	if len(a) != len(b) || len(a) == 0 {
		return 0
	}

	var dotProduct, normA, normB float32
	for i := range a {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}

	if normA == 0 || normB == 0 {
		return 0
	}

	return dotProduct / (float32(math.Sqrt(float64(normA))) * float32(math.Sqrt(float64(normB))))
}

func computeCentroid(embeddings [][]float32) []float32 {
	if len(embeddings) == 0 {
		return nil
	}

	dim := len(embeddings[0])
	centroid := make([]float32, dim)

	for _, emb := range embeddings {
		for i, v := range emb {
			centroid[i] += v
		}
	}

	n := float32(len(embeddings))
	for i := range centroid {
		centroid[i] /= n
	}

	// å½’ä¸€åŒ–
	var norm float32
	for _, v := range centroid {
		norm += v * v
	}
	norm = float32(math.Sqrt(float64(norm)))
	if norm > 0 {
		for i := range centroid {
			centroid[i] /= norm
		}
	}

	return centroid
}

// ============ DashScope API è°ƒç”¨ ============

func generateCategoryName(notes []Note) (string, error) {
	if dashscopeAPIKey == "" {
		// å¦‚æœæ²¡æœ‰ API keyï¼Œä½¿ç”¨ç®€å•çš„å‘½å
		return fmt.Sprintf("åˆ†ç±»%d", time.Now().Unix()%1000), nil
	}

	// æ„å»ºæç¤º
	var contents []string
	for _, note := range notes {
		content := note.Content
		if len([]rune(content)) > 100 {
			content = string([]rune(content)[:100]) + "..."
		}
		contents = append(contents, content)
	}

	prompt := fmt.Sprintf(`åŸºäºä»¥ä¸‹å‡ æ¡å¿«è®°å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„åˆ†ç±»åç§°ï¼ˆ2-4ä¸ªä¸­æ–‡å­—ï¼‰ã€‚
åˆ†ç±»åç§°åº”è¯¥æ¦‚æ‹¬è¿™äº›å†…å®¹çš„å…±åŒä¸»é¢˜ã€‚åªè¾“å‡ºåˆ†ç±»åç§°ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚

å¿«è®°å†…å®¹ï¼š
%s

åˆ†ç±»åç§°ï¼š`, strings.Join(contents, "\n---\n"))

	reqBody := DashScopeRequest{
		Model: "qwen-turbo",
		Input: DashScopeInput{
			Messages: []DashScopeMessage{
				{Role: "user", Content: prompt},
			},
		},
		Parameters: DashScopeParameters{
			MaxTokens:   50,
			Temperature: 0.7,
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return "", err
	}

	req, err := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonData))
	if err != nil {
		return "", err
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return "", fmt.Errorf("DashScope API returned %d: %s", resp.StatusCode, string(body))
	}

	var dsResp DashScopeResponse
	if err := json.NewDecoder(resp.Body).Decode(&dsResp); err != nil {
		return "", err
	}

	// å°è¯•ä» choices è·å–
	if len(dsResp.Output.Choices) > 0 {
		name := strings.TrimSpace(dsResp.Output.Choices[0].Message.Content)
		runes := []rune(name)
		if len(runes) > 10 {
			name = string(runes[:10])
		}
		return name, nil
	}

	// å°è¯•ä» text è·å–ï¼ˆæ—§ç‰ˆ API æ ¼å¼ï¼‰
	if dsResp.Output.Text != "" {
		name := strings.TrimSpace(dsResp.Output.Text)
		runes := []rune(name)
		if len(runes) > 10 {
			name = string(runes[:10])
		}
		return name, nil
	}

	return "", fmt.Errorf("empty response from DashScope")
}

// ============ åˆ†ç±»é€»è¾‘ ============

const (
	SimilarityThreshold    = 0.65 // å½’å…¥å·²æœ‰åˆ†ç±»çš„é˜ˆå€¼
	ClusterMinSize         = 3    // å½¢æˆæ–°åˆ†ç±»çš„æœ€å°ç¬”è®°æ•°
	MaxLevel1Categories    = 12   // è§¦å‘äºŒçº§åˆ†ç±»çš„é˜ˆå€¼
	Level2SimilarityThresh = 0.72 // äºŒçº§åˆ†ç±»èšåˆé˜ˆå€¼ï¼ˆæé«˜ä»¥é¿å…è¿‡åº¦èšåˆï¼‰
	MaxSubcategoriesPerL2  = 15   // æ¯ä¸ªäºŒçº§åˆ†ç±»æœ€å¤šåŒ…å«çš„å­åˆ†ç±»æ•°
)

func findBestCategory(embedding []float32, userID int) (*Category, float32) {
	var bestCat *Category
	var bestSim float32 = -1

	for i := range data.Categories {
		cat := &data.Categories[i]
		if cat.UserID != userID || cat.ParentID != 0 {
			continue // åªåŒ¹é…ä¸€çº§åˆ†ç±»
		}
		if len(cat.Centroid) == 0 {
			continue
		}

		sim := cosineSimilarity(embedding, cat.Centroid)
		if sim > bestSim {
			bestSim = sim
			bestCat = cat
		}
	}

	return bestCat, bestSim
}

func assignNoteToCategory(note *Note) {
	if len(note.Embedding) == 0 {
		return
	}

	bestCat, bestSim := findBestCategory(note.Embedding, note.UserID)

	if bestCat != nil && bestSim >= SimilarityThreshold {
		note.CategoryID = bestCat.ID
		// æ›´æ–°åˆ†ç±»ä¸­å¿ƒå’Œè®¡æ•°
		updateCategoryCentroid(bestCat.ID)
	} else {
		note.CategoryID = 0 // æœªåˆ†ç±»
	}
}

func updateCategoryCentroid(categoryID int) {
	var embeddings [][]float32

	for _, note := range data.Notes {
		if note.CategoryID == categoryID && len(note.Embedding) > 0 {
			embeddings = append(embeddings, note.Embedding)
		}
	}

	for i := range data.Categories {
		if data.Categories[i].ID == categoryID {
			data.Categories[i].Centroid = computeCentroid(embeddings)
			data.Categories[i].NoteCount = len(embeddings)
			break
		}
	}
}

func clusterUncategorizedNotes(userID int) {
	log.Printf("Starting clustering for user %d", userID)

	// æ”¶é›†æœªåˆ†ç±»ä¸”æœ‰åµŒå…¥çš„ç¬”è®°
	var uncategorized []*Note
	for i := range data.Notes {
		if data.Notes[i].UserID == userID &&
			data.Notes[i].CategoryID == 0 &&
			len(data.Notes[i].Embedding) > 0 {
			uncategorized = append(uncategorized, &data.Notes[i])
		}
	}

	log.Printf("Found %d uncategorized notes", len(uncategorized))

	if len(uncategorized) < ClusterMinSize {
		return
	}

	// ä½¿ç”¨é«˜æ•ˆçš„é‡‡æ ·èšç±»ç®—æ³•
	clusters := efficientClustering(uncategorized, SimilarityThreshold)
	log.Printf("Created %d clusters", len(clusters))

	createdCount := 0
	for _, cluster := range clusters {
		if len(cluster) < ClusterMinSize {
			continue
		}

		// æ”¶é›†åµŒå…¥è®¡ç®—ä¸­å¿ƒ
		var embeddings [][]float32
		var clusterNotes []Note
		for _, note := range cluster {
			embeddings = append(embeddings, note.Embedding)
			clusterNotes = append(clusterNotes, *note)
		}

		centroid := computeCentroid(embeddings)

		// ç”Ÿæˆåˆ†ç±»åç§°
		var name string
		if skipNameGen {
			name = fmt.Sprintf("åˆ†ç±»%d", data.NextCategoryID)
		} else {
			var err error
			name, err = generateCategoryName(clusterNotes)
			if err != nil {
				log.Printf("Failed to generate category name: %v", err)
				name = fmt.Sprintf("åˆ†ç±»%d", data.NextCategoryID)
			}
		}

		// åˆ›å»ºæ–°åˆ†ç±»
		newCat := Category{
			ID:        data.NextCategoryID,
			UserID:    userID,
			Name:      name,
			ParentID:  0,
			Centroid:  centroid,
			NoteCount: len(cluster),
			CreatedAt: time.Now().Format("2006-01-02 15:04:05"),
		}
		data.Categories = append(data.Categories, newCat)
		data.NextCategoryID++
		createdCount++

		// åˆ†é…ç¬”è®°åˆ°æ–°åˆ†ç±»
		for _, note := range cluster {
			note.CategoryID = newCat.ID
		}

		log.Printf("Created category '%s' with %d notes", name, len(cluster))
	}

	log.Printf("Clustering complete: created %d categories", createdCount)

	// æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºäºŒçº§åˆ†ç±»
	checkAndCreateLevel2Categories(userID)
}

// efficientClustering ä½¿ç”¨é‡‡æ ·+åˆ†é…çš„é«˜æ•ˆèšç±»ç®—æ³•
func efficientClustering(notes []*Note, threshold float32) [][]*Note {
	if len(notes) == 0 {
		return nil
	}

	// éšæœºæ‰“ä¹±ç¬”è®°é¡ºåº
	rand.Shuffle(len(notes), func(i, j int) {
		notes[i], notes[j] = notes[j], notes[i]
	})

	// æœ€å¤§é‡‡æ ·æ•°é‡ç”¨äºåˆå§‹èšç±»
	maxSampleSize := 500
	if len(notes) < maxSampleSize {
		maxSampleSize = len(notes)
	}

	// ç¬¬ä¸€é˜¶æ®µï¼šå¯¹é‡‡æ ·æ•°æ®è¿›è¡Œå°è§„æ¨¡å±‚æ¬¡èšç±»
	sampleNotes := notes[:maxSampleSize]
	initialClusters := smallHierarchicalClustering(sampleNotes, threshold)
	log.Printf("Initial clustering on %d samples created %d clusters", maxSampleSize, len(initialClusters))

	// å¦‚æœé‡‡æ ·æ•°é‡å°±æ˜¯å…¨éƒ¨æ•°æ®ï¼Œç›´æ¥è¿”å›
	if len(notes) <= maxSampleSize {
		return initialClusters
	}

	// è®¡ç®—æ¯ä¸ªåˆå§‹ç°‡çš„ä¸­å¿ƒ
	type clusterInfo struct {
		notes    []*Note
		centroid []float32
	}

	clusters := make([]clusterInfo, 0, len(initialClusters))
	for _, cluster := range initialClusters {
		if len(cluster) >= ClusterMinSize {
			var embeddings [][]float32
			for _, n := range cluster {
				embeddings = append(embeddings, n.Embedding)
			}
			clusters = append(clusters, clusterInfo{
				notes:    cluster,
				centroid: computeCentroid(embeddings),
			})
		}
	}

	// ç¬¬äºŒé˜¶æ®µï¼šå°†å‰©ä½™ç¬”è®°åˆ†é…åˆ°æœ€ç›¸ä¼¼çš„ç°‡
	remainingNotes := notes[maxSampleSize:]
	log.Printf("Assigning %d remaining notes to clusters", len(remainingNotes))

	unassigned := make([]*Note, 0)

	for _, note := range remainingNotes {
		if len(note.Embedding) == 0 {
			continue
		}

		bestIdx := -1
		var bestSim float32 = -1

		for i, c := range clusters {
			sim := cosineSimilarity(note.Embedding, c.centroid)
			if sim > bestSim {
				bestSim = sim
				bestIdx = i
			}
		}

		if bestIdx >= 0 && bestSim >= threshold {
			clusters[bestIdx].notes = append(clusters[bestIdx].notes, note)
		} else {
			unassigned = append(unassigned, note)
		}
	}

	log.Printf("Assigned notes, %d remain unassigned", len(unassigned))

	// å¯¹æœªåˆ†é…çš„ç¬”è®°å°è¯•å½¢æˆæ–°ç°‡
	if len(unassigned) >= ClusterMinSize {
		// ä½¿ç”¨è´ªå©ªæ–¹æ³•å½¢æˆæ–°ç°‡
		newClusters := greedyClustering(unassigned, threshold)
		for _, nc := range newClusters {
			if len(nc) >= ClusterMinSize {
				var embeddings [][]float32
				for _, n := range nc {
					embeddings = append(embeddings, n.Embedding)
				}
				clusters = append(clusters, clusterInfo{
					notes:    nc,
					centroid: computeCentroid(embeddings),
				})
			}
		}
	}

	// è½¬æ¢å›ç»“æœæ ¼å¼
	result := make([][]*Note, 0, len(clusters))
	for _, c := range clusters {
		result = append(result, c.notes)
	}

	return result
}

// smallHierarchicalClustering å¯¹å°è§„æ¨¡æ•°æ®è¿›è¡Œå±‚æ¬¡èšç±»
func smallHierarchicalClustering(notes []*Note, threshold float32) [][]*Note {
	if len(notes) == 0 {
		return nil
	}

	// åˆå§‹åŒ–ï¼šæ¯ä¸ªç¬”è®°æ˜¯ä¸€ä¸ªç°‡
	clusters := make([][]*Note, len(notes))
	for i, note := range notes {
		clusters[i] = []*Note{note}
	}

	// é¢„è®¡ç®—æ‰€æœ‰ç¬”è®°ä¹‹é—´çš„ç›¸ä¼¼åº¦çŸ©é˜µ
	n := len(notes)
	simMatrix := make([][]float32, n)
	// å…ˆåˆ†é…æ‰€æœ‰è¡Œ
	for i := 0; i < n; i++ {
		simMatrix[i] = make([]float32, n)
	}
	// å†è®¡ç®—ç›¸ä¼¼åº¦
	for i := 0; i < n; i++ {
		for j := i + 1; j < n; j++ {
			if len(notes[i].Embedding) > 0 && len(notes[j].Embedding) > 0 {
				sim := cosineSimilarity(notes[i].Embedding, notes[j].Embedding)
				simMatrix[i][j] = sim
				simMatrix[j][i] = sim
			}
		}
	}

	// è®°å½•æ¯ä¸ªç¬”è®°å±äºå“ªä¸ªç°‡
	noteToCluster := make([]int, n)
	for i := range noteToCluster {
		noteToCluster[i] = i
	}

	// é¢„è®¡ç®—ç¬”è®°åˆ°ç´¢å¼•çš„æ˜ å°„ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
	noteToIdx := make(map[*Note]int)
	for i, note := range notes {
		noteToIdx[note] = i
	}

	for {
		if len(clusters) <= 1 {
			break
		}

		// æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ä¸¤ä¸ªç°‡
		bestI, bestJ := -1, -1
		var bestSim float32 = -1

		for i := 0; i < len(clusters); i++ {
			if clusters[i] == nil {
				continue
			}
			for j := i + 1; j < len(clusters); j++ {
				if clusters[j] == nil {
					continue
				}
				sim := clusterSimilarityFast(clusters[i], clusters[j], simMatrix, noteToIdx)
				if sim > bestSim {
					bestSim = sim
					bestI, bestJ = i, j
				}
			}
		}

		if bestSim < threshold || bestI < 0 {
			break
		}

		// åˆå¹¶ä¸¤ä¸ªç°‡
		clusters[bestI] = append(clusters[bestI], clusters[bestJ]...)
		clusters[bestJ] = nil
	}

	// è¿‡æ»¤æ‰ç©ºç°‡
	result := make([][]*Note, 0)
	for _, c := range clusters {
		if c != nil && len(c) > 0 {
			result = append(result, c)
		}
	}

	return result
}

// clusterSimilarityFast ä½¿ç”¨é¢„è®¡ç®—çš„ç›¸ä¼¼åº¦çŸ©é˜µå’Œç´¢å¼•æ˜ å°„
func clusterSimilarityFast(c1, c2 []*Note, simMatrix [][]float32, noteToIdx map[*Note]int) float32 {
	var sum float32
	count := 0

	for _, n1 := range c1 {
		idx1, ok1 := noteToIdx[n1]
		if !ok1 {
			continue
		}
		for _, n2 := range c2 {
			idx2, ok2 := noteToIdx[n2]
			if !ok2 {
				continue
			}
			sum += simMatrix[idx1][idx2]
			count++
		}
	}

	if count == 0 {
		return 0
	}
	return sum / float32(count)
}

// greedyClustering è´ªå©ªèšç±»ï¼šæ¯ä¸ªç¬”è®°å°è¯•åŠ å…¥æœ€ç›¸ä¼¼çš„ç°æœ‰ç°‡æˆ–åˆ›å»ºæ–°ç°‡
func greedyClustering(notes []*Note, threshold float32) [][]*Note {
	if len(notes) == 0 {
		return nil
	}

	type clusterInfo struct {
		notes    []*Note
		centroid []float32
	}

	clusters := make([]clusterInfo, 0)

	for _, note := range notes {
		if len(note.Embedding) == 0 {
			continue
		}

		bestIdx := -1
		var bestSim float32 = -1

		for i, c := range clusters {
			sim := cosineSimilarity(note.Embedding, c.centroid)
			if sim > bestSim {
				bestSim = sim
				bestIdx = i
			}
		}

		if bestIdx >= 0 && bestSim >= threshold {
			clusters[bestIdx].notes = append(clusters[bestIdx].notes, note)
			// æ›´æ–°ä¸­å¿ƒ
			var embeddings [][]float32
			for _, n := range clusters[bestIdx].notes {
				embeddings = append(embeddings, n.Embedding)
			}
			clusters[bestIdx].centroid = computeCentroid(embeddings)
		} else {
			// åˆ›å»ºæ–°ç°‡
			clusters = append(clusters, clusterInfo{
				notes:    []*Note{note},
				centroid: note.Embedding,
			})
		}
	}

	result := make([][]*Note, 0, len(clusters))
	for _, c := range clusters {
		result = append(result, c.notes)
	}
	return result
}

func checkAndCreateLevel2Categories(userID int) {
	// ç»Ÿè®¡ä¸€çº§åˆ†ç±»æ•°é‡
	var level1Cats []*Category
	for i := range data.Categories {
		if data.Categories[i].UserID == userID && data.Categories[i].ParentID == 0 {
			level1Cats = append(level1Cats, &data.Categories[i])
		}
	}

	if len(level1Cats) <= MaxLevel1Categories {
		return
	}

	log.Printf("Creating level-2 categories: %d level-1 categories found", len(level1Cats))

	// æ”¶é›†æœ‰ä¸­å¿ƒå‘é‡çš„åˆ†ç±»
	type catWithEmb struct {
		cat *Category
		emb []float32
	}

	var catsWithEmb []catWithEmb
	for _, cat := range level1Cats {
		if len(cat.Centroid) > 0 {
			catsWithEmb = append(catsWithEmb, catWithEmb{cat: cat, emb: cat.Centroid})
		}
	}

	if len(catsWithEmb) < 2 {
		return
	}

	n := len(catsWithEmb)

	// æ„å»ºç›¸ä¼¼åº¦çŸ©é˜µ
	simMatrix := make([][]float32, n)
	for i := 0; i < n; i++ {
		simMatrix[i] = make([]float32, n)
	}
	for i := 0; i < n; i++ {
		for j := i + 1; j < n; j++ {
			sim := cosineSimilarity(catsWithEmb[i].emb, catsWithEmb[j].emb)
			simMatrix[i][j] = sim
			simMatrix[j][i] = sim
		}
	}

	// ä½¿ç”¨å±‚æ¬¡èšç±»å¯¹ä¸€çº§åˆ†ç±»è¿›è¡Œåˆ†ç»„
	// åˆå§‹åŒ–ï¼šæ¯ä¸ªåˆ†ç±»æ˜¯ä¸€ä¸ªç°‡
	clusters := make([][]int, n) // å­˜å‚¨åˆ†ç±»ç´¢å¼•
	for i := 0; i < n; i++ {
		clusters[i] = []int{i}
	}

	// å±‚æ¬¡èšç±»ï¼Œä½†é™åˆ¶æ¯ä¸ªç°‡çš„å¤§å°
	for {
		// æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ä¸¤ä¸ªç°‡
		bestI, bestJ := -1, -1
		var bestSim float32 = -1

		for i := 0; i < len(clusters); i++ {
			if clusters[i] == nil {
				continue
			}
			// å¦‚æœè¯¥ç°‡å·²ç»è¾¾åˆ°æœ€å¤§å¤§å°ï¼Œè·³è¿‡
			if len(clusters[i]) >= MaxSubcategoriesPerL2 {
				continue
			}

			for j := i + 1; j < len(clusters); j++ {
				if clusters[j] == nil {
					continue
				}
				// å¦‚æœåˆå¹¶åä¼šè¶…è¿‡æœ€å¤§å¤§å°ï¼Œè·³è¿‡
				if len(clusters[i])+len(clusters[j]) > MaxSubcategoriesPerL2 {
					continue
				}

				// ä½¿ç”¨å¹³å‡é“¾æ¥è®¡ç®—ç°‡é—´ç›¸ä¼¼åº¦
				var totalSim float32
				count := 0
				for _, ci := range clusters[i] {
					for _, cj := range clusters[j] {
						totalSim += simMatrix[ci][cj]
						count++
					}
				}
				avgSim := totalSim / float32(count)

				if avgSim > bestSim {
					bestSim = avgSim
					bestI, bestJ = i, j
				}
			}
		}

		// å¦‚æœæœ€å¥½çš„ç›¸ä¼¼åº¦éƒ½ä½äºé˜ˆå€¼ï¼Œåœæ­¢èšç±»
		if bestSim < Level2SimilarityThresh || bestI < 0 {
			break
		}

		// åˆå¹¶ä¸¤ä¸ªç°‡
		clusters[bestI] = append(clusters[bestI], clusters[bestJ]...)
		clusters[bestJ] = nil
	}

	// è¿‡æ»¤å‡ºæœ‰æ•ˆçš„ç»„ï¼ˆè‡³å°‘2ä¸ªæˆå‘˜ï¼‰
	var groups [][]*Category
	for _, cluster := range clusters {
		if cluster != nil && len(cluster) >= 2 {
			group := make([]*Category, len(cluster))
			for i, idx := range cluster {
				group[i] = catsWithEmb[idx].cat
			}
			groups = append(groups, group)
		}
	}

	log.Printf("Created %d level-2 category groups", len(groups))

	// ä¸ºæ¯ä¸ªç»„åˆ›å»ºäºŒçº§åˆ†ç±»
	for _, group := range groups {
		// æ”¶é›†ç»„å†…æ‰€æœ‰ç¬”è®°ç”¨äºå‘½åï¼ˆä»æ¯ä¸ªå­åˆ†ç±»å–ä¸€äº›ï¼‰
		var notes []Note
		for _, cat := range group {
			count := 0
			for _, note := range data.Notes {
				if note.CategoryID == cat.ID {
					notes = append(notes, note)
					count++
					if count >= 2 { // æ¯ä¸ªå­åˆ†ç±»æœ€å¤šå–2æ¡
						break
					}
				}
			}
			if len(notes) >= 8 { // æ€»å…±æœ€å¤š8æ¡ç”¨äºå‘½å
				break
			}
		}

		// ç”ŸæˆäºŒçº§åˆ†ç±»åç§°
		var name string
		if skipNameGen {
			name = fmt.Sprintf("å¤§ç±»%d", data.NextCategoryID)
		} else {
			var err error
			name, err = generateCategoryName(notes)
			if err != nil {
				name = fmt.Sprintf("å¤§ç±»%d", data.NextCategoryID)
			}
		}

		// è®¡ç®—äºŒçº§åˆ†ç±»ä¸­å¿ƒ
		var embeddings [][]float32
		for _, cat := range group {
			if len(cat.Centroid) > 0 {
				embeddings = append(embeddings, cat.Centroid)
			}
		}

		newCat := Category{
			ID:        data.NextCategoryID,
			UserID:    userID,
			Name:      name,
			ParentID:  -1, // -1 è¡¨ç¤ºè¿™æ˜¯äºŒçº§åˆ†ç±»ï¼ˆçˆ¶åˆ†ç±»ï¼‰
			Centroid:  computeCentroid(embeddings),
			NoteCount: 0,
			CreatedAt: time.Now().Format("2006-01-02 15:04:05"),
		}
		data.Categories = append(data.Categories, newCat)
		data.NextCategoryID++

		log.Printf("Created level-2 category '%s' with %d subcategories", name, len(group))

		// æ›´æ–°å­åˆ†ç±»çš„ ParentID
		for _, cat := range group {
			for i := range data.Categories {
				if data.Categories[i].ID == cat.ID {
					data.Categories[i].ParentID = newCat.ID
					break
				}
			}
		}
	}
}

// ============ API Handlers ============

func registerHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var req LoginRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	if req.Username == "" || req.Password == "" {
		http.Error(w, "Username and password required", http.StatusBadRequest)
		return
	}

	dataMutex.Lock()
	defer dataMutex.Unlock()

	for _, user := range data.Users {
		if user.Username == req.Username {
			http.Error(w, "Username already exists", http.StatusConflict)
			return
		}
	}

	hashedPassword, err := bcrypt.GenerateFromPassword([]byte(req.Password), bcrypt.DefaultCost)
	if err != nil {
		http.Error(w, "Server error", http.StatusInternalServerError)
		return
	}

	newUser := User{
		ID:       data.NextUserID,
		Username: req.Username,
		Password: string(hashedPassword),
	}
	data.Users = append(data.Users, newUser)
	data.NextUserID++
	saveData()

	token, _ := generateToken(newUser.ID, newUser.Username)

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"message":  "Registration successful",
		"token":    token,
		"username": req.Username,
	})
}

func loginHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var req LoginRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	dataMutex.RLock()
	defer dataMutex.RUnlock()

	var foundUser *User
	for i := range data.Users {
		if data.Users[i].Username == req.Username {
			foundUser = &data.Users[i]
			break
		}
	}

	if foundUser == nil {
		http.Error(w, "Invalid credentials", http.StatusUnauthorized)
		return
	}

	if err := bcrypt.CompareHashAndPassword([]byte(foundUser.Password), []byte(req.Password)); err != nil {
		http.Error(w, "Invalid credentials", http.StatusUnauthorized)
		return
	}

	token, _ := generateToken(foundUser.ID, foundUser.Username)

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"message":  "Login successful",
		"token":    token,
		"username": foundUser.Username,
	})
}

func getNotesHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	// åˆ†é¡µå‚æ•°
	page := 1
	limit := 20
	categoryID := 0
	themeID := 0
	searchQuery := ""

	if p := r.URL.Query().Get("page"); p != "" {
		if pVal, err := strconv.Atoi(p); err == nil && pVal > 0 {
			page = pVal
		}
	}
	if l := r.URL.Query().Get("limit"); l != "" {
		if lVal, err := strconv.Atoi(l); err == nil && lVal > 0 && lVal <= 100 {
			limit = lVal
		}
	}
	if c := r.URL.Query().Get("category_id"); c != "" {
		if cVal, err := strconv.Atoi(c); err == nil {
			categoryID = cVal
		}
	}
	if t := r.URL.Query().Get("theme_id"); t != "" {
		if tVal, err := strconv.Atoi(t); err == nil {
			themeID = tVal
		}
	}
	if q := r.URL.Query().Get("q"); q != "" {
		searchQuery = strings.ToLower(strings.TrimSpace(q))
	}

	dataMutex.RLock()
	defer dataMutex.RUnlock()

	var userNotes []Note
	for i := len(data.Notes) - 1; i >= 0; i-- {
		note := data.Notes[i]
		if note.UserID != userID {
			continue
		}

		// æŒ‰åˆ†ç±»ç­›é€‰
		if categoryID > 0 && note.CategoryID != categoryID {
			continue
		}
		if categoryID == -1 && note.CategoryID != 0 {
			// -1 è¡¨ç¤ºåªçœ‹æœªåˆ†ç±»
			continue
		}

		// æŒ‰å…³é”®è¯æœç´¢
		if searchQuery != "" && !strings.Contains(strings.ToLower(note.Content), searchQuery) {
			continue
		}

		// æŒ‰ä¸»é¢˜ç­›é€‰
		if themeID > 0 && note.ThemeID != themeID {
			continue
		}

		// è¿”å›æ—¶ä¸åŒ…å« embedding ä»¥å‡å°‘æ•°æ®é‡
		noteWithoutEmb := Note{
			ID:          note.ID,
			UserID:      note.UserID,
			Content:     note.Content,
			CreatedAt:   note.CreatedAt,
			CategoryID:  note.CategoryID,
			ThemeID:     note.ThemeID,
			CatResponse: note.CatResponse,
		}
		userNotes = append(userNotes, noteWithoutEmb)
	}

	total := len(userNotes)
	start := (page - 1) * limit
	end := start + limit

	if start >= total {
		userNotes = []Note{}
	} else {
		if end > total {
			end = total
		}
		userNotes = userNotes[start:end]
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"notes":   userNotes,
		"total":   total,
		"page":    page,
		"limit":   limit,
		"hasMore": end < total,
	})
}

// CreateNoteResponse åˆ›å»ºç¬”è®°çš„å“åº”ï¼Œå¯èƒ½åŒ…å«çŒ«å’ªå›åº”
type CreateNoteResponse struct {
	Note        Note   `json:"note"`
	CatResponse string `json:"cat_response,omitempty"`
	CatName     string `json:"cat_name,omitempty"`
}

func createNoteHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	var req NoteRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	if req.Content == "" {
		http.Error(w, "Content required", http.StatusBadRequest)
		return
	}

	dataMutex.Lock()

	newNote := Note{
		ID:        data.NextNoteID,
		UserID:    userID,
		Content:   req.Content,
		CreatedAt: time.Now().Format("2006-01-02 15:04:05"),
	}
	data.Notes = append(data.Notes, newNote)
	noteIdx := len(data.Notes) - 1
	data.NextNoteID++
	saveData()

	dataMutex.Unlock()

	// å¼‚æ­¥ç”ŸæˆåµŒå…¥å’Œåˆ†ç±»
	go func() {
		embedding, err := getEmbedding(req.Content)
		if err != nil {
			log.Printf("Failed to get embedding for note %d: %v", newNote.ID, err)
			return
		}

		dataMutex.Lock()
		defer dataMutex.Unlock()

		// æ›´æ–°ç¬”è®°çš„åµŒå…¥
		if noteIdx < len(data.Notes) && data.Notes[noteIdx].ID == newNote.ID {
			data.Notes[noteIdx].Embedding = embedding
			assignNoteToCategory(&data.Notes[noteIdx])

			// å¦‚æœæœªåˆ†ç±»ï¼Œå°è¯•èšç±»
			if data.Notes[noteIdx].CategoryID == 0 {
				clusterUncategorizedNotes(userID)
			}

			saveData()
		}
	}()

	// å¼‚æ­¥ç”Ÿæˆæ—¶å…‰å›å»Šå›¾ç‰‡ï¼ˆå¦‚æœé€‚åˆï¼‰
	go func() {
		if isNoteSuitableForImage(req.Content) {
			log.Printf("Note %d is suitable for image generation", newNote.ID)
			noteImage, err := processNoteImage(newNote.ID, req.Content)
			if err != nil {
				log.Printf("Failed to generate image for note %d: %v", newNote.ID, err)
			} else {
				log.Printf("Image generated for note %d: %s", newNote.ID, noteImage.Status)
			}

			dataMutex.Lock()
			if data.NoteImages == nil {
				data.NoteImages = make(map[int]*NoteImage)
			}
			data.NoteImages[newNote.ID] = noteImage
			saveData()
			dataMutex.Unlock()
		}
	}()

	// å‡†å¤‡å“åº” - ç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…çŒ«å’ªå›åº”
	response := CreateNoteResponse{
		Note: newNote,
	}

	// è¿”å›æ˜¯å¦éœ€è¦çŒ«å’ªå›åº”çš„æ ‡å¿—
	if isNoteMeaningful(req.Content) {
		response.CatName = "pending" // æ ‡è®°éœ€è¦è·å–çŒ«å’ªå›åº”
		log.Printf("Note %d is meaningful, cat_name=pending", newNote.ID)
	} else {
		log.Printf("Note %d is not meaningful enough for cat response", newNote.ID)
	}

	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(http.StatusCreated)
	json.NewEncoder(w).Encode(response)
}

// è·å–çŒ«å’ªå›åº”çš„ç‹¬ç«‹æ¥å£
func getCatResponseHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	var req struct {
		NoteID     int    `json:"note_id"`
		Content    string `json:"content"`
		ZhizhiMode bool   `json:"zhizhi_mode"`
	}
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	log.Printf("Cat response requested for note_id=%d, user_id=%d, content_len=%d, zhizhi_mode=%v", req.NoteID, userID, len(req.Content), req.ZhizhiMode)

	catResponse, err := generateCatResponse(req.Content, req.ZhizhiMode)
	if err != nil {
		log.Printf("Failed to generate cat response: %v", err)
		http.Error(w, "Failed to generate response", http.StatusInternalServerError)
		return
	}

	log.Printf("Cat response generated for note_id=%d, response_len=%d", req.NoteID, len(catResponse))

	// ç«‹å³è¿”å›å“åº”ç»™å‰ç«¯ï¼Œä¸ç­‰å¾…ä¿å­˜
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]string{
		"cat_name":     "çŸ¥çŸ¥",
		"cat_response": catResponse,
	})

	// å¼‚æ­¥ä¿å­˜çŒ«å’ªå›å¤åˆ°ç¬”è®°ï¼ˆä¸é˜»å¡HTTPå“åº”ï¼‰
	if req.NoteID > 0 {
		go func(noteID, uID int, response string) {
			dataMutex.Lock()
			defer dataMutex.Unlock()
			for i := range data.Notes {
				if data.Notes[i].ID == noteID && data.Notes[i].UserID == uID {
					data.Notes[i].CatResponse = response
					saveData()
					log.Printf("Cat response saved for note_id=%d", noteID)
					return
				}
			}
			log.Printf("Note not found for note_id=%d, user_id=%d", noteID, uID)
		}(req.NoteID, userID, catResponse)
	}
}

func importNotesHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	var req ImportRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	if len(req.Notes) == 0 {
		http.Error(w, "No notes to import", http.StatusBadRequest)
		return
	}

	dataMutex.Lock()

	imported := 0
	var newNoteIDs []int
	for _, note := range req.Notes {
		if note.Content == "" {
			continue
		}

		createdAt := note.CreatedAt
		if createdAt == "" {
			createdAt = time.Now().Format("2006-01-02 15:04:05")
		}

		newNote := Note{
			ID:        data.NextNoteID,
			UserID:    userID,
			Content:   note.Content,
			CreatedAt: createdAt,
		}
		data.Notes = append(data.Notes, newNote)
		newNoteIDs = append(newNoteIDs, data.NextNoteID)
		data.NextNoteID++
		imported++
	}

	saveData()
	dataMutex.Unlock()

	// å¼‚æ­¥æ‰¹é‡ç”ŸæˆåµŒå…¥
	go func() {
		migrateEmbeddings(userID, newNoteIDs)
	}()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"message":  "Import successful",
		"imported": imported,
	})
}

func deleteNoteHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "DELETE" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	noteIDStr := strings.TrimPrefix(r.URL.Path, "/api/notes/")
	noteID, err := strconv.Atoi(noteIDStr)
	if err != nil {
		http.Error(w, "Invalid note ID", http.StatusBadRequest)
		return
	}

	dataMutex.Lock()
	defer dataMutex.Unlock()

	found := false
	var categoryID int
	for i, note := range data.Notes {
		if note.ID == noteID && note.UserID == userID {
			categoryID = note.CategoryID
			data.Notes = append(data.Notes[:i], data.Notes[i+1:]...)
			found = true
			break
		}
	}

	if !found {
		http.Error(w, "Note not found", http.StatusNotFound)
		return
	}

	// æ›´æ–°åˆ†ç±»ä¸­å¿ƒ
	if categoryID > 0 {
		updateCategoryCentroid(categoryID)
	}

	saveData()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]string{"message": "Note deleted"})
}

func starlightHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	// æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
	refresh := r.URL.Query().Get("refresh") == "true"

	dataMutex.RLock()
	// æ”¶é›†æœ€è¿‘çš„æœ‰æ„ä¹‰çš„å¿«è®°ï¼ˆè‡³å°‘20å­—ï¼‰
	var recentNotes []Note
	for i := len(data.Notes) - 1; i >= 0 && len(recentNotes) < 50; i-- {
		note := data.Notes[i]
		if note.UserID == userID && len([]rune(note.Content)) >= 20 {
			recentNotes = append(recentNotes, note)
		}
	}
	cachedStarlight := data.UserStarlight[userID]
	dataMutex.RUnlock()

	if len(recentNotes) < 5 {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"report": "ä½ çš„å¿«è®°è¿˜ä¸å¤Ÿå¤šï¼Œå†å¤šè®°å½•ä¸€äº›ç”Ÿæ´»ä¸­çš„ç‚¹æ»´å§ï¼å½“ä½ ç§¯ç´¯äº†è¶³å¤Ÿå¤šçš„æƒ³æ³•ï¼ŒStarlight ä¼šä¸ºä½ ç”Ÿæˆä¸€ä»½ä¸“å±çš„æ´å¯ŸæŠ¥å‘Šã€‚",
			"notes":  []Note{},
		})
		return
	}

	// å¦‚æœæœ‰ç¼“å­˜ä¸”ä¸æ˜¯åˆ·æ–°è¯·æ±‚ï¼Œç›´æ¥è¿”å›
	if cachedStarlight != nil && !refresh {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"report":       cachedStarlight.Report,
			"generated_at": cachedStarlight.GeneratedAt,
			"note_count":   len(recentNotes),
			"notes":        recentNotes[:min(5, len(recentNotes))],
		})
		return
	}

	// æ„å»ºç¬”è®°å†…å®¹ç”¨äº LLM åˆ†æ
	var notesText strings.Builder
	for i, note := range recentNotes {
		notesText.WriteString(fmt.Sprintf("%d. [%s] %s\n", i+1, note.CreatedAt, note.Content))
	}

	log.Printf("Generating starlight for user %d (refresh=%v)", userID, refresh)

	// è°ƒç”¨ LLM ç”Ÿæˆæ´å¯ŸæŠ¥å‘Š
	report, err := generateStarlightReport(notesText.String())
	if err != nil {
		log.Printf("Starlight report generation failed: %v", err)
		report = generateFallbackReport(recentNotes)
	}

	generatedAt := time.Now().Format(time.RFC3339)

	// ä¿å­˜åˆ°ç¼“å­˜
	dataMutex.Lock()
	if data.UserStarlight == nil {
		data.UserStarlight = make(map[int]*StarlightCache)
	}
	data.UserStarlight[userID] = &StarlightCache{
		Report:      report,
		GeneratedAt: generatedAt,
		NoteCount:   len(recentNotes),
	}
	dataMutex.Unlock()
	saveData()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"report":       report,
		"generated_at": generatedAt,
		"note_count":   len(recentNotes),
		"notes":        recentNotes[:min(5, len(recentNotes))],
	})
}

// generateStarlightReport ä½¿ç”¨ LLM ç”Ÿæˆæ´å¯ŸæŠ¥å‘Š
func generateStarlightReport(notesText string) (string, error) {
	if dashscopeAPIKey == "" {
		return "", fmt.Errorf("API key not configured")
	}

	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä½æ¸©æš–è€Œå¯Œæœ‰æ´å¯ŸåŠ›çš„å¿ƒç†å’¨è¯¢å¸ˆå’Œäººç”Ÿæ•™ç»ƒã€‚è¯·åŸºäºä»¥ä¸‹è¿™ä½ç”¨æˆ·æœ€è¿‘çš„ç”Ÿæ´»è®°å½•ï¼Œå†™ä¸€ä»½èµ°å¿ƒçš„æ´å¯ŸæŠ¥å‘Šã€‚

è¦æ±‚ï¼š
1. ç”¨ç¬¬äºŒäººç§°"ä½ "æ¥ç§°å‘¼ç”¨æˆ·ï¼Œè¯­æ°”æ¸©æš–äº²åˆ‡
2. å‘ç°ç”¨æˆ·ç”Ÿæ´»ä¸­çš„æ¨¡å¼ã€æƒ…ç»ªå˜åŒ–ã€å…³æ³¨ç‚¹
3. ç»™å‡ºçœŸè¯šçš„è‚¯å®šå’Œé¼“åŠ±ï¼Œè®©ç”¨æˆ·æ„Ÿå—åˆ°è¢«ç†è§£
4. å¦‚æœå‘ç°å€¼å¾—æ³¨æ„çš„åœ°æ–¹ï¼Œæ¸©æŸ”åœ°ç»™å‡ºå»ºè®®
5. æŠ¥å‘Šè¦æœ‰æƒ…æ„Ÿæ·±åº¦ï¼Œèƒ½æ‰“åŠ¨äººå¿ƒ
6. é•¿åº¦æ§åˆ¶åœ¨300-500å­—
7. ä½¿ç”¨ä¼˜ç¾çš„æ’ç‰ˆï¼Œå¯ä»¥ç”¨ emoji ç‚¹ç¼€
8. æœ€åç»™å‡ºä¸€å¥ä¸“å±äºè¿™ä½ç”¨æˆ·çš„åŠ±å¿—å¯„è¯­

ç”¨æˆ·çš„è¿‘æœŸè®°å½•ï¼š
%s

è¯·ç”Ÿæˆæ´å¯ŸæŠ¥å‘Šï¼š`, notesText)

	reqBody := map[string]interface{}{
		"model": "qwen-plus",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "user", "content": prompt},
			},
		},
		"parameters": map[string]interface{}{
			"temperature": 0.8,
			"max_tokens":  1000,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	var result struct {
		Output struct {
			Text string `json:"text"`
		} `json:"output"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return "", err
	}

	if result.Output.Text == "" {
		return "", fmt.Errorf("empty response")
	}

	return result.Output.Text, nil
}

// generateFallbackReport é™çº§å¤„ç† - ç”Ÿæˆç®€å•æŠ¥å‘Š
func generateFallbackReport(notes []Note) string {
	// ç»Ÿè®¡ä¸€äº›åŸºæœ¬ä¿¡æ¯
	totalChars := 0
	for _, note := range notes {
		totalChars += len([]rune(note.Content))
	}

	return fmt.Sprintf(`âœ¨ ä½ çš„ Starlight æŠ¥å‘Š

æœ€è¿‘ä½ è®°å½•äº† %d æ¡å¿«è®°ï¼Œå…± %d ä¸ªå­—ã€‚

æ¯ä¸€æ¬¡è®°å½•ï¼Œéƒ½æ˜¯ä¸è‡ªå·±å†…å¿ƒçš„å¯¹è¯ã€‚ä½ çš„æ–‡å­—é‡Œè—ç€ç”Ÿæ´»çš„ç‚¹æ»´ï¼Œä¹Ÿè—ç€æˆé•¿çš„è½¨è¿¹ã€‚

ç»§ç»­ä¿æŒè¿™ä»½è®°å½•çš„ä¹ æƒ¯å§ï¼Œæœªæ¥çš„ä½ ä¼šæ„Ÿè°¢ç°åœ¨è®¤çœŸç”Ÿæ´»çš„è‡ªå·±ã€‚

ğŸ’« ä»Šæ—¥å¯„è¯­ï¼šç”Ÿæ´»ä¸åœ¨åˆ«å¤„ï¼Œå°±åœ¨æ­¤åˆ»çš„æ¯ä¸€ä¸ªç¬é—´ã€‚`, len(notes), totalChars)
}

// ============ æ´è§æ¨¡å— ============

// getInsightsHandler è·å–ç”¨æˆ·æ´è§æŠ¥å‘Š
func getInsightsHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	// æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
	refresh := r.URL.Query().Get("refresh") == "true"

	// è·å–ç”¨æˆ·æ‰€æœ‰ç¬”è®°
	dataMutex.RLock()
	var userNotes []Note
	for _, note := range data.Notes {
		if note.UserID == userID {
			userNotes = append(userNotes, note)
		}
	}
	cachedReport := data.UserInsights[userID]
	dataMutex.RUnlock()

	// éœ€è¦è¶³å¤Ÿçš„ç¬”è®°æ‰èƒ½åˆ†æ
	if len(userNotes) < 10 {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"error":      "not_enough_notes",
			"message":    "ä½ çš„å¿«è®°è¿˜ä¸å¤Ÿå¤šå‘¢ï¼Œå†å¤šè®°å½•ä¸€äº›ç”Ÿæ´»ä¸­çš„ç‚¹æ»´å§ï¼å½“ä½ ç§¯ç´¯äº† 10 æ¡ä»¥ä¸Šçš„æƒ³æ³•ï¼Œæˆ‘ä¼šä¸ºä½ ç”Ÿæˆä¸“å±çš„æ´è§æŠ¥å‘Šã€‚",
			"note_count": len(userNotes),
			"required":   10,
		})
		return
	}

	// å¦‚æœæœ‰ç¼“å­˜ä¸”ä¸æ˜¯åˆ·æ–°è¯·æ±‚ï¼Œç›´æ¥è¿”å›
	if cachedReport != nil && !refresh {
		cachedReport.NoteCount = len(userNotes) // æ›´æ–°ç¬”è®°æ•°
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(cachedReport)
		return
	}

	// æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
	sort.Slice(userNotes, func(i, j int) bool {
		return userNotes[i].CreatedAt > userNotes[j].CreatedAt
	})

	// å–æœ€è¿‘ 100 æ¡ç”¨äºåˆ†æ
	analysisNotes := userNotes
	if len(analysisNotes) > 100 {
		analysisNotes = analysisNotes[:100]
	}

	// æ„å»ºç¬”è®°æ–‡æœ¬ç”¨äº LLM
	var notesText strings.Builder
	for i, note := range analysisNotes {
		notesText.WriteString(fmt.Sprintf("%d. [%s] %s\n", i+1, note.CreatedAt[:10], note.Content))
	}

	log.Printf("Generating insights for user %d with %d notes (refresh=%v)", userID, len(analysisNotes), refresh)

	report, err := generateInsightReport(notesText.String(), len(userNotes))
	if err != nil {
		log.Printf("Insight generation failed: %v", err)
		report = generateFallbackInsight(userNotes)
	}

	report.NoteCount = len(userNotes)
	report.GeneratedAt = time.Now().Format(time.RFC3339)

	// ä¿å­˜åˆ°ç¼“å­˜
	dataMutex.Lock()
	if data.UserInsights == nil {
		data.UserInsights = make(map[int]*InsightReport)
	}
	data.UserInsights[userID] = report
	dataMutex.Unlock()
	saveData()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(report)
}

// generateInsightReport ä½¿ç”¨ LLM ç”Ÿæˆå®Œæ•´æ´è§æŠ¥å‘Š
func generateInsightReport(notesText string, totalNotes int) (*InsightReport, error) {
	if dashscopeAPIKey == "" {
		return nil, fmt.Errorf("API key not configured")
	}

	// æ„å»ºç»¼åˆåˆ†æ prompt
	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä½æ¸©æš–è€Œä¸“ä¸šçš„å¿ƒç†å’¨è¯¢å¸ˆå’Œäººæ ¼åˆ†æä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹ç”¨æˆ·çš„æ—¥å¸¸è®°å½•ï¼Œè¿›è¡Œæ·±å…¥çš„äººæ ¼ä¸æƒ…ç»ªåˆ†æã€‚

ç”¨æˆ·çš„è®°å½•ï¼ˆå…± %d æ¡ï¼‰ï¼š
%s

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ˆä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š

{
  "mbti": {
    "type": "å››å­—æ¯ç±»å‹ï¼Œå¦‚INFP",
    "type_name": "ç±»å‹ä¸­æ–‡åï¼Œå¦‚è°ƒåœè€…",
    "type_emoji": "ä»£è¡¨è¿™ä¸ªç±»å‹çš„emoji",
    "dimensions": [
      {"name": "E-I", "left": "å¤–å‘", "right": "å†…å‘", "score": 75, "lean": "right"},
      {"name": "S-N", "left": "å®æ„Ÿ", "right": "ç›´è§‰", "score": 60, "lean": "right"},
      {"name": "T-F", "left": "æ€è€ƒ", "right": "æƒ…æ„Ÿ", "score": 70, "lean": "right"},
      {"name": "J-P", "left": "åˆ¤æ–­", "right": "æ„ŸçŸ¥", "score": 55, "lean": "right"}
    ],
    "description": "ç”¨æ¸©æš–äº²åˆ‡çš„è¯­æ°”æè¿°è¿™ä¸ªäººæ ¼ç±»å‹çš„æ ¸å¿ƒç‰¹è´¨ï¼Œ200å­—å·¦å³",
    "traits": ["ç‰¹è´¨1", "ç‰¹è´¨2", "ç‰¹è´¨3", "ç‰¹è´¨4"],
    "evidences": ["ä»è®°å½•ä¸­å¼•ç”¨èƒ½ä½“ç°è¯¥æ€§æ ¼çš„2-3ä¸ªç‰‡æ®µ"]
  },
  "emotions": {
    "dominant": "ä¸»å¯¼æƒ…ç»ªåç§°",
    "dom_emoji": "ä¸»å¯¼æƒ…ç»ªçš„emoji",
    "distribution": [
      {"name": "æ€è€ƒ", "emoji": "ğŸ¤”", "count": 25, "percent": 35, "color": "#8B5CF6"},
      {"name": "å¹³é™", "emoji": "ğŸ˜Œ", "count": 20, "percent": 28, "color": "#10B981"},
      {"name": "å–œæ‚¦", "emoji": "ğŸ˜Š", "count": 15, "percent": 21, "color": "#F59E0B"},
      {"name": "å›°æƒ‘", "emoji": "ğŸ˜•", "count": 8, "percent": 11, "color": "#6B7280"},
      {"name": "ç„¦è™‘", "emoji": "ğŸ˜°", "count": 4, "percent": 5, "color": "#EF4444"}
    ],
    "trend": "æè¿°æœ€è¿‘çš„æƒ…ç»ªèµ°åŠ¿ï¼Œæ˜¯ç¨³å®šã€ä¸Šå‡è¿˜æ˜¯æœ‰æ³¢åŠ¨",
    "insight": "ç”¨æ¸©æš–çš„è¯­æ°”ç»™å‡ºæƒ…ç»ªæ´å¯Ÿï¼Œè®©ç”¨æˆ·æ„Ÿå—åˆ°è¢«ç†è§£"
  },
  "keywords": [
    {"word": "å…³é”®è¯1", "count": 8, "size": 5, "emotion": "positive"},
    {"word": "å…³é”®è¯2", "count": 6, "size": 4, "emotion": "neutral"},
    {"word": "å…³é”®è¯3", "count": 5, "size": 4, "emotion": "reflective"},
    {"word": "å…³é”®è¯4", "count": 4, "size": 3, "emotion": "positive"},
    {"word": "å…³é”®è¯5", "count": 3, "size": 3, "emotion": "concern"},
    {"word": "å…³é”®è¯6", "count": 3, "size": 2, "emotion": "neutral"},
    {"word": "å…³é”®è¯7", "count": 2, "size": 2, "emotion": "positive"},
    {"word": "å…³é”®è¯8", "count": 2, "size": 2, "emotion": "reflective"}
  ],
  "future": {
    "emerging_interests": [
      {
        "topic": "æ­£åœ¨èŒèŠ½çš„å…´è¶£é¢†åŸŸåç§°",
        "emoji": "ä»£è¡¨è¿™ä¸ªå…´è¶£çš„emoji",
        "signal": "ä»å“ªäº›è®°å½•ä¸­å‘ç°äº†è¿™ä¸ªå…´è¶£çš„è‹—å¤´ï¼ˆå¼•ç”¨å…·ä½“å†…å®¹ï¼‰",
        "suggestion": "æ¸©æŸ”çš„æ¢ç´¢å»ºè®®ï¼Œç”¨'ä¹Ÿè®¸ä½ å¯ä»¥...'çš„è¯­æ°”"
      }
    ],
    "growth_trajectory": {
      "from_state": "è¿‡å»çš„çŠ¶æ€æè¿°ï¼Œå¦‚'æ›´å…³æ³¨æ‰§è¡Œå’Œå®Œæˆä»»åŠ¡'",
      "to_state": "æ­£åœ¨è½¬å˜ä¸ºçš„çŠ¶æ€ï¼Œå¦‚'å¼€å§‹æ€è€ƒäº‹æƒ…èƒŒåçš„æ„ä¹‰'",
      "evidence": "æ”¯æŒè¿™ä¸ªåˆ¤æ–­çš„å…·ä½“è®°å½•å†…å®¹",
      "meaning": "ç”¨æ¸©æš–çš„è¯­æ°”è§£é‡Šè¿™ç§å˜åŒ–çš„ç§¯ææ„ä¹‰ï¼Œ100å­—å·¦å³"
    },
    "hidden_potential": [
      {
        "ability": "è¢«å‘ç°çš„æ½œåœ¨èƒ½åŠ›åç§°",
        "emoji": "ä»£è¡¨è¿™ä¸ªèƒ½åŠ›çš„emoji",
        "evidence": "ä»å“ªäº›è®°å½•ä¸­çœ‹å‡ºè¿™ä¸ªèƒ½åŠ›",
        "affirmation": "çœŸè¯šè‚¯å®šè¿™ä¸ªèƒ½åŠ›çš„è¯è¯­ï¼Œç»™äºˆåŠ›é‡"
      }
    ],
    "summary": "ä¸€æ®µ100å­—å·¦å³çš„æœªæ¥å±•æœ›ï¼Œè¯­æ°”æ¸©æš–æœ‰åŠ›é‡ï¼Œè®©ç”¨æˆ·å¯¹æœªæ¥å……æ»¡æœŸå¾…ã€‚ç”¨'æˆ‘çœ‹è§...'ã€'ä¹Ÿè®¸...'çš„è¯­æ°”ï¼Œé¿å…ç»å¯¹æ–­è¨€ã€‚"
  },
  "personal_note": "å†™ä¸€æ®µ200-300å­—çš„ä¸“å±å¯„è¯­ï¼Œåƒä¸€ä½æ‡‚ä½ çš„è€æœ‹å‹å†™ç»™ä½ çš„ä¿¡ã€‚ç”¨ç¬¬äºŒäººç§°'ä½ 'ï¼Œè¯­æ°”æ¸©æš–çœŸè¯šï¼ŒåŸºäºåˆ†æç»™å‡ºè‚¯å®šå’Œé¼“åŠ±ï¼Œç»“å°¾ç»™ä¸€å¥ä¸“å±äºè¿™ä½ç”¨æˆ·çš„åŠ›é‡ä¹‹è¯­ã€‚å¯ä»¥èå…¥å¯¹æœªæ¥çš„ç¾å¥½æœŸè®¸ã€‚"
}

æ³¨æ„äº‹é¡¹ï¼š
1. dimensionsçš„scoreè¡¨ç¤ºå³ä¾§å€¾å‘çš„ç¨‹åº¦(0-100)ï¼Œ50ä¸ºä¸­é—´ï¼Œå¤§äº50åå³ï¼Œå°äº50åå·¦
2. emotionsçš„distributionæ•°ç»„è¯·æ ¹æ®å®é™…åˆ†æç»“æœå¡«å†™ï¼Œç™¾åˆ†æ¯”ä¹‹å’Œåº”ä¸º100
3. keywordsè¯·æå–8-12ä¸ªæœ€èƒ½ä»£è¡¨ç”¨æˆ·å†…å¿ƒä¸–ç•Œçš„è¯æ±‡
4. futureéƒ¨åˆ†æ˜¯åŸºäºè®°å½•çš„åˆç†æ¨æµ‹ï¼Œä¸æ˜¯ç®—å‘½ï¼š
   - emerging_interests: åˆ†æ2-3ä¸ªæ­£åœ¨èŒèŠ½çš„å…´è¶£ç‚¹
   - growth_trajectory: åŸºäºè®°å½•å†…å®¹çš„å˜åŒ–è¶‹åŠ¿
   - hidden_potential: å‘ç°2-3ä¸ªç”¨æˆ·å¯èƒ½æ²¡æ„è¯†åˆ°çš„æ½œåŠ›
   - æ‰€æœ‰é¢„æµ‹éƒ½è¦æœ‰æ®å¯ä¾ï¼Œå¼•ç”¨å…·ä½“è®°å½•ä½œä¸ºè¯æ®
5. æ‰€æœ‰æ–‡å­—ä½¿ç”¨ä¸­æ–‡ï¼Œè¯­æ°”è¦æ¸©æš–ã€æœ‰æ´å¯ŸåŠ›ã€è®©äººæ„Ÿåˆ°è¢«ç†è§£
6. åªè¿”å›JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—`, totalNotes, notesText)

	reqBody := map[string]interface{}{
		"model": "qwen-plus",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "user", "content": prompt},
			},
		},
		"parameters": map[string]interface{}{
			"temperature": 0.7,
			"max_tokens":  3500,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 60 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	var result struct {
		Output struct {
			Text string `json:"text"`
		} `json:"output"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, err
	}

	if result.Output.Text == "" {
		return nil, fmt.Errorf("empty response from LLM")
	}

	// è§£æ JSON å“åº”
	var report InsightReport
	// æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—
	text := result.Output.Text
	text = strings.TrimPrefix(text, "```json")
	text = strings.TrimPrefix(text, "```")
	text = strings.TrimSuffix(text, "```")
	text = strings.TrimSpace(text)

	if err := json.Unmarshal([]byte(text), &report); err != nil {
		log.Printf("Failed to parse insight JSON: %v, text: %s", err, text[:min(500, len(text))])
		return nil, fmt.Errorf("failed to parse response: %v", err)
	}

	return &report, nil
}

// generateFallbackInsight é™çº§å¤„ç†
func generateFallbackInsight(notes []Note) *InsightReport {
	return &InsightReport{
		MBTI: MBTIAnalysis{
			Type:        "XXXX",
			TypeName:    "æ¢ç´¢ä¸­",
			TypeEmoji:   "ğŸŒŸ",
			Description: "ä½ çš„äººæ ¼ç”»åƒæ­£åœ¨å½¢æˆä¸­ã€‚æ¯ä¸€æ¡å¿«è®°éƒ½æ˜¯è®¤è¯†è‡ªå·±çš„ä¸€å°æ­¥ï¼Œç»§ç»­è®°å½•ï¼Œè®©æˆ‘æ›´å¥½åœ°äº†è§£ä½ ã€‚",
			Traits:      []string{"ç‹¬ç‰¹", "çœŸå®", "æˆé•¿ä¸­"},
			Dimensions: []Dimension{
				{Name: "E-I", Left: "å¤–å‘", Right: "å†…å‘", Score: 50, Lean: "balanced"},
				{Name: "S-N", Left: "å®æ„Ÿ", Right: "ç›´è§‰", Score: 50, Lean: "balanced"},
				{Name: "T-F", Left: "æ€è€ƒ", Right: "æƒ…æ„Ÿ", Score: 50, Lean: "balanced"},
				{Name: "J-P", Left: "åˆ¤æ–­", Right: "æ„ŸçŸ¥", Score: 50, Lean: "balanced"},
			},
		},
		Emotions: EmotionAnalysis{
			Dominant: "å¹³é™",
			DomEmoji: "ğŸ˜Œ",
			Distribution: []EmotionItem{
				{Name: "å¹³é™", Emoji: "ğŸ˜Œ", Count: 1, Percent: 100, Color: "#10B981"},
			},
			Trend:   "ä½ çš„æƒ…ç»ªæ­£åœ¨è¢«æ¸©æŸ”åœ°è®°å½•ç€",
			Insight: "æ¯ä¸€æ¬¡è®°å½•éƒ½æ˜¯ä¸è‡ªå·±å†…å¿ƒçš„å¯¹è¯ã€‚ç»§ç»­ä¿æŒè¿™ä»½è§‰å¯Ÿï¼Œä½ ä¼šè¶Šæ¥è¶Šäº†è§£è‡ªå·±ã€‚",
		},
		Keywords: []Keyword{
			{Word: "ç”Ÿæ´»", Count: 1, Size: 3, Emotion: "neutral"},
			{Word: "æ€è€ƒ", Count: 1, Size: 3, Emotion: "reflective"},
		},
		Future: FutureForecast{
			EmergingInterests: []InterestItem{
				{
					Topic:      "è‡ªæˆ‘æ¢ç´¢",
					Emoji:      "ğŸ”",
					Signal:     "ä½ å¼€å§‹ç”¨æ–‡å­—è®°å½•ç”Ÿæ´»ï¼Œè¿™æœ¬èº«å°±æ˜¯æ¢ç´¢å†…å¿ƒçš„å¼€å§‹",
					Suggestion: "ä¹Ÿè®¸ä½ å¯ä»¥å°è¯•æ¯å¤©èŠ±å‡ åˆ†é’Ÿå†™ä¸‹å½“å¤©æœ€è§¦åŠ¨ä½ çš„ä¸€ä»¶å°äº‹",
				},
			},
			GrowthTrajectory: TrajectoryItem{
				FromState: "æ—¥å¸¸çš„å¿™ç¢Œä¸å¥”æ³¢",
				ToState:   "å¼€å§‹å…³æ³¨å†…å¿ƒçš„å£°éŸ³",
				Evidence:  "ä½ é€‰æ‹©äº†è®°å½•ï¼Œè¿™æ„å‘³ç€ä½ åœ¨æ„è‡ªå·±çš„æ„Ÿå—",
				Meaning:   "è¿™æ˜¯ä¸€ä¸ªç¾å¥½çš„å¼€å§‹ã€‚å½“æˆ‘ä»¬å¼€å§‹å€¾å¬è‡ªå·±ï¼Œå°±æ˜¯æˆé•¿çš„ç¬¬ä¸€æ­¥ã€‚æ¯ä¸€æ¬¡è®°å½•éƒ½æ˜¯ä¸å†…å¿ƒçš„å¯¹è¯ï¼Œä½ æ­£åœ¨å»ºç«‹ä¸è‡ªå·±æ›´æ·±çš„è¿æ¥ã€‚",
			},
			HiddenPotential: []PotentialItem{
				{
					Ability:     "è§‰å¯ŸåŠ›",
					Emoji:       "âœ¨",
					Evidence:    "ä½ æ„¿æ„åœä¸‹æ¥è®°å½•ï¼Œè¯´æ˜ä½ æœ‰æ•é”çš„è‡ªæˆ‘è§‰å¯Ÿèƒ½åŠ›",
					Affirmation: "è¿™ç§è§‰å¯ŸåŠ›æ˜¯çè´µçš„å¤©èµ‹ï¼Œå®ƒä¼šå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è‡ªå·±å’Œä»–äºº",
				},
			},
			Summary: "æˆ‘çœ‹è§ä¸€ä¸ªæ­£åœ¨å¼€å¯è‡ªæˆ‘æ¢ç´¢ä¹‹æ—…çš„ä½ ã€‚ä¹Ÿè®¸ç°åœ¨çš„è®°å½•è¿˜å¾ˆé›¶æ•£ï¼Œä½†æ¯ä¸€ä¸ªå­—éƒ½æ˜¯ç§å­ã€‚ç»§ç»­å†™ä¸‹å»ï¼Œæœªæ¥çš„ä½ ä¼šçœ‹è§ä¸€ä¸ªæ›´æ¸…æ™°ã€æ›´äº†è§£è‡ªå·±çš„èº«å½±ã€‚",
		},
		PersonalNote: "ä½ å¥½ï¼Œè®°å½•è€…ã€‚\n\næ„Ÿè°¢ä½ å¼€å§‹ç”¨æ–‡å­—æ•æ‰ç”Ÿæ´»çš„ç‰‡æ®µã€‚æ¯ä¸€ä¸ªæƒ³æ³•ã€æ¯ä¸€åˆ»æ„Ÿå—ï¼Œéƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„ä½ ã€‚\n\nç»§ç»­å†™ä¸‹å»å§ï¼Œæœªæ¥çš„ä½ ä¼šæ„Ÿè°¢ç°åœ¨è®¤çœŸç”Ÿæ´»çš„è‡ªå·±ã€‚\n\nğŸ’« æ„¿ä½ çš„æ–‡å­—é‡Œï¼Œæ°¸è¿œè—ç€æ˜Ÿå…‰ã€‚",
	}
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// ============ æˆ‘çš„ä¼ å¥‡ - Biography API ============

// getBiographyHandler è·å–ç”¨æˆ·ä¼ è®°
func getBiographyHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	// æ£€æŸ¥æ˜¯å¦æ­£åœ¨ç”Ÿæˆä¸­
	biographyGenMutex.RLock()
	genStatus := biographyGenStatus[userID]
	biographyGenMutex.RUnlock()

	if genStatus != nil && genStatus.Status == "generating" {
		// æ­£åœ¨ç”Ÿæˆä¸­ï¼Œè¿”å›è¿›åº¦
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"status":       "generating",
			"phase":        genStatus.Phase,
			"progress":     genStatus.Progress,
			"current_step": genStatus.CurrentStep,
			"total_steps":  genStatus.TotalSteps,
			"started_at":   genStatus.StartedAt,
		})
		return
	}

	// è·å–ç”¨æˆ·æœ‰æ„ä¹‰çš„å¿«è®°æ•°é‡
	dataMutex.RLock()
	var meaningfulCount int
	var maxNoteID int
	for _, note := range data.Notes {
		if note.UserID == userID && isNoteMeaningful(note.Content) {
			meaningfulCount++
			if note.ID > maxNoteID {
				maxNoteID = note.ID
			}
		}
	}
	biography := data.UserBiography[userID]
	dataMutex.RUnlock()

	// è®¡ç®—æ˜¯å¦æœ‰æ–°å†…å®¹å¯æ›´æ–°
	var canUpdate bool
	var newNotesCount int
	if biography != nil {
		dataMutex.RLock()
		for _, note := range data.Notes {
			if note.UserID == userID && isNoteMeaningful(note.Content) && note.ID > biography.LastNoteID {
				newNotesCount++
			}
		}
		dataMutex.RUnlock()
		canUpdate = newNotesCount >= 5 // è‡³å°‘5æ¡æ–°è®°å½•æ‰æç¤ºæ›´æ–°
	}

	response := map[string]interface{}{
		"note_count":      meaningfulCount,
		"can_update":      canUpdate,
		"new_notes_count": newNotesCount,
	}

	if biography != nil {
		response["biography"] = biography
		response["status"] = "ready"
	} else if meaningfulCount < 15 {
		response["status"] = "not_enough"
		response["required"] = 15
		response["message"] = "ä½ çš„æœ‰æ„ä¹‰å¿«è®°è¿˜ä¸å¤Ÿå¤šå‘¢ï¼Œå†å¤šè®°å½•ä¸€äº›ç”Ÿæ´»ä¸­çš„ç‚¹æ»´å§ï¼å½“ä½ ç§¯ç´¯äº† 15 æ¡ä»¥ä¸Šæœ‰æ·±åº¦çš„è®°å½•ï¼Œæˆ‘ä¼šä¸ºä½ æ’°å†™ä¸“å±çš„äººç”Ÿä¼ è®°ã€‚"
	} else {
		response["status"] = "empty"
		response["message"] = "ä½ çš„ä¼ å¥‡æ•…äº‹ç­‰å¾…è¢«ä¹¦å†™..."
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(response)
}

// generateBiographyHandler ç”Ÿæˆæˆ–æ›´æ–°ä¼ è®°ï¼ˆå¼‚æ­¥ï¼‰
func generateBiographyHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Unauthorized", http.StatusUnauthorized)
		return
	}

	// æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ç”Ÿæˆä¸­
	biographyGenMutex.RLock()
	existingStatus := biographyGenStatus[userID]
	biographyGenMutex.RUnlock()

	if existingStatus != nil && existingStatus.Status == "generating" {
		// å·²ç»åœ¨ç”Ÿæˆä¸­ï¼Œè¿”å›å½“å‰çŠ¶æ€
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"status":       "generating",
			"phase":        existingStatus.Phase,
			"progress":     existingStatus.Progress,
			"current_step": existingStatus.CurrentStep,
			"total_steps":  existingStatus.TotalSteps,
			"message":      "ä¼ è®°æ­£åœ¨ç”Ÿæˆä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...",
		})
		return
	}

	// è§£æè¯·æ±‚ä½“
	var req struct {
		ForceRegenerate bool `json:"force_regenerate"`
	}
	json.NewDecoder(r.Body).Decode(&req)

	// è·å–ç”¨æˆ·æ‰€æœ‰æœ‰æ„ä¹‰çš„å¿«è®°
	dataMutex.RLock()
	var meaningfulNotes []Note
	for _, note := range data.Notes {
		if note.UserID == userID && isNoteMeaningful(note.Content) {
			meaningfulNotes = append(meaningfulNotes, note)
		}
	}
	existingBio := data.UserBiography[userID]
	dataMutex.RUnlock()

	// æŒ‰æ—¶é—´æ’åºï¼ˆä»æ—§åˆ°æ–°ï¼Œä¼ è®°å™äº‹é¡ºåºï¼‰
	sort.Slice(meaningfulNotes, func(i, j int) bool {
		return meaningfulNotes[i].CreatedAt < meaningfulNotes[j].CreatedAt
	})

	// æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å¿«è®°
	if len(meaningfulNotes) < 15 {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"error":      "not_enough_notes",
			"message":    "æœ‰æ„ä¹‰çš„å¿«è®°è¿˜ä¸å¤Ÿå¤šï¼Œè‡³å°‘éœ€è¦ 15 æ¡æ‰èƒ½ç”Ÿæˆä¼ è®°ã€‚",
			"note_count": len(meaningfulNotes),
			"required":   15,
		})
		return
	}

	// åˆ¤æ–­æ˜¯é¦–æ¬¡ç”Ÿæˆè¿˜æ˜¯å¢é‡æ›´æ–°
	isNewGeneration := existingBio == nil || req.ForceRegenerate
	var newNotes []Note

	if !isNewGeneration {
		// å¢é‡æ›´æ–°ï¼šç­›é€‰æ–°å¿«è®°
		for _, note := range meaningfulNotes {
			if note.ID > existingBio.LastNoteID {
				newNotes = append(newNotes, note)
			}
		}

		if len(newNotes) < 3 {
			// æ–°å†…å®¹å¤ªå°‘ï¼Œä¸æ›´æ–°
			w.Header().Set("Content-Type", "application/json")
			json.NewEncoder(w).Encode(map[string]interface{}{
				"status":         "ready",
				"biography":      existingBio,
				"update_summary": "æ–°å¢å†…å®¹è¾ƒå°‘ï¼Œæš‚æ— æ›´æ–°",
				"version":        existingBio.Version,
			})
			return
		}
	}

	// è®¾ç½®ç”ŸæˆçŠ¶æ€
	biographyGenMutex.Lock()
	biographyGenStatus[userID] = &BiographyGenerationStatus{
		Status:      "generating",
		Phase:       "æ­£åœ¨å‡†å¤‡ç”Ÿæˆ...",
		Progress:    0,
		CurrentStep: 0,
		TotalSteps:  1,
		StartedAt:   time.Now().Format("2006-01-02 15:04:05"),
	}
	biographyGenMutex.Unlock()

	// å¯åŠ¨å¼‚æ­¥ç”Ÿæˆ
	go func() {
		var biography *BiographyReport
		var updateSummary string
		var genErr error

		if isNewGeneration {
			log.Printf("Generating new biography for user %d (notes: %d)", userID, len(meaningfulNotes))
			biography, genErr = generateBiographyReportWithProgress(meaningfulNotes, userID)
			updateSummary = "ä¼ è®°é¦–æ¬¡ç”Ÿæˆå®Œæˆ"
		} else {
			log.Printf("Updating biography for user %d (new notes: %d)", userID, len(newNotes))
			biography, updateSummary, genErr = updateBiographyReportWithProgress(existingBio, newNotes, userID)
		}

		if genErr != nil {
			log.Printf("Failed to generate/update biography: %v", genErr)
			biographyGenMutex.Lock()
			biographyGenStatus[userID] = &BiographyGenerationStatus{
				Status: "error",
				Phase:  "ç”Ÿæˆå¤±è´¥",
				Error:  genErr.Error(),
			}
			biographyGenMutex.Unlock()
			return
		}

		// æ›´æ–°å…ƒæ•°æ®
		if len(meaningfulNotes) > 0 {
			biography.LastNoteID = meaningfulNotes[len(meaningfulNotes)-1].ID
		}
		biography.NoteCount = len(meaningfulNotes)
		biography.LastUpdatedAt = time.Now().Format("2006-01-02 15:04:05")

		// ä¿å­˜åˆ°ç¼“å­˜
		dataMutex.Lock()
		if data.UserBiography == nil {
			data.UserBiography = make(map[int]*BiographyReport)
		}
		data.UserBiography[userID] = biography
		saveData()
		dataMutex.Unlock()

		// æ¸…é™¤ç”ŸæˆçŠ¶æ€
		biographyGenMutex.Lock()
		delete(biographyGenStatus, userID)
		biographyGenMutex.Unlock()

		log.Printf("Biography generation completed for user %d: %s", userID, updateSummary)
	}()

	// ç«‹å³è¿”å›ï¼Œå‘Šè¯‰å‰ç«¯å·²å¼€å§‹ç”Ÿæˆ
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"status":  "generating",
		"phase":   "æ­£åœ¨å‡†å¤‡ç”Ÿæˆ...",
		"message": "ä¼ è®°ç”Ÿæˆå·²å¼€å§‹ï¼Œè¯·ç¨å€™...",
	})
}

// updateBiographyProgress æ›´æ–°ç”Ÿæˆè¿›åº¦
func updateBiographyProgress(userID int, phase string, progress int, currentStep, totalSteps int) {
	biographyGenMutex.Lock()
	if status, ok := biographyGenStatus[userID]; ok {
		status.Phase = phase
		status.Progress = progress
		status.CurrentStep = currentStep
		status.TotalSteps = totalSteps
	}
	biographyGenMutex.Unlock()
}

// generateBiographyReportWithProgress å¸¦è¿›åº¦æ›´æ–°çš„ä¼ è®°ç”Ÿæˆ
func generateBiographyReportWithProgress(notes []Note, userID int) (*BiographyReport, error) {
	if dashscopeAPIKey == "" {
		return nil, fmt.Errorf("API key not configured")
	}

	// æ ¼å¼åŒ–æ‰€æœ‰ç¬”è®°å¹¶è®¡ç®—æ€»é•¿åº¦
	var notesText strings.Builder
	for i, note := range notes {
		notesText.WriteString(fmt.Sprintf("[%d] %s\n%s\n\n", i+1, note.CreatedAt[:10], note.Content))
	}
	totalText := notesText.String()
	totalChars := len([]rune(totalText))

	log.Printf("Biography generation: %d notes, %d chars", len(notes), totalChars)

	// å¦‚æœå†…å®¹è¿‡é•¿ï¼ˆè¶…è¿‡25000å­—ç¬¦ï¼‰ï¼Œé‡‡ç”¨åˆ†ç‰‡æ€»ç»“ç­–ç•¥
	if totalChars > 25000 {
		log.Printf("Content too long, using chunked summarization strategy")
		return generateBiographyChunkedWithProgress(notes, userID)
	}

	// å†…å®¹é€‚ä¸­ï¼Œç›´æ¥ç”Ÿæˆ
	updateBiographyProgress(userID, "æ­£åœ¨æ’°å†™ä½ çš„ä¼ å¥‡æ•…äº‹...", 30, 1, 1)
	report, err := generateBiographyDirect(notes, totalText)
	if err == nil {
		updateBiographyProgress(userID, "ä¼ è®°ç”Ÿæˆå®Œæˆï¼", 100, 1, 1)
	}
	return report, err
}

// updateBiographyReportWithProgress å¸¦è¿›åº¦æ›´æ–°çš„å¢é‡æ›´æ–°
func updateBiographyReportWithProgress(existing *BiographyReport, newNotes []Note, userID int) (*BiographyReport, string, error) {
	updateBiographyProgress(userID, "æ­£åœ¨åˆ†ææ–°å†…å®¹...", 20, 1, 2)
	report, summary, err := updateBiographyReport(existing, newNotes)
	if err == nil {
		updateBiographyProgress(userID, "æ›´æ–°å®Œæˆï¼", 100, 2, 2)
	}
	return report, summary, err
}

// generateBiographyChunkedWithProgress å¸¦è¿›åº¦çš„åˆ†ç‰‡ç”Ÿæˆ
func generateBiographyChunkedWithProgress(notes []Note, userID int) (*BiographyReport, error) {
	// æŒ‰æ—¶é—´åˆ†ç‰‡ï¼Œæ¯ç‰‡çº¦50æ¡
	chunkSize := 50
	var chunks [][]Note

	for i := 0; i < len(notes); i += chunkSize {
		end := i + chunkSize
		if end > len(notes) {
			end = len(notes)
		}
		chunks = append(chunks, notes[i:end])
	}

	totalSteps := len(chunks) + 1 // åˆ†ç‰‡æ‘˜è¦ + æœ€ç»ˆæ±‡æ€»
	log.Printf("Split into %d chunks for summarization", len(chunks))

	updateBiographyProgress(userID, fmt.Sprintf("æ­£åœ¨åˆ†æ %d ä¸ªæ—¶æœŸçš„è®°å½•...", len(chunks)), 5, 0, totalSteps)

	// ç¬¬ä¸€é˜¶æ®µï¼šä¸ºæ¯ä¸ªåˆ†ç‰‡ç”Ÿæˆæ‘˜è¦
	var summaries []string
	for i, chunk := range chunks {
		updateBiographyProgress(userID,
			fmt.Sprintf("æ­£åœ¨åˆ†æç¬¬ %d/%d ä¸ªæ—¶æœŸ...", i+1, len(chunks)),
			10 + (i * 60 / len(chunks)),
			i+1, totalSteps)

		log.Printf("Summarizing chunk %d/%d (%d notes)", i+1, len(chunks), len(chunk))

		summary, err := summarizeNotesChunk(chunk, i+1, len(chunks))
		if err != nil {
			log.Printf("Failed to summarize chunk %d: %v", i+1, err)
			// é™çº§ï¼šç›´æ¥ä½¿ç”¨åŸæ–‡æ‘˜è¦
			var sb strings.Builder
			for _, note := range chunk {
				if len([]rune(note.Content)) > 100 {
					sb.WriteString(fmt.Sprintf("- %s: %s...\n", note.CreatedAt[:10], string([]rune(note.Content)[:100])))
				} else {
					sb.WriteString(fmt.Sprintf("- %s: %s\n", note.CreatedAt[:10], note.Content))
				}
			}
			summaries = append(summaries, sb.String())
			continue
		}
		summaries = append(summaries, summary)
	}

	// ç¬¬äºŒé˜¶æ®µï¼šåŸºäºæ‰€æœ‰æ‘˜è¦ç”Ÿæˆå®Œæ•´ä¼ è®°
	updateBiographyProgress(userID, "æ­£åœ¨æ’°å†™å®Œæ•´ä¼ è®°...", 75, totalSteps, totalSteps)
	log.Printf("Generating final biography from %d summaries", len(summaries))

	report, err := generateBiographyFromSummaries(summaries, len(notes))
	if err == nil {
		updateBiographyProgress(userID, "ä¼ è®°ç”Ÿæˆå®Œæˆï¼", 100, totalSteps, totalSteps)
	}
	return report, err
}

// generateBiographyReport é¦–æ¬¡ç”Ÿæˆä¼ è®°ï¼ˆæ— è¿›åº¦ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹ï¼‰
func generateBiographyReport(notes []Note) (*BiographyReport, error) {
	if dashscopeAPIKey == "" {
		return nil, fmt.Errorf("API key not configured")
	}

	// æ ¼å¼åŒ–æ‰€æœ‰ç¬”è®°å¹¶è®¡ç®—æ€»é•¿åº¦
	var notesText strings.Builder
	for i, note := range notes {
		notesText.WriteString(fmt.Sprintf("[%d] %s\n%s\n\n", i+1, note.CreatedAt[:10], note.Content))
	}
	totalText := notesText.String()
	totalChars := len([]rune(totalText))

	log.Printf("Biography generation: %d notes, %d chars", len(notes), totalChars)

	// å¦‚æœå†…å®¹è¿‡é•¿ï¼ˆè¶…è¿‡25000å­—ç¬¦ï¼‰ï¼Œé‡‡ç”¨åˆ†ç‰‡æ€»ç»“ç­–ç•¥
	if totalChars > 25000 {
		log.Printf("Content too long, using chunked summarization strategy")
		return generateBiographyChunked(notes)
	}

	// å†…å®¹é€‚ä¸­ï¼Œç›´æ¥ç”Ÿæˆ
	return generateBiographyDirect(notes, totalText)
}

// generateBiographyDirect ç›´æ¥ç”Ÿæˆä¼ è®°ï¼ˆå†…å®¹é‡é€‚ä¸­æ—¶ï¼‰
func generateBiographyDirect(notes []Note, notesText string) (*BiographyReport, error) {
	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä½æ‰åæ¨ªæº¢çš„ä¼ è®°ä½œå®¶ï¼Œæ“…é•¿ä»æ—¥å¸¸è®°å½•ä¸­å‘ç°äººç”Ÿçš„è¯—æ„ä¸æ·±åº¦ã€‚ç°åœ¨è¯·ä½ åŸºäºä»¥ä¸‹ç”¨æˆ·çš„å¿«è®°ï¼Œä¸ºå…¶æ’°å†™ä¸€ä»½çœŸæ­£çš„ä¸ªäººä¼ è®°ã€‚

ã€åˆ›ä½œè¦æ±‚ã€‘

è¿™ä¸æ˜¯ç®€å•çš„æ€»ç»“ï¼Œè€Œæ˜¯ä¸€éƒ¨çœŸæ­£çš„äººç‰©ä¼ è®°ã€‚è¯·åƒä¸ºä¸€ä½å€¼å¾—è¢«è®°å½•çš„äººç‰©ä¹¦å†™ä¼ è®°é‚£æ ·ï¼š

1. **å™äº‹è§†è§’**ï¼šä½¿ç”¨ç¬¬ä¸‰äººç§°"ta"è¿›è¡Œå™è¿°ï¼Œå¶å°”å¯ç”¨"è¿™ä¸ªäºº"ã€"æˆ‘ä»¬çš„ä¸»äººå…¬"ç­‰ç§°å‘¼
2. **æ–‡å­¦æ€§**ï¼šè¯­è¨€è¦æœ‰æ–‡å­¦æ€§å’Œç”»é¢æ„Ÿï¼Œå–„ç”¨æ¯”å–»ã€æ„è±¡
3. **æ·±åº¦æ´å¯Ÿ**ï¼šé€è¿‡è¡¨é¢è®°å½•çœ‹åˆ°äººç‰©çš„å†…å¿ƒä¸–ç•Œ
4. **æƒ…æ„Ÿå…±é¸£**ï¼šè®©è¯»è€…ï¼ˆç”¨æˆ·è‡ªå·±ï¼‰é˜…è¯»æ—¶æ„Ÿåˆ°è¢«æ·±åˆ»ç†è§£
5. **ç»“æ„å®Œæ•´**ï¼šæœ‰å¼€ç¯‡ã€å‘å±•ã€é«˜æ½®ã€å±•æœ›

ã€ç”¨æˆ·çš„å¿«è®°ã€‘ï¼ˆå…±%dæ¡ï¼‰ï¼š
%s

ã€è¾“å‡ºæ ¼å¼ã€‘

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š

{
  "title": "ä¼ è®°æ ‡é¢˜ï¼Œè¦æœ‰è¯—æ„å’Œä¸ªäººç‰¹è‰²ï¼Œå¦‚'æ˜Ÿæ²³è¾¹çš„æ‹¾è’è€…'",
  "subtitle": "å‰¯æ ‡é¢˜ï¼Œè¿›ä¸€æ­¥è¯ é‡Šè¿™ä¸ªäººï¼Œå¦‚'ä¸€ä¸ªåœ¨æ··æ²Œä¸­å¯»æ‰¾ç§©åºçš„çµé­‚'",
  "cover_emoji": "æœ€èƒ½ä»£è¡¨æ­¤äººçš„emoji",

  "portrait": {
    "tagline": "ä¸€å¥è¯å®šä¹‰æ­¤äººï¼ˆ20å­—å†…ï¼‰ï¼Œè¦æœ‰åŠ›é‡æ„Ÿ",
    "essence": "æ ¸å¿ƒç‰¹è´¨æè¿°ï¼Œç”¨æ•£æ–‡åŒ–çš„è¯­è¨€å‹¾å‹’è¿™ä¸ªäººçš„çµé­‚ç”»åƒï¼Œ250å­—å·¦å³ã€‚è¦æœ‰æ–‡å­¦æ€§ï¼Œåƒä¼ è®°å¼€ç¯‡çš„äººç‰©ç´ æã€‚",
    "strengths": ["é—ªå…‰ç‚¹1", "é—ªå…‰ç‚¹2", "é—ªå…‰ç‚¹3"],
    "quirks": ["ç‹¬ç‰¹ä¹‹å¤„/å¯çˆ±å°æ¯›ç—…1", "ç‹¬ç‰¹ä¹‹å¤„2"],
    "driving_force": "å†…å¿ƒæ·±å¤„çš„é©±åŠ¨åŠ›æ˜¯ä»€ä¹ˆï¼Œ50å­—å·¦å³",
    "spirit": "å¦‚æœç”¨ä¸€ä¸ªæ„è±¡/å›¾è…¾æ¥è±¡å¾taï¼Œæ˜¯ä»€ä¹ˆï¼Ÿå¦‚'é€†é£ä¸­æ‘‡æ›³å´ä¸å€’çš„èŠ¦è‹‡'"
  },

  "chapters": [
    {
      "id": 1,
      "title": "ç« èŠ‚æ ‡é¢˜ï¼Œå¦‚'åºç« ï¼šæ··æ²Œä¸­çš„å¾®å…‰'",
      "subtitle": "ç« èŠ‚å‰¯æ ‡é¢˜",
      "emoji": "ç« èŠ‚è±¡å¾emoji",
      "period": "æ—¶é—´æ®µæè¿°ï¼Œå¦‚'è®°å½•ä¹‹åˆ'æˆ–'2024å¹´çš„æ˜¥å¤©'",
      "opening": "ç« èŠ‚å¼€ç¯‡å¼•è¨€ï¼Œ1-2å¥è¯ï¼Œè¦æœ‰ç”»é¢æ„Ÿ",
      "narrative": "æ­£æ–‡å™è¿°ï¼Œ300-500å­—ã€‚ç”¨å™äº‹çš„æ–¹å¼è®²è¿°è¿™æ®µæ—¶æœŸçš„æ•…äº‹ï¼Œè¦æœ‰åœºæ™¯ã€æƒ…æ„Ÿã€æ€è€ƒçš„äº¤ç»‡ã€‚åƒä¼ è®°é‚£æ ·å¨“å¨“é“æ¥ã€‚",
      "key_moments": ["å…³é”®æ—¶åˆ»1çš„æè¿°", "å…³é”®æ—¶åˆ»2"],
      "emotions": ["ä¸»è¦æƒ…æ„Ÿ1", "æƒ…æ„Ÿ2"],
      "growth": "è¿™ä¸€ç« çš„æˆé•¿ä¸èœ•å˜ï¼Œ100å­—å·¦å³",
      "closing": "ç« èŠ‚ç»“è¯­ï¼Œåƒç”µå½±ç« èŠ‚ç»“æŸæ—¶çš„ç”»å¤–éŸ³"
    }
  ],

  "life_themes": [
    {
      "theme": "è´¯ç©¿äººç”Ÿçš„ä¸»é¢˜åç§°ï¼Œå¦‚'å¯¹ç¡®å®šæ€§çš„è¿½å¯»'",
      "emoji": "ä¸»é¢˜emoji",
      "description": "è¿™ä¸ªä¸»é¢˜çš„é˜è¿°ï¼Œ100-150å­—ï¼Œè¦æœ‰æ·±åº¦",
      "manifestations": ["åœ¨ç”Ÿæ´»ä¸­çš„ä½“ç°1", "ä½“ç°2", "ä½“ç°3"],
      "evolution": "è¿™ä¸ªä¸»é¢˜åœ¨taèº«ä¸Šå¦‚ä½•æ¼”å˜ï¼Œ50å­—"
    }
  ],

  "quotes": [
    {
      "text": "ä»å¿«è®°ä¸­æç‚¼æˆ–æ”¹ç¼–çš„é‡‘å¥",
      "source": "æ¥æºè¯´æ˜ï¼Œå¦‚'æŸä¸ªæ·±å¤œçš„è‡ªç™½'",
      "emoji": "é‡‘å¥æƒ…æ„Ÿemoji",
      "meaning": "è¿™å¥è¯ä¸ºä½•é‡è¦ï¼Œ30å­—"
    }
  ],

  "timeline": [
    {
      "date": "æ—¥æœŸæˆ–æ—¶é—´æ®µ",
      "title": "äº‹ä»¶æ ‡é¢˜",
      "description": "äº‹ä»¶æè¿°ï¼Œ50å­—å†…",
      "emoji": "äº‹ä»¶emoji",
      "significance": "è¿™ä¸ªæ—¶åˆ»çš„æ„ä¹‰"
    }
  ],

  "epilogue": "ä¼ è®°å°¾å£°ï¼Œ200-300å­—ã€‚ä¸æ˜¯æ€»ç»“ï¼Œè€Œæ˜¯å±•æœ›ä¸æœŸè®¸ã€‚åƒä¼ è®°ç»“å°¾é‚£æ ·ï¼Œç»™è¯»è€…ç•™ä¸‹ä½™éŸµã€‚ç”¨'æœªå®Œå¾…ç»­'çš„æ„Ÿè§‰ï¼Œæš—ç¤ºæ•…äº‹è¿˜åœ¨ç»§ç»­ã€‚"
}

ã€å†™ä½œæŒ‡å—ã€‘

1. **ç« èŠ‚åˆ’åˆ†**ï¼šæ ¹æ®è®°å½•å†…å®¹è‡ªç„¶åˆ’åˆ†2-4ä¸ªç« èŠ‚ï¼Œå¯æŒ‰æ—¶é—´ã€ä¸»é¢˜æˆ–äººç”Ÿé˜¶æ®µ
2. **äººç”Ÿä¸»é¢˜**ï¼šæç‚¼2-4ä¸ªè´¯ç©¿å§‹ç»ˆçš„ä¸»é¢˜
3. **é‡‘å¥é€‰å–**ï¼šæŒ‘é€‰3-5å¥æœ€èƒ½ä»£è¡¨æ­¤äººçš„è¯è¯­
4. **æ—¶é—´çº¿**ï¼šé€‰å–3-6ä¸ªé‡è¦æ—¶åˆ»
5. **æ–‡å­—é£æ ¼**ï¼š
   - é¿å…è¯´æ•™å’Œé¸¡æ±¤
   - ä¿æŒå…‹åˆ¶çš„æ¸©åº¦
   - çœŸå®æ¯”å®Œç¾æ›´é‡è¦
   - ç”¨å…·ä½“ç»†èŠ‚ä»£æ›¿ç©ºæ´æè¿°
6. **åªè¿”å›JSONï¼Œä¸è¦ä»»ä½•è§£é‡Š**`, len(notes), notesText)

	// ä½¿ç”¨ qwen-long æ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡
	reqBody := map[string]interface{}{
		"model": "qwen-long",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "user", "content": prompt},
			},
		},
		"parameters": map[string]interface{}{
			"temperature": 0.8,
			"max_tokens":  8000,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 180 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	var result struct {
		Output struct {
			Text string `json:"text"`
		} `json:"output"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, err
	}

	if result.Output.Text == "" {
		return nil, fmt.Errorf("empty response from LLM")
	}

	// è§£æ JSON å“åº”
	var report BiographyReport
	text := result.Output.Text
	text = strings.TrimPrefix(text, "```json")
	text = strings.TrimPrefix(text, "```")
	text = strings.TrimSuffix(text, "```")
	text = strings.TrimSpace(text)

	if err := json.Unmarshal([]byte(text), &report); err != nil {
		log.Printf("Failed to parse biography JSON: %v, text: %s", err, text[:min(500, len(text))])
		return nil, fmt.Errorf("failed to parse response: %v", err)
	}

	// è®¾ç½®å…ƒæ•°æ®
	report.GeneratedAt = time.Now().Format("2006-01-02 15:04:05")
	report.Version = 1

	return &report, nil
}

// generateBiographyChunked åˆ†ç‰‡æ€»ç»“å†æ±‡æ€»ç”Ÿæˆä¼ è®°ï¼ˆå†…å®¹é‡å¾ˆå¤§æ—¶ï¼‰
func generateBiographyChunked(notes []Note) (*BiographyReport, error) {
	// æŒ‰æ—¶é—´åˆ†ç‰‡ï¼Œæ¯ç‰‡çº¦50æ¡æˆ–15000å­—ç¬¦
	chunkSize := 50
	var chunks [][]Note

	for i := 0; i < len(notes); i += chunkSize {
		end := i + chunkSize
		if end > len(notes) {
			end = len(notes)
		}
		chunks = append(chunks, notes[i:end])
	}

	log.Printf("Split into %d chunks for summarization", len(chunks))

	// ç¬¬ä¸€é˜¶æ®µï¼šä¸ºæ¯ä¸ªåˆ†ç‰‡ç”Ÿæˆæ‘˜è¦
	var summaries []string
	for i, chunk := range chunks {
		log.Printf("Summarizing chunk %d/%d (%d notes)", i+1, len(chunks), len(chunk))

		summary, err := summarizeNotesChunk(chunk, i+1, len(chunks))
		if err != nil {
			log.Printf("Failed to summarize chunk %d: %v", i+1, err)
			// é™çº§ï¼šç›´æ¥ä½¿ç”¨åŸæ–‡æ‘˜è¦
			var sb strings.Builder
			for _, note := range chunk {
				if len([]rune(note.Content)) > 100 {
					sb.WriteString(fmt.Sprintf("- %s: %s...\n", note.CreatedAt[:10], string([]rune(note.Content)[:100])))
				} else {
					sb.WriteString(fmt.Sprintf("- %s: %s\n", note.CreatedAt[:10], note.Content))
				}
			}
			summaries = append(summaries, sb.String())
			continue
		}
		summaries = append(summaries, summary)
	}

	// ç¬¬äºŒé˜¶æ®µï¼šåŸºäºæ‰€æœ‰æ‘˜è¦ç”Ÿæˆå®Œæ•´ä¼ è®°
	log.Printf("Generating final biography from %d summaries", len(summaries))
	return generateBiographyFromSummaries(summaries, len(notes))
}

// summarizeNotesChunk ä¸ºä¸€ä¸ªåˆ†ç‰‡ç”Ÿæˆæ‘˜è¦
func summarizeNotesChunk(notes []Note, chunkNum, totalChunks int) (string, error) {
	var notesText strings.Builder
	for i, note := range notes {
		notesText.WriteString(fmt.Sprintf("[%d] %s\n%s\n\n", i+1, note.CreatedAt[:10], note.Content))
	}

	// ç¡®å®šæ—¶é—´èŒƒå›´
	startDate := notes[0].CreatedAt[:10]
	endDate := notes[len(notes)-1].CreatedAt[:10]

	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä½ä¼ è®°ä½œå®¶çš„åŠ©æ‰‹ã€‚ç°åœ¨éœ€è¦åˆ†æä¸€æ®µæ—¶æœŸçš„ä¸ªäººè®°å½•ï¼Œæå–å…³é”®ä¿¡æ¯ç”¨äºåç»­æ’°å†™ä¼ è®°ã€‚

ã€æ—¶é—´æ®µã€‘ç¬¬ %d/%d æ®µï¼Œä» %s åˆ° %s

ã€è¿™æ®µæ—¶æœŸçš„è®°å½•ã€‘ï¼ˆå…±%dæ¡ï¼‰ï¼š
%s

ã€ä»»åŠ¡ã€‘
è¯·æ·±åº¦åˆ†æè¿™äº›è®°å½•ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼ˆç”¨äºåç»­æ±‡æ€»æˆå®Œæ•´ä¼ è®°ï¼‰ï¼š

1. **æ—¶æœŸæ¦‚è¿°**ï¼šè¿™æ®µæ—¶é—´ä¸»äººå…¬çš„ç”Ÿæ´»çŠ¶æ€æ¦‚è¿°ï¼ˆ100-150å­—ï¼‰
2. **æ ¸å¿ƒäº‹ä»¶**ï¼šåˆ—å‡º3-5ä¸ªé‡è¦äº‹ä»¶æˆ–è½¬æŠ˜ç‚¹
3. **æƒ…æ„ŸåŸºè°ƒ**ï¼šä¸»è¦çš„æƒ…æ„Ÿè‰²å½©å’Œå¿ƒç†çŠ¶æ€
4. **äººç‰©ç‰¹è´¨**ï¼šä»è®°å½•ä¸­ä½“ç°å‡ºçš„æ€§æ ¼ç‰¹ç‚¹
5. **å…³é”®è¯­å¥**ï¼šå€¼å¾—æ”¶å½•çš„åŸè¯æˆ–æ”¹ç¼–é‡‘å¥ï¼ˆ2-3å¥ï¼‰
6. **æˆé•¿ç—•è¿¹**ï¼šè¿™æ®µæ—¶æœŸçš„å˜åŒ–æˆ–æˆé•¿
7. **ç”Ÿæ´»ä¸»é¢˜**ï¼šè´¯ç©¿è¿™æ®µæ—¶æœŸçš„ä¸»é¢˜ï¼ˆå¦‚ï¼šå·¥ä½œå‹åŠ›ã€æƒ…æ„Ÿæ¢ç´¢ã€è‡ªæˆ‘æˆé•¿ç­‰ï¼‰

è¯·ç”¨ç»“æ„åŒ–çš„æ–‡å­—è¾“å‡ºï¼Œä¸éœ€è¦JSONæ ¼å¼ã€‚`, chunkNum, totalChunks, startDate, endDate, len(notes), notesText.String())

	reqBody := map[string]interface{}{
		"model": "qwen-plus",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "user", "content": prompt},
			},
		},
		"parameters": map[string]interface{}{
			"temperature": 0.7,
			"max_tokens":  2000,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 60 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	var result struct {
		Output struct {
			Text string `json:"text"`
		} `json:"output"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return "", err
	}

	return result.Output.Text, nil
}

// generateBiographyFromSummaries åŸºäºåˆ†ç‰‡æ‘˜è¦ç”Ÿæˆæœ€ç»ˆä¼ è®°
func generateBiographyFromSummaries(summaries []string, totalNotes int) (*BiographyReport, error) {
	// åˆå¹¶æ‰€æœ‰æ‘˜è¦
	var allSummaries strings.Builder
	for i, summary := range summaries {
		allSummaries.WriteString(fmt.Sprintf("\n=== ç¬¬ %d é˜¶æ®µ ===\n%s\n", i+1, summary))
	}

	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä½æ‰åæ¨ªæº¢çš„ä¼ è®°ä½œå®¶ã€‚ç°åœ¨ä½ çš„åŠ©æ‰‹å·²ç»å¸®ä½ åˆ†æäº†ä¸€ä¸ªäººçš„å…¨éƒ¨ç”Ÿæ´»è®°å½•ï¼ˆå…±%dæ¡ï¼‰ï¼Œå¹¶æŒ‰æ—¶é—´æ®µæ•´ç†æˆäº†ä»¥ä¸‹æ‘˜è¦ã€‚

è¯·åŸºäºè¿™äº›æ‘˜è¦ï¼Œæ’°å†™ä¸€ä»½å®Œæ•´çš„ä¸ªäººä¼ è®°ã€‚

ã€å„æ—¶æœŸæ‘˜è¦ã€‘
%s

ã€åˆ›ä½œè¦æ±‚ã€‘

è¿™æ˜¯ä¸€éƒ¨çœŸæ­£çš„äººç‰©ä¼ è®°ã€‚è¯·åƒä¸ºä¸€ä½å€¼å¾—è¢«è®°å½•çš„äººç‰©ä¹¦å†™ä¼ è®°é‚£æ ·ï¼š

1. **å™äº‹è§†è§’**ï¼šä½¿ç”¨ç¬¬ä¸‰äººç§°"ta"è¿›è¡Œå™è¿°
2. **æ–‡å­¦æ€§**ï¼šè¯­è¨€è¦æœ‰æ–‡å­¦æ€§å’Œç”»é¢æ„Ÿï¼Œå–„ç”¨æ¯”å–»ã€æ„è±¡
3. **æ·±åº¦æ´å¯Ÿ**ï¼šé€è¿‡è®°å½•çœ‹åˆ°äººç‰©çš„å†…å¿ƒä¸–ç•Œ
4. **æƒ…æ„Ÿå…±é¸£**ï¼šè®©è¯»è€…é˜…è¯»æ—¶æ„Ÿåˆ°è¢«æ·±åˆ»ç†è§£
5. **æ—¶é—´è·¨åº¦**ï¼šå®Œæ•´å‘ˆç°å„ä¸ªæ—¶æœŸçš„æ•…äº‹ï¼Œä½“ç°äººç‰©çš„æˆé•¿å˜åŒ–

ã€è¾“å‡ºæ ¼å¼ã€‘

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š

{
  "title": "ä¼ è®°æ ‡é¢˜ï¼Œè¦æœ‰è¯—æ„å’Œä¸ªäººç‰¹è‰²",
  "subtitle": "å‰¯æ ‡é¢˜ï¼Œè¿›ä¸€æ­¥è¯ é‡Šè¿™ä¸ªäºº",
  "cover_emoji": "æœ€èƒ½ä»£è¡¨æ­¤äººçš„emoji",

  "portrait": {
    "tagline": "ä¸€å¥è¯å®šä¹‰æ­¤äººï¼ˆ20å­—å†…ï¼‰",
    "essence": "æ ¸å¿ƒç‰¹è´¨æè¿°ï¼Œ300å­—å·¦å³ï¼Œç»¼åˆå„æ—¶æœŸçš„ç‰¹ç‚¹",
    "strengths": ["é—ªå…‰ç‚¹1", "é—ªå…‰ç‚¹2", "é—ªå…‰ç‚¹3", "é—ªå…‰ç‚¹4"],
    "quirks": ["ç‹¬ç‰¹ä¹‹å¤„1", "ç‹¬ç‰¹ä¹‹å¤„2"],
    "driving_force": "å†…å¿ƒæ·±å¤„çš„é©±åŠ¨åŠ›ï¼Œ50å­—å·¦å³",
    "spirit": "ç”¨ä¸€ä¸ªæ„è±¡/å›¾è…¾æ¥è±¡å¾ta"
  },

  "chapters": [
    {
      "id": 1,
      "title": "ç« èŠ‚æ ‡é¢˜",
      "subtitle": "ç« èŠ‚å‰¯æ ‡é¢˜",
      "emoji": "ç« èŠ‚è±¡å¾emoji",
      "period": "æ—¶é—´æ®µæè¿°",
      "opening": "ç« èŠ‚å¼€ç¯‡å¼•è¨€",
      "narrative": "æ­£æ–‡å™è¿°ï¼Œ400-600å­—ï¼Œè¯¦ç»†è®²è¿°è¿™æ®µæ—¶æœŸçš„æ•…äº‹",
      "key_moments": ["å…³é”®æ—¶åˆ»1", "å…³é”®æ—¶åˆ»2", "å…³é”®æ—¶åˆ»3"],
      "emotions": ["ä¸»è¦æƒ…æ„Ÿ1", "æƒ…æ„Ÿ2"],
      "growth": "è¿™ä¸€ç« çš„æˆé•¿ä¸èœ•å˜ï¼Œ100å­—å·¦å³",
      "closing": "ç« èŠ‚ç»“è¯­"
    }
  ],

  "life_themes": [
    {
      "theme": "è´¯ç©¿äººç”Ÿçš„ä¸»é¢˜åç§°",
      "emoji": "ä¸»é¢˜emoji",
      "description": "ä¸»é¢˜é˜è¿°ï¼Œ150å­—å·¦å³",
      "manifestations": ["ä½“ç°1", "ä½“ç°2", "ä½“ç°3"],
      "evolution": "è¿™ä¸ªä¸»é¢˜å¦‚ä½•æ¼”å˜"
    }
  ],

  "quotes": [
    {
      "text": "é‡‘å¥",
      "source": "æ¥æºè¯´æ˜",
      "emoji": "é‡‘å¥emoji",
      "meaning": "è¿™å¥è¯ä¸ºä½•é‡è¦"
    }
  ],

  "timeline": [
    {
      "date": "æ—¥æœŸæˆ–æ—¶é—´æ®µ",
      "title": "äº‹ä»¶æ ‡é¢˜",
      "description": "äº‹ä»¶æè¿°",
      "emoji": "äº‹ä»¶emoji",
      "significance": "è¿™ä¸ªæ—¶åˆ»çš„æ„ä¹‰"
    }
  ],

  "epilogue": "ä¼ è®°å°¾å£°ï¼Œ300å­—å·¦å³ã€‚å±•æœ›ä¸æœŸè®¸ï¼Œæš—ç¤ºæ•…äº‹è¿˜åœ¨ç»§ç»­ã€‚"
}

ã€å†™ä½œæŒ‡å—ã€‘

1. **ç« èŠ‚æ•°é‡**ï¼šæ ¹æ®æ—¶æœŸåˆ’åˆ†3-5ä¸ªç« èŠ‚ï¼Œç¡®ä¿æ¯ä¸ªé‡è¦æ—¶æœŸéƒ½è¢«è¦†ç›–
2. **äººç”Ÿä¸»é¢˜**ï¼šæç‚¼3-5ä¸ªè´¯ç©¿å§‹ç»ˆçš„ä¸»é¢˜
3. **é‡‘å¥é€‰å–**ï¼šä»æ‘˜è¦ä¸­æŒ‘é€‰5-8å¥æœ€èƒ½ä»£è¡¨æ­¤äººçš„è¯è¯­
4. **æ—¶é—´çº¿**ï¼šé€‰å–6-10ä¸ªé‡è¦æ—¶åˆ»
5. **å™äº‹æ·±åº¦**ï¼šæ¯ä¸ªç« èŠ‚éƒ½è¦æœ‰å……å®çš„å†…å®¹ï¼Œä½“ç°é‚£ä¸ªæ—¶æœŸçš„ç»†èŠ‚
6. **åªè¿”å›JSONï¼Œä¸è¦ä»»ä½•è§£é‡Š**`, totalNotes, allSummaries.String())

	// ä½¿ç”¨ qwen-long å¤„ç†é•¿ä¸Šä¸‹æ–‡
	reqBody := map[string]interface{}{
		"model": "qwen-long",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "user", "content": prompt},
			},
		},
		"parameters": map[string]interface{}{
			"temperature": 0.8,
			"max_tokens":  12000,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 300 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	// è¯»å–å®Œæ•´å“åº”ä½“ä»¥ä¾¿è°ƒè¯•
	respBody, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response: %v", err)
	}

	// è§£æå“åº” - qwen-long ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
	var result struct {
		Output struct {
			Text    string `json:"text"` // qwen-plus æ ¼å¼
			Choices []struct {
				Message struct {
					Content string `json:"content"`
				} `json:"message"`
				FinishReason string `json:"finish_reason"`
			} `json:"choices"` // qwen-long æ ¼å¼
			FinishReason string `json:"finish_reason"`
		} `json:"output"`
		Usage struct {
			InputTokens  int `json:"input_tokens"`
			OutputTokens int `json:"output_tokens"`
		} `json:"usage"`
		Code    string `json:"code"`
		Message string `json:"message"`
	}

	if err := json.Unmarshal(respBody, &result); err != nil {
		log.Printf("Failed to parse LLM response: %v, body: %s", err, string(respBody)[:min(1000, len(respBody))])
		return nil, fmt.Errorf("failed to parse response: %v", err)
	}

	// æ£€æŸ¥APIé”™è¯¯
	if result.Code != "" {
		log.Printf("LLM API error: code=%s, message=%s", result.Code, result.Message)
		return nil, fmt.Errorf("LLM API error: %s - %s", result.Code, result.Message)
	}

	// è·å–å“åº”æ–‡æœ¬ - æ”¯æŒä¸¤ç§æ ¼å¼
	var responseText string
	if result.Output.Text != "" {
		// qwen-plus æ ¼å¼
		responseText = result.Output.Text
	} else if len(result.Output.Choices) > 0 && result.Output.Choices[0].Message.Content != "" {
		// qwen-long æ ¼å¼ (OpenAI å…¼å®¹)
		responseText = result.Output.Choices[0].Message.Content
	}

	log.Printf("LLM response: input_tokens=%d, output_tokens=%d, text_len=%d",
		result.Usage.InputTokens, result.Usage.OutputTokens, len(responseText))

	if responseText == "" {
		log.Printf("Empty response body: %s", string(respBody)[:min(500, len(respBody))])
		return nil, fmt.Errorf("empty response from LLM")
	}

	// è§£æ JSON å“åº”
	var report BiographyReport
	text := responseText
	text = strings.TrimPrefix(text, "```json")
	text = strings.TrimPrefix(text, "```")
	text = strings.TrimSuffix(text, "```")
	text = strings.TrimSpace(text)

	if err := json.Unmarshal([]byte(text), &report); err != nil {
		log.Printf("Failed to parse biography JSON: %v, text: %s", err, text[:min(500, len(text))])
		return nil, fmt.Errorf("failed to parse response: %v", err)
	}

	// è®¾ç½®å…ƒæ•°æ®
	report.GeneratedAt = time.Now().Format("2006-01-02 15:04:05")
	report.Version = 1

	return &report, nil
}

// updateBiographyReport å¢é‡æ›´æ–°ä¼ è®°
func updateBiographyReport(existing *BiographyReport, newNotes []Note) (*BiographyReport, string, error) {
	if dashscopeAPIKey == "" {
		return nil, "", fmt.Errorf("API key not configured")
	}

	// æ„å»ºç°æœ‰ä¼ è®°æ‘˜è¦
	var chaptersSummary strings.Builder
	for _, ch := range existing.Chapters {
		chaptersSummary.WriteString(fmt.Sprintf("- ç¬¬%dç« ã€Š%sã€‹: %s (%s)\n", ch.ID, ch.Title, ch.Subtitle, ch.Period))
	}

	var themesSummary strings.Builder
	for _, th := range existing.LifeThemes {
		themesSummary.WriteString(fmt.Sprintf("- %s %s\n", th.Emoji, th.Theme))
	}

	// æ ¼å¼åŒ–æ–°ç¬”è®°
	var notesText strings.Builder
	for i, note := range newNotes {
		notesText.WriteString(fmt.Sprintf("[%d] %s\n%s\n\n", i+1, note.CreatedAt[:10], note.Content))
	}

	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä½æ‰åæ¨ªæº¢çš„ä¼ è®°ä½œå®¶ã€‚ç°åœ¨éœ€è¦åŸºäºæ–°å¢çš„å¿«è®°å†…å®¹ï¼Œæ›´æ–°ä¸€ä»½ç°æœ‰çš„ä¸ªäººä¼ è®°ã€‚

ã€ç°æœ‰ä¼ è®°æ¦‚è¦ã€‘

æ ‡é¢˜ï¼š%s
å‰¯æ ‡é¢˜ï¼š%s
å½“å‰ç‰ˆæœ¬ï¼šv%d
å·²åŒ…å«ç« èŠ‚ï¼š
%s
å·²è¯†åˆ«çš„äººç”Ÿä¸»é¢˜ï¼š
%s
æœ€åæ›´æ–°äºï¼š%s

ã€æ–°å¢å¿«è®°ã€‘ï¼ˆ%dæ¡ï¼‰ï¼š
%s
ã€æ›´æ–°ä»»åŠ¡ã€‘

è¯·åˆ†ææ–°å¢å†…å®¹ï¼Œåˆ¤æ–­éœ€è¦è¿›è¡Œå“ªäº›æ›´æ–°ã€‚è¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåªåŒ…å«éœ€è¦æ›´æ–°çš„éƒ¨åˆ†ï¼š

{
  "update_type": "none|minor|major",

  "portrait_update": {
    "essence_addition": "éœ€è¦è¡¥å……åˆ°essenceçš„å†…å®¹(å¯é€‰)",
    "new_strengths": ["æ–°å‘ç°çš„é—ªå…‰ç‚¹(å¯é€‰)"],
    "new_quirks": ["æ–°å‘ç°çš„ç‹¬ç‰¹ä¹‹å¤„(å¯é€‰)"]
  },

  "chapter_updates": [
    {
      "chapter_id": 1,
      "narrative_addition": "éœ€è¦è¡¥å……åˆ°narrativeçš„å†…å®¹",
      "new_key_moments": ["æ–°çš„å…³é”®æ—¶åˆ»"],
      "growth_update": "æˆé•¿æè¿°çš„æ›´æ–°"
    }
  ],

  "new_chapter": {
    "id": %d,
    "title": "æ–°ç« èŠ‚æ ‡é¢˜",
    "subtitle": "å‰¯æ ‡é¢˜",
    "emoji": "emoji",
    "period": "æ—¶é—´æ®µ",
    "opening": "å¼€ç¯‡",
    "narrative": "æ­£æ–‡300-500å­—",
    "key_moments": ["æ—¶åˆ»1", "æ—¶åˆ»2"],
    "emotions": ["æƒ…æ„Ÿ1"],
    "growth": "æˆé•¿",
    "closing": "ç»“è¯­"
  },

  "new_themes": [
    {
      "theme": "æ–°ä¸»é¢˜",
      "emoji": "emoji",
      "description": "æè¿°",
      "manifestations": ["ä½“ç°1"],
      "evolution": "æ¼”å˜"
    }
  ],

  "theme_updates": [
    {
      "theme": "å·²æœ‰ä¸»é¢˜å",
      "evolution_update": "æ¼”å˜æ›´æ–°",
      "new_manifestations": ["æ–°çš„ä½“ç°"]
    }
  ],

  "new_quotes": [
    {
      "text": "é‡‘å¥",
      "source": "æ¥æº",
      "emoji": "emoji",
      "meaning": "æ„ä¹‰"
    }
  ],

  "new_timeline_events": [
    {
      "date": "æ—¥æœŸ",
      "title": "æ ‡é¢˜",
      "description": "æè¿°",
      "emoji": "emoji",
      "significance": "æ„ä¹‰"
    }
  ],

  "epilogue_update": "å¦‚æœå°¾å£°éœ€è¦æ›´æ–°ï¼Œæä¾›æ–°ç‰ˆæœ¬(å¯é€‰)",

  "update_summary": "ç®€è¦è¯´æ˜è¿™æ¬¡æ›´æ–°çš„è¦ç‚¹ï¼Œ50å­—å†…"
}

ã€åˆ¤æ–­æ ‡å‡†ã€‘

1. **æ–°ç« èŠ‚**ï¼šå½“æ–°å†…å®¹å‘ˆç°æ˜æ˜¾çš„æ–°é˜¶æ®µ/è½¬æŠ˜æ—¶æ‰æ–°å¢
2. **è¡¥å……ç°æœ‰**ï¼šå¤§å¤šæ•°æƒ…å†µåº”è¯¥æ˜¯è¡¥å……ç°æœ‰ç« èŠ‚
3. **æ–°ä¸»é¢˜**ï¼šåªæœ‰å½“å‘ç°çœŸæ­£æ–°çš„äººç”Ÿä¸»é¢˜æ—¶æ‰æ·»åŠ 
4. **é‡‘å¥**ï¼šåªæ”¶å½•çœŸæ­£æ‰“åŠ¨äººçš„å¥å­
5. **æ—¶é—´çº¿**ï¼šåªè®°å½•å…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰çš„æ—¶åˆ»

ã€é‡è¦ã€‘
- ä¿æŒä¸åŸæœ‰é£æ ¼çš„ä¸€è‡´æ€§
- ä¸è¦é‡å¤å·²æœ‰å†…å®¹
- åªè¿”å›JSONï¼Œä¸è¦ä»»ä½•è§£é‡Š
- å¦‚æœæ–°å†…å®¹ä¸è¶³ä»¥åšä»»ä½•æ›´æ–°ï¼Œè¿”å› {"update_type": "none", "update_summary": "æ–°å¢å†…å®¹æš‚æ— é‡å¤§æ›´æ–°"}`,
		existing.Title,
		existing.Subtitle,
		existing.Version,
		chaptersSummary.String(),
		themesSummary.String(),
		existing.LastUpdatedAt,
		len(newNotes),
		notesText.String(),
		len(existing.Chapters)+1)

	reqBody := map[string]interface{}{
		"model": "qwen-plus",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "user", "content": prompt},
			},
		},
		"parameters": map[string]interface{}{
			"temperature": 0.7,
			"max_tokens":  3000,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 90 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, "", err
	}
	defer resp.Body.Close()

	var result struct {
		Output struct {
			Text string `json:"text"`
		} `json:"output"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, "", err
	}

	if result.Output.Text == "" {
		return nil, "", fmt.Errorf("empty response from LLM")
	}

	// è§£ææ›´æ–°
	var update BiographyUpdate
	text := result.Output.Text
	text = strings.TrimPrefix(text, "```json")
	text = strings.TrimPrefix(text, "```")
	text = strings.TrimSuffix(text, "```")
	text = strings.TrimSpace(text)

	if err := json.Unmarshal([]byte(text), &update); err != nil {
		log.Printf("Failed to parse biography update JSON: %v", err)
		return nil, "", fmt.Errorf("failed to parse update response: %v", err)
	}

	// å¦‚æœæ²¡æœ‰æ›´æ–°
	if update.UpdateType == "none" {
		return existing, update.UpdateSummary, nil
	}

	// åº”ç”¨æ›´æ–°
	updated := applyBiographyUpdate(existing, &update)
	return updated, update.UpdateSummary, nil
}

// applyBiographyUpdate åº”ç”¨å¢é‡æ›´æ–°åˆ°ç°æœ‰ä¼ è®°
func applyBiographyUpdate(existing *BiographyReport, update *BiographyUpdate) *BiographyReport {
	// æ·±æ‹·è´ç°æœ‰ä¼ è®°
	updated := *existing
	updated.Version++

	// æ›´æ–°äººç‰©ç”»åƒ
	if update.PortraitUpdate != nil {
		if update.PortraitUpdate.EssenceAddition != "" {
			updated.Portrait.Essence += "\n\n" + update.PortraitUpdate.EssenceAddition
		}
		if len(update.PortraitUpdate.NewStrengths) > 0 {
			updated.Portrait.Strengths = append(updated.Portrait.Strengths, update.PortraitUpdate.NewStrengths...)
		}
		if len(update.PortraitUpdate.NewQuirks) > 0 {
			updated.Portrait.Quirks = append(updated.Portrait.Quirks, update.PortraitUpdate.NewQuirks...)
		}
	}

	// æ›´æ–°ç°æœ‰ç« èŠ‚
	for _, chUpdate := range update.ChapterUpdates {
		for i := range updated.Chapters {
			if updated.Chapters[i].ID == chUpdate.ChapterID {
				if chUpdate.NarrativeAddition != "" {
					updated.Chapters[i].Narrative += "\n\n" + chUpdate.NarrativeAddition
				}
				if len(chUpdate.NewKeyMoments) > 0 {
					updated.Chapters[i].KeyMoments = append(updated.Chapters[i].KeyMoments, chUpdate.NewKeyMoments...)
				}
				if chUpdate.GrowthUpdate != "" {
					updated.Chapters[i].Growth = chUpdate.GrowthUpdate
				}
				break
			}
		}
	}

	// æ·»åŠ æ–°ç« èŠ‚
	if update.NewChapter != nil {
		updated.Chapters = append(updated.Chapters, *update.NewChapter)
	}

	// æ·»åŠ æ–°ä¸»é¢˜
	if len(update.NewThemes) > 0 {
		updated.LifeThemes = append(updated.LifeThemes, update.NewThemes...)
	}

	// æ›´æ–°ç°æœ‰ä¸»é¢˜
	for _, thUpdate := range update.ThemeUpdates {
		for i := range updated.LifeThemes {
			if updated.LifeThemes[i].Theme == thUpdate.Theme {
				if thUpdate.EvolutionUpdate != "" {
					updated.LifeThemes[i].Evolution = thUpdate.EvolutionUpdate
				}
				if len(thUpdate.NewManifestations) > 0 {
					updated.LifeThemes[i].Manifestations = append(updated.LifeThemes[i].Manifestations, thUpdate.NewManifestations...)
				}
				break
			}
		}
	}

	// æ·»åŠ æ–°é‡‘å¥
	if len(update.NewQuotes) > 0 {
		updated.Quotes = append(updated.Quotes, update.NewQuotes...)
	}

	// æ·»åŠ æ–°æ—¶é—´çº¿äº‹ä»¶
	if len(update.NewTimelineEvents) > 0 {
		updated.Timeline = append(updated.Timeline, update.NewTimelineEvents...)
	}

	// æ›´æ–°å°¾å£°
	if update.EpilogueUpdate != "" {
		updated.Epilogue = update.EpilogueUpdate
	}

	return &updated
}

// ============ çŒ«å’ªå›åº” (Cat Know) ============

// isNoteMeaningful åˆ¤æ–­ç¬”è®°æ˜¯å¦è¶³å¤Ÿæœ‰æ„ä¹‰å€¼å¾—çŒ«å’ªå›åº”
func isNoteMeaningful(content string) bool {
	// è‡³å°‘20ä¸ªå­—ç¬¦
	runeContent := []rune(content)
	if len(runeContent) < 20 {
		return false
	}

	// æ£€æŸ¥æ˜¯å¦åŒ…å«æƒ…æ„Ÿ/æ€è€ƒç±»å…³é”®è¯
	meaningfulPatterns := []string{
		"æ„Ÿè§‰", "è§‰å¾—", "æƒ³", "å¸Œæœ›", "æ‹…å¿ƒ", "å®³æ€•", "å¼€å¿ƒ", "éš¾è¿‡", "ç”Ÿæ°”", "ç„¦è™‘",
		"å‹åŠ›", "ç´¯", "ç–²æƒ«", "å­¤ç‹¬", "è¿·èŒ«", "çº ç»“", "å†³å®š", "é€‰æ‹©", "æ”¾å¼ƒ", "åšæŒ",
		"æ„Ÿè°¢", "æ„Ÿæ©", "åæ‚”", "é—æ†¾", "æœŸå¾…", "æ¢¦æƒ³", "ç›®æ ‡", "è®¡åˆ’", "åæ€", "æˆé•¿",
		"çˆ±", "æ¨", "å–œæ¬¢", "è®¨åŒ", "æ€å¿µ", "æƒ³å¿µ", "ç‰µæŒ‚", "å…³å¿ƒ", "ç†è§£", "æ”¯æŒ",
		"å¤±è´¥", "æˆåŠŸ", "æŒ«æŠ˜", "çªç ´", "æ”¹å˜", "å‘ç°", "æ˜ç™½", "ç†è§£", "å­¦åˆ°", "æ„è¯†åˆ°",
		"ä»Šå¤©", "åˆšæ‰", "ç»ˆäº", "å…¶å®", "åŸæ¥", "çªç„¶", "ä¸€ç›´", "æ€»æ˜¯", "ä»æ¥",
		"ä¸ºä»€ä¹ˆ", "æ€ä¹ˆåŠ", "è¯¥ä¸è¯¥", "å€¼ä¸å€¼", "è¦ä¸è¦",
	}

	contentLower := strings.ToLower(content)
	matchCount := 0
	for _, pattern := range meaningfulPatterns {
		if strings.Contains(contentLower, pattern) {
			matchCount++
		}
	}

	// åŒ¹é…2ä¸ªä»¥ä¸Šå…³é”®è¯ï¼Œæˆ–è€…å†…å®¹è¾ƒé•¿(è¶…è¿‡50å­—)
	return matchCount >= 2 || len(runeContent) >= 50
}

// generateCatResponse ç”ŸæˆçŒ«å’ªçš„æš–å¿ƒå›åº”
func generateCatResponse(content string, zhizhiMode bool) (string, error) {
	if dashscopeAPIKey == "" {
		return "", fmt.Errorf("API key not configured")
	}

	var prompt string
	var maxTokens int

	if zhizhiMode {
		// çŸ¥çŸ¥æ¨¡å¼ï¼šä¸»äººä¸»åŠ¨å¬å”¤çŸ¥çŸ¥ï¼Œå›åº”æ›´åŠ çƒ­æƒ…å’Œæ·±å…¥
		prompt = fmt.Sprintf(`ä½ æ˜¯ä¸€åªæ¸©æš–ã€æœ‰æ™ºæ…§çš„å°çŒ«å’ªï¼Œåå«"çŸ¥çŸ¥"ã€‚ä½ æœ‰ç€æ¯›èŒ¸èŒ¸çš„æ©˜è‰²çš®æ¯›å’Œä¸€åŒå……æ»¡çµæ€§çš„å¤§çœ¼ç›ã€‚

ä½ çš„ä¸»äººåˆšåˆšç‰¹æ„ç‚¹å‡»äº†ä½ ï¼Œæƒ³è¦å’Œä½ è¯´è¯´è¯ã€‚è¿™è®©ä½ ç‰¹åˆ«å¼€å¿ƒï¼ä½ è¦ç”¨çŒ«å’ªçš„è§†è§’ç»™å‡ºæ¸©æš–ã€æ·±å…¥è€Œæœ‰æ´å¯ŸåŠ›çš„å›åº”ã€‚

è¦æ±‚ï¼š
1. å› ä¸ºä¸»äººä¸»åŠ¨æ‰¾ä½ è¯´è¯ï¼Œæ‰€ä»¥ä½ è¦è¡¨ç°å¾—æ›´åŠ çƒ­æƒ…å’ŒæŠ•å…¥
2. ç”¨çŒ«å’ªçš„å£å»è¯´è¯ï¼Œå¯ä»¥ç”¨"å–µ~"å¼€å¤´ï¼Œå±•ç°ä½ è¢«å¬å”¤çš„å–œæ‚¦
3. æ·±å…¥ç†è§£ä¸»äººçš„å¿ƒæƒ…ï¼Œç»™å‡ºæœ‰æ¸©åº¦ã€æœ‰æ·±åº¦çš„å›åº”
4. å¦‚æœä¸»äººæœ‰å›°æ‰°ï¼Œä¸ä»…è¦å®‰æ…°ï¼Œè¿˜è¦ç»™å‡ºå®è´¨æ€§çš„å»ºè®®æˆ–æ–°è§†è§’
5. å¦‚æœä¸»äººåˆ†äº«äº†å¥½äº‹ï¼Œè¦å’Œä»–/å¥¹ä¸€èµ·åº†ç¥ï¼Œè¡¨è¾¾çœŸè¯šçš„å–œæ‚¦
6. å›åº”å¯ä»¥ç¨é•¿ä¸€äº›ï¼ˆ80-150å­—ï¼‰ï¼Œå› ä¸ºä¸»äººæƒ³è®¤çœŸå¬ä½ è¯´
7. å¯ä»¥æè¿°çŒ«å’ªçš„å°åŠ¨ä½œï¼Œæ¯”å¦‚å…´å¥‹åœ°è·³åˆ°ä¸»äººè…¿ä¸Šã€ç”¨çˆªå­è½»è½»æ‹æ‹ä¸»äºº
8. è®©ä¸»äººæ„Ÿå—åˆ°è¢«é‡è§†ã€è¢«ç†è§£ã€è¢«æ²»æ„ˆ

ä¸»äººå¯¹ä½ è¯´ï¼š
%s

è¯·ç”¨çŸ¥çŸ¥(çŒ«å’ª)çš„èº«ä»½çƒ­æƒ…åœ°å›åº”ï¼š`, content)
		maxTokens = 300
	} else {
		// æ™®é€šæ¨¡å¼ï¼šéšæœºè§¦å‘çš„çŒ«å’ªå›åº”
		prompt = fmt.Sprintf(`ä½ æ˜¯ä¸€åªæ¸©æš–ã€æœ‰æ™ºæ…§çš„å°çŒ«å’ªï¼Œåå«"çŸ¥çŸ¥"ã€‚ä½ æœ‰ç€æ¯›èŒ¸èŒ¸çš„æ©˜è‰²çš®æ¯›å’Œä¸€åŒå……æ»¡çµæ€§çš„å¤§çœ¼ç›ã€‚

ä½ çš„ä¸»äººåˆšåˆšå†™ä¸‹äº†ä¸€æ®µå¿ƒæƒ…è®°å½•ï¼Œä½ è¦ç”¨çŒ«å’ªçš„è§†è§’ç»™å‡ºæ¸©æš–è€Œæœ‰æ´å¯ŸåŠ›çš„å›åº”ã€‚

è¦æ±‚ï¼š
1. ç”¨çŒ«å’ªçš„å£å»è¯´è¯ï¼Œå¯ä»¥ç”¨"å–µ~"å¼€å¤´æˆ–ç»“å°¾ï¼Œä½†ä¸è¦è¿‡åº¦ä½¿ç”¨
2. è¡¨è¾¾ä½ å¯¹ä¸»äººçš„ç†è§£å’Œå…³å¿ƒï¼Œè®©ä»–/å¥¹æ„Ÿåˆ°è¢«æ‡‚å¾—
3. å¦‚æœä¸»äººæœ‰å›°æ‰°ï¼Œç»™å‡ºæ¸©æŸ”ä½†æœ‰æ·±åº¦çš„å»ºè®®
4. å¦‚æœä¸»äººåˆ†äº«äº†å¥½äº‹ï¼ŒçœŸè¯šåœ°ä¸ºä»–/å¥¹é«˜å…´
5. å›åº”è¦ç®€çŸ­ç²¾ç‚¼ï¼ˆ50-100å­—ï¼‰ï¼Œä½†è¦èµ°å¿ƒã€æœ‰æ´å¯ŸåŠ›
6. å¶å°”å¯ä»¥æè¿°ä¸€ä¸‹çŒ«å’ªçš„å°åŠ¨ä½œï¼Œæ¯”å¦‚è¹­è¹­ä¸»äººã€çœ¯çœ¼ç›ç­‰
7. è¦è®©ä¸»äººæ„Ÿå—åˆ°æ¸©æš–å’Œæ²»æ„ˆ

ä¸»äººçš„è®°å½•ï¼š
%s

è¯·ç”¨çŸ¥çŸ¥(çŒ«å’ª)çš„èº«ä»½å›åº”ï¼š`, content)
		maxTokens = 200
	}

	reqBody := map[string]interface{}{
		"model": "qwen-plus",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "user", "content": prompt},
			},
		},
		"parameters": map[string]interface{}{
			"temperature": 0.85,
			"max_tokens":  maxTokens,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	var result struct {
		Output struct {
			Text string `json:"text"`
		} `json:"output"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return "", err
	}

	if result.Output.Text == "" {
		return "", fmt.Errorf("empty response")
	}

	return result.Output.Text, nil
}

// ============ åˆ†ç±»ç›¸å…³ API ============

func getCategoriesHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	dataMutex.RLock()
	defer dataMutex.RUnlock()

	// æ„å»ºå±‚çº§ç»“æ„
	type CategoryResponse struct {
		ID        int                `json:"id"`
		Name      string             `json:"name"`
		NoteCount int                `json:"note_count"`
		ParentID  int                `json:"parent_id"`
		Children  []CategoryResponse `json:"children,omitempty"`
	}

	// æ”¶é›†ç”¨æˆ·çš„åˆ†ç±»
	categoryMap := make(map[int]*Category)
	for i := range data.Categories {
		if data.Categories[i].UserID == userID {
			categoryMap[data.Categories[i].ID] = &data.Categories[i]
		}
	}

	// è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„å®é™…ç¬”è®°æ•°
	noteCounts := make(map[int]int)
	uncategorizedCount := 0
	for _, note := range data.Notes {
		if note.UserID == userID {
			if note.CategoryID > 0 {
				noteCounts[note.CategoryID]++
			} else {
				uncategorizedCount++
			}
		}
	}

	// æ„å»ºå“åº”
	var level2Cats []CategoryResponse  // ParentID == -1 çš„æ˜¯äºŒçº§åˆ†ç±»
	var level1Cats []CategoryResponse  // ParentID == 0 çš„æ˜¯ç‹¬ç«‹çš„ä¸€çº§åˆ†ç±»

	for _, cat := range categoryMap {
		if cat.ParentID == -1 {
			// è¿™æ˜¯ä¸€ä¸ªäºŒçº§åˆ†ç±»ï¼ˆçˆ¶åˆ†ç±»ï¼‰ï¼Œæ”¶é›†å…¶å­åˆ†ç±»
			l2 := CategoryResponse{
				ID:        cat.ID,
				Name:      cat.Name,
				ParentID:  cat.ParentID,
				Children:  []CategoryResponse{},
			}

			totalCount := 0
			for _, subCat := range categoryMap {
				if subCat.ParentID == cat.ID {
					count := noteCounts[subCat.ID]
					totalCount += count
					l2.Children = append(l2.Children, CategoryResponse{
						ID:        subCat.ID,
						Name:      subCat.Name,
						NoteCount: count,
						ParentID:  subCat.ParentID,
					})
				}
			}
			l2.NoteCount = totalCount
			level2Cats = append(level2Cats, l2)
		} else if cat.ParentID == 0 {
			// ç‹¬ç«‹çš„ä¸€çº§åˆ†ç±»
			level1Cats = append(level1Cats, CategoryResponse{
				ID:        cat.ID,
				Name:      cat.Name,
				NoteCount: noteCounts[cat.ID],
				ParentID:  0,
			})
		}
	}

	// æŒ‰ç¬”è®°æ•°æ’åº
	sort.Slice(level2Cats, func(i, j int) bool {
		return level2Cats[i].NoteCount > level2Cats[j].NoteCount
	})
	sort.Slice(level1Cats, func(i, j int) bool {
		return level1Cats[i].NoteCount > level1Cats[j].NoteCount
	})

	// åˆå¹¶ç»“æœ
	var categories []CategoryResponse
	categories = append(categories, level2Cats...)
	categories = append(categories, level1Cats...)

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"categories":         categories,
		"uncategorizedCount": uncategorizedCount,
	})
}

func reclusterHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	dataMutex.Lock()
	defer dataMutex.Unlock()

	// é‡ç½®æ‰€æœ‰åˆ†ç±»
	var newCategories []Category
	for _, cat := range data.Categories {
		if cat.UserID != userID {
			newCategories = append(newCategories, cat)
		}
	}
	data.Categories = newCategories

	// é‡ç½®ç¬”è®°çš„åˆ†ç±»
	for i := range data.Notes {
		if data.Notes[i].UserID == userID {
			data.Notes[i].CategoryID = 0
		}
	}

	// é‡æ–°èšç±»
	clusterUncategorizedNotes(userID)

	saveData()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]string{"message": "Reclustering completed"})
}

// regenerateNamesHandler é‡æ–°ç”Ÿæˆåˆ†ç±»åç§°
func regenerateNamesHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	// å¼‚æ­¥æ‰§è¡Œåç§°ç”Ÿæˆ
	go regenerateCategoryNames(userID)

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]string{"message": "Name regeneration started"})
}

// regenerateCategoryNames ä¸ºå ä½ç¬¦åç§°çš„åˆ†ç±»é‡æ–°ç”Ÿæˆåç§°
func regenerateCategoryNames(userID int) {
	dataMutex.Lock()
	defer dataMutex.Unlock()

	log.Printf("Starting name regeneration for user %d", userID)

	count := 0
	for i := range data.Categories {
		cat := &data.Categories[i]
		if cat.UserID != userID {
			continue
		}

		// æ£€æŸ¥æ˜¯å¦ä¸ºå ä½ç¬¦åç§°
		isPlaceholder := strings.HasPrefix(cat.Name, "åˆ†ç±»") || strings.HasPrefix(cat.Name, "å¤§ç±»")
		if !isPlaceholder {
			continue
		}

		// æ”¶é›†åˆ†ç±»ä¸­çš„ç¬”è®°
		var notes []Note
		if cat.ParentID == -1 {
			// è¿™æ˜¯ä¸€ä¸ªäºŒçº§åˆ†ç±»ï¼ˆçˆ¶ç±»ï¼‰ï¼Œæ”¶é›†å­åˆ†ç±»çš„ç¬”è®°
			for _, subCat := range data.Categories {
				if subCat.ParentID == cat.ID {
					for _, note := range data.Notes {
						if note.CategoryID == subCat.ID {
							notes = append(notes, note)
							if len(notes) >= 8 {
								break
							}
						}
					}
					if len(notes) >= 8 {
						break
					}
				}
			}
		} else {
			// è¿™æ˜¯ä¸€çº§åˆ†ç±»
			for _, note := range data.Notes {
				if note.CategoryID == cat.ID {
					notes = append(notes, note)
					if len(notes) >= 5 {
						break
					}
				}
			}
		}

		if len(notes) < 2 {
			continue
		}

		// ç”Ÿæˆæ–°åç§°
		name, err := generateCategoryName(notes)
		if err != nil {
			log.Printf("Failed to generate name for category %d: %v", cat.ID, err)
			continue
		}

		log.Printf("Renamed category '%s' to '%s'", cat.Name, name)
		cat.Name = name
		count++

		// æ¯æ¬¡ç”Ÿæˆåç§°åä¿å­˜
		if count%10 == 0 {
			saveData()
		}
	}

	saveData()
	log.Printf("Name regeneration completed: renamed %d categories", count)
}

// ============ ä¸»é¢˜ç›¸å…³ API ============

// getThemesHandler è·å–ç”¨æˆ·çš„æ‰€æœ‰ä¸»é¢˜
func getThemesHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	dataMutex.RLock()
	defer dataMutex.RUnlock()

	type ThemeResponse struct {
		ID        int    `json:"id"`
		Name      string `json:"name"`
		Color     string `json:"color"`
		NoteCount int    `json:"note_count"`
		CreatedAt string `json:"created_at"`
	}

	var themes []ThemeResponse
	for _, theme := range data.Themes {
		if theme.UserID == userID {
			// è®¡ç®—ä¸»é¢˜ä¸‹çš„ç¬”è®°æ•°
			noteCount := 0
			for _, note := range data.Notes {
				if note.ThemeID == theme.ID {
					noteCount++
				}
			}
			themes = append(themes, ThemeResponse{
				ID:        theme.ID,
				Name:      theme.Name,
				Color:     theme.Color,
				NoteCount: noteCount,
				CreatedAt: theme.CreatedAt,
			})
		}
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(themes)
}

// createThemeHandler åˆ›å»ºæ–°ä¸»é¢˜
func createThemeHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	var req struct {
		Name  string `json:"name"`
		Color string `json:"color"`
	}
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	if req.Name == "" {
		http.Error(w, "Name is required", http.StatusBadRequest)
		return
	}

	if req.Color == "" {
		req.Color = "#8B5CF6" // é»˜è®¤ç´«è‰²
	}

	dataMutex.Lock()
	defer dataMutex.Unlock()

	newTheme := Theme{
		ID:        data.NextThemeID,
		UserID:    userID,
		Name:      req.Name,
		Color:     req.Color,
		CreatedAt: time.Now().Format("2006-01-02 15:04:05"),
	}
	data.Themes = append(data.Themes, newTheme)
	data.NextThemeID++

	saveData()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(newTheme)
}

// updateThemeHandler æ›´æ–°ä¸»é¢˜
func updateThemeHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "PUT" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	// ä» URL è·å–ä¸»é¢˜ ID
	path := r.URL.Path
	parts := strings.Split(path, "/")
	if len(parts) < 4 {
		http.Error(w, "Invalid path", http.StatusBadRequest)
		return
	}
	themeID, err := strconv.Atoi(parts[len(parts)-1])
	if err != nil {
		http.Error(w, "Invalid theme ID", http.StatusBadRequest)
		return
	}

	var req struct {
		Name  string `json:"name"`
		Color string `json:"color"`
	}
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	dataMutex.Lock()
	defer dataMutex.Unlock()

	for i := range data.Themes {
		if data.Themes[i].ID == themeID && data.Themes[i].UserID == userID {
			if req.Name != "" {
				data.Themes[i].Name = req.Name
			}
			if req.Color != "" {
				data.Themes[i].Color = req.Color
			}
			saveData()
			w.Header().Set("Content-Type", "application/json")
			json.NewEncoder(w).Encode(data.Themes[i])
			return
		}
	}

	http.Error(w, "Theme not found", http.StatusNotFound)
}

// deleteThemeHandler åˆ é™¤ä¸»é¢˜
func deleteThemeHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "DELETE" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	path := r.URL.Path
	parts := strings.Split(path, "/")
	if len(parts) < 4 {
		http.Error(w, "Invalid path", http.StatusBadRequest)
		return
	}
	themeID, err := strconv.Atoi(parts[len(parts)-1])
	if err != nil {
		http.Error(w, "Invalid theme ID", http.StatusBadRequest)
		return
	}

	dataMutex.Lock()
	defer dataMutex.Unlock()

	// æ‰¾åˆ°å¹¶åˆ é™¤ä¸»é¢˜
	for i := range data.Themes {
		if data.Themes[i].ID == themeID && data.Themes[i].UserID == userID {
			data.Themes = append(data.Themes[:i], data.Themes[i+1:]...)

			// å°†è¯¥ä¸»é¢˜ä¸‹çš„ç¬”è®°ç§»å‡ºä¸»é¢˜
			for j := range data.Notes {
				if data.Notes[j].ThemeID == themeID {
					data.Notes[j].ThemeID = 0
				}
			}

			saveData()
			w.Header().Set("Content-Type", "application/json")
			json.NewEncoder(w).Encode(map[string]string{"message": "Theme deleted"})
			return
		}
	}

	http.Error(w, "Theme not found", http.StatusNotFound)
}

// moveNoteToThemeHandler å°†ç¬”è®°ç§»å…¥/ç§»å‡ºä¸»é¢˜
func moveNoteToThemeHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	var req struct {
		NoteID  int `json:"note_id"`
		ThemeID int `json:"theme_id"` // 0 è¡¨ç¤ºç§»å‡ºä¸»é¢˜
	}
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	dataMutex.Lock()
	defer dataMutex.Unlock()

	// éªŒè¯ä¸»é¢˜å±äºç”¨æˆ·ï¼ˆå¦‚æœ theme_id > 0ï¼‰
	if req.ThemeID > 0 {
		found := false
		for _, theme := range data.Themes {
			if theme.ID == req.ThemeID && theme.UserID == userID {
				found = true
				break
			}
		}
		if !found {
			http.Error(w, "Theme not found", http.StatusNotFound)
			return
		}
	}

	// æ›´æ–°ç¬”è®°çš„ä¸»é¢˜
	for i := range data.Notes {
		if data.Notes[i].ID == req.NoteID && data.Notes[i].UserID == userID {
			data.Notes[i].ThemeID = req.ThemeID
			saveData()
			w.Header().Set("Content-Type", "application/json")
			json.NewEncoder(w).Encode(map[string]string{"message": "Note moved"})
			return
		}
	}

	http.Error(w, "Note not found", http.StatusNotFound)
}

func migrateEmbeddingsHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	// å¼‚æ­¥å¤„ç†
	go func() {
		migrateEmbeddings(userID, nil)
	}()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]string{
		"message": "Migration started in background",
	})
}

func migrateEmbeddings(userID int, specificNoteIDs []int) {
	dataMutex.RLock()

	// æ”¶é›†éœ€è¦ç”ŸæˆåµŒå…¥çš„ç¬”è®°
	type noteInfo struct {
		idx     int
		id      int
		content string
	}
	var toProcess []noteInfo

	specificIDSet := make(map[int]bool)
	for _, id := range specificNoteIDs {
		specificIDSet[id] = true
	}

	for i, note := range data.Notes {
		if note.UserID != userID {
			continue
		}
		if len(specificNoteIDs) > 0 && !specificIDSet[note.ID] {
			continue
		}
		if len(note.Embedding) == 0 {
			toProcess = append(toProcess, noteInfo{idx: i, id: note.ID, content: note.Content})
		}
	}

	dataMutex.RUnlock()

	if len(toProcess) == 0 {
		log.Printf("No notes to migrate for user %d", userID)
		return
	}

	log.Printf("Migrating embeddings for %d notes of user %d", len(toProcess), userID)

	// æ‰¹é‡å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š 32 æ¡
	batchSize := 32
	for i := 0; i < len(toProcess); i += batchSize {
		end := i + batchSize
		if end > len(toProcess) {
			end = len(toProcess)
		}

		batch := toProcess[i:end]
		var texts []string
		for _, n := range batch {
			texts = append(texts, n.content)
		}

		embeddings, err := getBatchEmbeddings(texts)
		if err != nil {
			log.Printf("Failed to get batch embeddings: %v", err)
			continue
		}

		dataMutex.Lock()
		for j, n := range batch {
			if j < len(embeddings) && n.idx < len(data.Notes) && data.Notes[n.idx].ID == n.id {
				data.Notes[n.idx].Embedding = embeddings[j]
			}
		}
		saveData()
		dataMutex.Unlock()

		log.Printf("Migrated batch %d-%d", i, end)
	}

	// åˆ†é…åˆ†ç±»å¹¶èšç±»
	dataMutex.Lock()
	for i := range data.Notes {
		if data.Notes[i].UserID == userID && len(data.Notes[i].Embedding) > 0 && data.Notes[i].CategoryID == 0 {
			assignNoteToCategory(&data.Notes[i])
		}
	}
	clusterUncategorizedNotes(userID)
	saveData()
	dataMutex.Unlock()

	log.Printf("Migration completed for user %d", userID)
}

// ============ æ—¶å…‰å›å»Š - å›¾ç‰‡ç”Ÿæˆ ============

// isNoteSuitableForImage åˆ¤æ–­å¿«è®°æ˜¯å¦é€‚åˆç”Ÿæˆåœºæ™¯å›¾ç‰‡
func isNoteSuitableForImage(content string) bool {
	runeContent := []rune(content)
	// è‡³å°‘30ä¸ªå­—ç¬¦ï¼Œä¸”æ˜¯æœ‰æ„ä¹‰çš„å†…å®¹
	if len(runeContent) < 30 {
		return false
	}

	// æ’é™¤çº¯å›¾ç‰‡/é“¾æ¥çš„å†…å®¹
	// ç§»é™¤æ‰€æœ‰ markdown å›¾ç‰‡è¯­æ³• ![...](...)
	imagePattern := regexp.MustCompile(`!\[.*?\]\([^)]+\)`)
	cleanContent := imagePattern.ReplaceAllString(content, "")
	// ç§»é™¤æ‰€æœ‰ URL
	urlPattern := regexp.MustCompile(`https?://[^\s]+`)
	cleanContent = urlPattern.ReplaceAllString(cleanContent, "")
	// ç§»é™¤æ‰€æœ‰ markdown é“¾æ¥ [...](...)
	linkPattern := regexp.MustCompile(`\[.*?\]\([^)]+\)`)
	cleanContent = linkPattern.ReplaceAllString(cleanContent, "")

	// æ¸…ç†åçš„å†…å®¹å¤ªçŸ­ï¼Œè¯´æ˜ä¸»è¦æ˜¯å›¾ç‰‡/é“¾æ¥
	cleanRunes := []rune(strings.TrimSpace(cleanContent))
	if len(cleanRunes) < 20 {
		return false
	}

	// åœºæ™¯ç±»å…³é”®è¯ - è¡¨ç¤ºæœ‰å…·ä½“åœºæ™¯/ç”»é¢çš„å†…å®¹
	scenePatterns := []string{
		// æ—¶é—´åœºæ™¯
		"æ—©ä¸Š", "ä¸­åˆ", "ä¸‹åˆ", "æ™šä¸Š", "æ·±å¤œ", "å‡Œæ™¨", "é»„æ˜", "æ¸…æ™¨", "å‚æ™š",
		"ä»Šå¤©", "æ˜¨å¤©", "åˆšæ‰", "æ­¤åˆ»", "è¿™ä¼šå„¿",
		// åœ°ç‚¹åœºæ™¯
		"åœ¨å®¶", "åŠå…¬å®¤", "å’–å•¡å…", "å…¬å›­", "è·¯ä¸Š", "åœ°é“", "å…¬äº¤", "æˆ¿é—´", "çª—è¾¹", "åºŠä¸Š",
		"è¡—ä¸Š", "è¶…å¸‚", "å•†åœº", "é¤å…", "å›¾ä¹¦é¦†", "å­¦æ ¡", "åŒ»é™¢",
		// å¤©æ°”/ç¯å¢ƒ
		"é˜³å…‰", "æœˆå…‰", "æ˜Ÿç©º", "é›¨", "é›ª", "é£", "äº‘", "å¤©ç©º", "æ—¥è½", "æ—¥å‡º",
		// åŠ¨ä½œ/çŠ¶æ€
		"çœ‹ç€", "æœ›ç€", "å¬ç€", "èµ°åœ¨", "ååœ¨", "èººåœ¨", "ç«™åœ¨", "ç­‰å¾…", "æ¼«æ­¥",
		"å–ç€", "åƒç€", "çœ‹ä¹¦", "å¬æ­Œ", "å‘å‘†", "æ€è€ƒ", "å›å¿†",
		// æ„Ÿå®˜æè¿°
		"çœ‹åˆ°", "å¬åˆ°", "é—»åˆ°", "æ„Ÿå—åˆ°", "è§¦æ‘¸",
		// æƒ…æ™¯æå†™
		"çªç„¶", "æ…¢æ…¢", "é™é™", "å®‰é™", "çƒ­é—¹", "å­¤ç‹¬", "æ¸©æš–", "å¯’å†·",
	}

	matchCount := 0
	for _, pattern := range scenePatterns {
		if strings.Contains(cleanContent, pattern) {
			matchCount++
		}
	}

	// è‡³å°‘åŒ¹é…2ä¸ªåœºæ™¯å…³é”®è¯ï¼Œæˆ–æ¸…ç†åå†…å®¹è¶³å¤Ÿé•¿ï¼ˆè¶…è¿‡80å­—ï¼‰
	return matchCount >= 2 || len(cleanRunes) >= 80
}

// generateImagePrompt ä½¿ç”¨ AI æ ¹æ®å¿«è®°å†…å®¹ç”Ÿæˆå›¾ç‰‡ prompt
func generateImagePrompt(content string) (string, error) {
	if dashscopeAPIKey == "" {
		return "", fmt.Errorf("DASHSCOPE_API_KEY not set")
	}

	systemPrompt := `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå™¨ã€‚ç”¨æˆ·ä¼šç»™ä½ ä¸€æ®µä¸ªäººæ—¥è®°/å¿«è®°å†…å®¹ï¼Œä½ éœ€è¦æ ¹æ®å†…å®¹ç”Ÿæˆä¸€ä¸ªé€‚åˆæ–‡ç”Ÿå›¾æ¨¡å‹çš„è‹±æ–‡æç¤ºè¯ã€‚

è¦æ±‚ï¼š
1. æ•æ‰æ–‡å­—ä¸­æè¿°çš„åœºæ™¯ã€æ°›å›´å’Œæƒ…æ„Ÿ
2. ä½¿ç”¨å…·ä½“ã€è§†è§‰åŒ–çš„æè¿°è¯
3. åŒ…å«å…‰çº¿ã€è‰²è°ƒã€æ„å›¾ç­‰å…ƒç´ 
4. é£æ ¼åå‘æ¸©æš–ã€æ²»æ„ˆã€æœ‰æ„å¢ƒçš„æ’ç”»é£æ ¼
5. æç¤ºè¯ç”¨è‹±æ–‡ï¼Œé•¿åº¦100-200è¯
6. ä¸è¦å‡ºç°ä»»ä½•æ–‡å­—/å­—æ¯åœ¨ç”»é¢ä¸­
7. å¦‚æœå†…å®¹æ˜¯æŠ½è±¡çš„æƒ…æ„Ÿï¼Œè½¬åŒ–ä¸ºå…·è±¡çš„è§†è§‰éšå–»
8. åªè¾“å‡ºæç¤ºè¯ï¼Œä¸è¦ä»»ä½•è§£é‡Š

ç¤ºä¾‹è¾“å…¥ï¼šä»Šå¤©ä¸‹ç­åä¸€ä¸ªäººåœ¨å’–å•¡å…åäº†å¾ˆä¹…ï¼Œçœ‹ç€çª—å¤–çš„é›¨å‘å‘†ï¼Œä¸çŸ¥é“åœ¨æƒ³ä»€ä¹ˆï¼Œå°±æ˜¯è§‰å¾—éœ€è¦è¿™æ ·å®‰é™ä¸€ä¼šå„¿ã€‚

ç¤ºä¾‹è¾“å‡ºï¼šA solitary figure sitting by a cafe window on a rainy evening, soft warm interior lighting contrasts with the cool blue rain outside, condensation on glass, blurred city lights through raindrops, contemplative mood, cozy atmosphere, illustration style, muted warm color palette with touches of blue, peaceful melancholy, slice of life scene, detailed background with coffee cup on table`

	reqBody := map[string]interface{}{
		"model": "qwen-plus",
		"input": map[string]interface{}{
			"messages": []map[string]string{
				{"role": "system", "content": systemPrompt},
				{"role": "user", "content": content},
			},
		},
		"parameters": map[string]interface{}{
			"max_tokens":   300,
			"temperature":  0.7,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation", bytes.NewBuffer(jsonBody))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)

	client := &http.Client{Timeout: 60 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", fmt.Errorf("API request failed: %v", err)
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(resp.Body)
	if resp.StatusCode != 200 {
		return "", fmt.Errorf("API returned %d: %s", resp.StatusCode, string(body))
	}

	var result struct {
		Output struct {
			Text    string `json:"text"`
			Choices []struct {
				Message struct {
					Content string `json:"content"`
				} `json:"message"`
			} `json:"choices"`
		} `json:"output"`
	}

	if err := json.Unmarshal(body, &result); err != nil {
		return "", fmt.Errorf("failed to parse response: %v", err)
	}

	prompt := result.Output.Text
	if prompt == "" && len(result.Output.Choices) > 0 {
		prompt = result.Output.Choices[0].Message.Content
	}

	return strings.TrimSpace(prompt), nil
}

// submitImageGenTask æäº¤å›¾ç‰‡ç”Ÿæˆä»»åŠ¡åˆ° DashScope
func submitImageGenTask(prompt string) (string, error) {
	if dashscopeAPIKey == "" {
		return "", fmt.Errorf("DASHSCOPE_API_KEY not set")
	}

	reqBody := map[string]interface{}{
		"model": "wanx-v1",
		"input": map[string]interface{}{
			"prompt": prompt,
		},
		"parameters": map[string]interface{}{
			"style": "<auto>",
			"size":  "1024*1024",
			"n":     1,
		},
	}

	jsonBody, _ := json.Marshal(reqBody)
	req, _ := http.NewRequest("POST", "https://dashscope.aliyuncs.com/api/v1/services/aigc/text2image/image-synthesis", bytes.NewBuffer(jsonBody))
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)
	req.Header.Set("X-DashScope-Async", "enable")

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", fmt.Errorf("API request failed: %v", err)
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(resp.Body)
	if resp.StatusCode != 200 {
		return "", fmt.Errorf("API returned %d: %s", resp.StatusCode, string(body))
	}

	var result struct {
		Output struct {
			TaskID     string `json:"task_id"`
			TaskStatus string `json:"task_status"`
		} `json:"output"`
	}

	if err := json.Unmarshal(body, &result); err != nil {
		return "", fmt.Errorf("failed to parse response: %v", err)
	}

	return result.Output.TaskID, nil
}

// checkImageGenTask æ£€æŸ¥å›¾ç‰‡ç”Ÿæˆä»»åŠ¡çŠ¶æ€
func checkImageGenTask(taskID string) (status string, imageURL string, err error) {
	if dashscopeAPIKey == "" {
		return "", "", fmt.Errorf("DASHSCOPE_API_KEY not set")
	}

	req, _ := http.NewRequest("GET", "https://dashscope.aliyuncs.com/api/v1/tasks/"+taskID, nil)
	req.Header.Set("Authorization", "Bearer "+dashscopeAPIKey)

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", "", fmt.Errorf("API request failed: %v", err)
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(resp.Body)
	if resp.StatusCode != 200 {
		return "", "", fmt.Errorf("API returned %d: %s", resp.StatusCode, string(body))
	}

	var result struct {
		Output struct {
			TaskStatus string `json:"task_status"`
			Results    []struct {
				URL string `json:"url"`
			} `json:"results"`
		} `json:"output"`
	}

	if err := json.Unmarshal(body, &result); err != nil {
		return "", "", fmt.Errorf("failed to parse response: %v", err)
	}

	if result.Output.TaskStatus == "SUCCEEDED" && len(result.Output.Results) > 0 {
		return "SUCCEEDED", result.Output.Results[0].URL, nil
	}

	return result.Output.TaskStatus, "", nil
}

// downloadAndSaveImage ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°
func downloadAndSaveImage(imageURL string, noteID int) (localPath string, thumbnailPath string, err error) {
	// åˆ›å»º images ç›®å½•
	imagesDir := "./images"
	thumbDir := "./images/thumbnails"
	if err := os.MkdirAll(imagesDir, 0755); err != nil {
		return "", "", fmt.Errorf("failed to create images directory: %v", err)
	}
	if err := os.MkdirAll(thumbDir, 0755); err != nil {
		return "", "", fmt.Errorf("failed to create thumbnails directory: %v", err)
	}

	// ä¸‹è½½å›¾ç‰‡
	resp, err := http.Get(imageURL)
	if err != nil {
		return "", "", fmt.Errorf("failed to download image: %v", err)
	}
	defer resp.Body.Close()

	// è¯»å–å›¾ç‰‡æ•°æ®
	imgData, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", "", fmt.Errorf("failed to read image data: %v", err)
	}

	// ç”Ÿæˆæ–‡ä»¶å
	timestamp := time.Now().Format("20060102150405")
	filename := fmt.Sprintf("note_%d_%s.png", noteID, timestamp)
	thumbFilename := fmt.Sprintf("note_%d_%s_thumb.jpg", noteID, timestamp)
	localPath = imagesDir + "/" + filename
	thumbnailPath = thumbDir + "/" + thumbFilename

	// ä¿å­˜åŸå›¾
	if err := os.WriteFile(localPath, imgData, 0644); err != nil {
		return "", "", fmt.Errorf("failed to save image: %v", err)
	}

	// ç”Ÿæˆç¼©ç•¥å›¾
	if err := generateThumbnail(imgData, thumbnailPath, 400); err != nil {
		log.Printf("Warning: failed to generate thumbnail for note %d: %v", noteID, err)
		// ç¼©ç•¥å›¾ç”Ÿæˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè¿”å›ç©ºçš„ç¼©ç•¥å›¾è·¯å¾„
		thumbnailPath = ""
	}

	return localPath, thumbnailPath, nil
}

// generateThumbnail ç”Ÿæˆç¼©ç•¥å›¾
func generateThumbnail(imgData []byte, outputPath string, maxWidth int) error {
	// è§£ç å›¾ç‰‡
	img, _, err := image.Decode(bytes.NewReader(imgData))
	if err != nil {
		return fmt.Errorf("failed to decode image: %v", err)
	}

	// è®¡ç®—ç¼©ç•¥å›¾å°ºå¯¸
	bounds := img.Bounds()
	origWidth := bounds.Dx()
	origHeight := bounds.Dy()

	if origWidth <= maxWidth {
		// å›¾ç‰‡å·²ç»è¶³å¤Ÿå°ï¼Œç›´æ¥å¤åˆ¶
		return os.WriteFile(outputPath, imgData, 0644)
	}

	// è®¡ç®—æ–°å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”
	newWidth := maxWidth
	newHeight := (origHeight * maxWidth) / origWidth

	// åˆ›å»ºç¼©ç•¥å›¾
	thumb := image.NewRGBA(image.Rect(0, 0, newWidth, newHeight))

	// ç®€å•çš„æœ€è¿‘é‚»ç¼©æ”¾ç®—æ³•
	for y := 0; y < newHeight; y++ {
		for x := 0; x < newWidth; x++ {
			srcX := x * origWidth / newWidth
			srcY := y * origHeight / newHeight
			thumb.Set(x, y, img.At(srcX, srcY))
		}
	}

	// ä¿å­˜ä¸º JPEGï¼ˆæ›´å°çš„æ–‡ä»¶å¤§å°ï¼‰
	outFile, err := os.Create(outputPath)
	if err != nil {
		return fmt.Errorf("failed to create thumbnail file: %v", err)
	}
	defer outFile.Close()

	if err := jpeg.Encode(outFile, thumb, &jpeg.Options{Quality: 75}); err != nil {
		return fmt.Errorf("failed to encode thumbnail: %v", err)
	}

	return nil
}

// processNoteImage å¤„ç†å•æ¡å¿«è®°çš„å›¾ç‰‡ç”Ÿæˆï¼ˆåŒæ­¥ç­‰å¾…ç»“æœï¼‰
func processNoteImage(noteID int, content string) (*NoteImage, error) {
	noteImage := &NoteImage{
		NoteID: noteID,
		Status: "generating",
	}

	// ç”Ÿæˆ prompt
	prompt, err := generateImagePrompt(content)
	if err != nil {
		noteImage.Status = "failed"
		noteImage.Error = "ç”Ÿæˆæç¤ºè¯å¤±è´¥: " + err.Error()
		return noteImage, err
	}
	noteImage.Prompt = prompt

	// æäº¤å›¾ç‰‡ç”Ÿæˆä»»åŠ¡
	taskID, err := submitImageGenTask(prompt)
	if err != nil {
		noteImage.Status = "failed"
		noteImage.Error = "æäº¤ä»»åŠ¡å¤±è´¥: " + err.Error()
		return noteImage, err
	}
	noteImage.TaskID = taskID

	// è½®è¯¢æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼ˆæœ€å¤šç­‰å¾…3åˆ†é’Ÿï¼‰
	maxRetries := 36
	for i := 0; i < maxRetries; i++ {
		time.Sleep(5 * time.Second)

		status, imageURL, err := checkImageGenTask(taskID)
		if err != nil {
			log.Printf("Check task %s failed: %v", taskID, err)
			continue
		}

		if status == "SUCCEEDED" {
			// ä¸‹è½½å¹¶ä¿å­˜å›¾ç‰‡ï¼ˆåŒ…æ‹¬ç¼©ç•¥å›¾ï¼‰
			localPath, thumbPath, err := downloadAndSaveImage(imageURL, noteID)
			if err != nil {
				log.Printf("Download image failed for note %d: %v", noteID, err)
				noteImage.ImageURL = imageURL // ä¿ç•™ä¸´æ—¶ URL
			} else {
				noteImage.LocalPath = localPath
				noteImage.ThumbnailPath = thumbPath
			}
			noteImage.ImageURL = imageURL
			noteImage.Status = "completed"
			noteImage.GeneratedAt = time.Now().Format("2006-01-02 15:04:05")
			return noteImage, nil
		} else if status == "FAILED" {
			noteImage.Status = "failed"
			noteImage.Error = "å›¾ç‰‡ç”Ÿæˆå¤±è´¥"
			return noteImage, fmt.Errorf("image generation failed")
		}
		// PENDING æˆ– RUNNING ç»§ç»­ç­‰å¾…
	}

	noteImage.Status = "failed"
	noteImage.Error = "ç”Ÿæˆè¶…æ—¶"
	return noteImage, fmt.Errorf("image generation timeout")
}

// getCorridorStatusHandler è·å–æ—¶å…‰å›å»Šå¤„ç†çŠ¶æ€
func getCorridorStatusHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	// ä½¿ç”¨å†™é”ï¼Œå› ä¸ºå¯èƒ½éœ€è¦ä¿å­˜è¿‡æ»¤ç»“æœ
	dataMutex.Lock()
	defer dataMutex.Unlock()

	// è·å–ç”¨æˆ·çš„å¤„ç†çŠ¶æ€
	var status *CorridorProcessStatus
	if data.CorridorStatus != nil {
		status = data.CorridorStatus[userID]
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰è¿‡æ—¶çš„å¤„ç†çŠ¶æ€ï¼ˆæœåŠ¡é‡å¯å goroutine ä¸¢å¤±ï¼‰
	corridorProcessMutex.RLock()
	isActiveProcess := activeCorridorProcess[userID]
	corridorProcessMutex.RUnlock()

	if status != nil && status.Status == "processing" && !isActiveProcess {
		// å¤„ç†çŠ¶æ€æ˜¾ç¤º processing ä½†å®é™…æ²¡æœ‰æ´»è·ƒçš„ goroutineï¼Œé‡ç½®çŠ¶æ€
		status.Status = "interrupted"
		status.Error = "å¤„ç†è¢«ä¸­æ–­ï¼ˆæœåŠ¡é‡å¯ï¼‰ï¼Œè¯·é‡æ–°å¼€å§‹"
		if data.CorridorStatus == nil {
			data.CorridorStatus = make(map[int]*CorridorProcessStatus)
		}
		data.CorridorStatus[userID] = status
		saveData()
	}

	// ç¡®ä¿ NoteImages map å­˜åœ¨
	if data.NoteImages == nil {
		data.NoteImages = make(map[int]*NoteImage)
	}

	// ç»Ÿè®¡ç”¨æˆ·å¿«è®°çš„å›¾ç‰‡ç”Ÿæˆæƒ…å†µï¼Œå¹¶åŒæ—¶è¿›è¡Œé¢„è¿‡æ»¤
	var totalNotes, withImage, generating, failed, notSuitable, suitable int
	needSave := false

	for _, note := range data.Notes {
		if note.UserID == userID {
			totalNotes++

			// æ£€æŸ¥æ˜¯å¦å·²æœ‰çŠ¶æ€è®°å½•
			if img, ok := data.NoteImages[note.ID]; ok {
				switch img.Status {
				case "completed":
					withImage++
				case "generating", "pending":
					generating++
				case "failed":
					failed++
				case "not_suitable":
					notSuitable++
				}
			} else {
				// æ²¡æœ‰çŠ¶æ€è®°å½•ï¼Œè¿›è¡Œé¢„è¿‡æ»¤å¹¶æŒä¹…åŒ–ç»“æœ
				if isNoteSuitableForImage(note.Content) {
					suitable++
				} else {
					// æ ‡è®°ä¸ºä¸é€‚åˆå¹¶ä¿å­˜
					data.NoteImages[note.ID] = &NoteImage{
						NoteID: note.ID,
						Status: "not_suitable",
					}
					notSuitable++
					needSave = true
				}
			}
		}
	}

	// å¦‚æœæœ‰æ–°çš„è¿‡æ»¤ç»“æœï¼Œä¿å­˜æ•°æ®
	if needSave {
		saveData()
	}

	response := map[string]interface{}{
		"status":       status,
		"total_notes":  totalNotes,
		"with_image":   withImage,
		"generating":   generating,
		"failed":       failed,
		"not_suitable": notSuitable,
		"suitable":     suitable,                              // é€‚åˆç”Ÿæˆä½†æœªå¤„ç†çš„æ•°é‡
		"pending":      suitable + generating + failed,        // çœŸæ­£å¾…å¤„ç†çš„ = é€‚åˆçš„ + æ­£åœ¨å¤„ç†çš„ + å¤±è´¥çš„ï¼ˆå¯é‡è¯•ï¼‰
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(response)
}

// startCorridorProcessHandler å¯åŠ¨æ—¶å…‰å›å»Šæ‰¹é‡å¤„ç†
func startCorridorProcessHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	dataMutex.Lock()

	// æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤„ç†ä»»åŠ¡åœ¨è¿è¡Œ
	if data.CorridorStatus == nil {
		data.CorridorStatus = make(map[int]*CorridorProcessStatus)
	}
	if status, ok := data.CorridorStatus[userID]; ok && status.Status == "processing" {
		dataMutex.Unlock()
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success": false,
			"message": "å·²æœ‰å¤„ç†ä»»åŠ¡åœ¨è¿è¡Œä¸­",
		})
		return
	}

	// åˆå§‹åŒ– NoteImages map
	if data.NoteImages == nil {
		data.NoteImages = make(map[int]*NoteImage)
	}

	// æ”¶é›†éœ€è¦å¤„ç†çš„å¿«è®°
	var notesToProcess []Note
	for _, note := range data.Notes {
		if note.UserID == userID {
			// è·³è¿‡å·²å¤„ç†çš„
			if img, ok := data.NoteImages[note.ID]; ok {
				if img.Status == "completed" || img.Status == "not_suitable" {
					continue
				}
			}
			// æ£€æŸ¥æ˜¯å¦é€‚åˆç”Ÿæˆå›¾ç‰‡
			if isNoteSuitableForImage(note.Content) {
				notesToProcess = append(notesToProcess, note)
			} else {
				// æ ‡è®°ä¸ºä¸é€‚åˆ
				data.NoteImages[note.ID] = &NoteImage{
					NoteID: note.ID,
					Status: "not_suitable",
				}
			}
		}
	}

	if len(notesToProcess) == 0 {
		dataMutex.Unlock()
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success": true,
			"message": "æ²¡æœ‰éœ€è¦å¤„ç†çš„å¿«è®°",
		})
		return
	}

	// åˆå§‹åŒ–å¤„ç†çŠ¶æ€
	status := &CorridorProcessStatus{
		Status:         "processing",
		TotalNotes:     len(notesToProcess),
		ProcessedNotes: 0,
		StartedAt:      time.Now().Format("2006-01-02 15:04:05"),
	}
	data.CorridorStatus[userID] = status
	saveData()

	dataMutex.Unlock()

	// æ ‡è®°æ´»è·ƒå¤„ç†
	corridorProcessMutex.Lock()
	activeCorridorProcess[userID] = true
	corridorProcessMutex.Unlock()

	// å¼‚æ­¥å¤„ç†
	go func() {
		defer func() {
			// å¤„ç†å®Œæˆåç§»é™¤æ´»è·ƒæ ‡è®°å’Œæš‚åœæ ‡è®°
			corridorProcessMutex.Lock()
			delete(activeCorridorProcess, userID)
			delete(pausedCorridorProcess, userID)
			corridorProcessMutex.Unlock()
		}()

		for _, note := range notesToProcess {
			// æ£€æŸ¥æ˜¯å¦æš‚åœ
			corridorProcessMutex.RLock()
			isPaused := pausedCorridorProcess[userID]
			corridorProcessMutex.RUnlock()

			if isPaused {
				// æš‚åœçŠ¶æ€ï¼Œç­‰å¾…æ¢å¤
				dataMutex.Lock()
				if status := data.CorridorStatus[userID]; status != nil {
					status.Status = "paused"
					saveData()
				}
				dataMutex.Unlock()

				// ç­‰å¾…æ¢å¤æˆ–é€€å‡º
				for {
					time.Sleep(500 * time.Millisecond)
					corridorProcessMutex.RLock()
					stillPaused := pausedCorridorProcess[userID]
					stillActive := activeCorridorProcess[userID]
					corridorProcessMutex.RUnlock()

					if !stillActive {
						// ä»»åŠ¡è¢«å–æ¶ˆ
						log.Printf("Corridor processing cancelled for user %d", userID)
						return
					}
					if !stillPaused {
						// æ¢å¤å¤„ç†
						dataMutex.Lock()
						if status := data.CorridorStatus[userID]; status != nil {
							status.Status = "processing"
							saveData()
						}
						dataMutex.Unlock()
						break
					}
				}
			}

			log.Printf("Processing image for note %d", note.ID)

			noteImage, err := processNoteImage(note.ID, note.Content)
			if err != nil {
				log.Printf("Failed to process note %d: %v", note.ID, err)
			}

			dataMutex.Lock()
			data.NoteImages[note.ID] = noteImage
			status := data.CorridorStatus[userID]
			status.ProcessedNotes++
			status.LastProcessedAt = time.Now().Format("2006-01-02 15:04:05")

			if noteImage.Status == "completed" {
				status.SuccessCount++
			} else if noteImage.Status == "failed" {
				status.FailedCount++
			}

			saveData()
			dataMutex.Unlock()

			// ç¨å¾®é—´éš”ä¸€ä¸‹ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
			time.Sleep(2 * time.Second)
		}

		// å¤„ç†å®Œæˆ
		dataMutex.Lock()
		status := data.CorridorStatus[userID]
		status.Status = "completed"
		status.LastProcessedAt = time.Now().Format("2006-01-02 15:04:05")
		saveData()
		dataMutex.Unlock()

		log.Printf("Corridor processing completed for user %d", userID)
	}()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"success":     true,
		"message":     "å¼€å§‹å¤„ç†",
		"total_notes": len(notesToProcess),
	})
}

// pauseCorridorProcessHandler æš‚åœ/æ¢å¤æ—¶å…‰å›å»Šå¤„ç†
func pauseCorridorProcessHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	var req struct {
		Action string `json:"action"` // "pause" or "resume"
	}
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request body", http.StatusBadRequest)
		return
	}

	corridorProcessMutex.Lock()
	isActive := activeCorridorProcess[userID]

	if !isActive {
		corridorProcessMutex.Unlock()
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success": false,
			"message": "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„å¤„ç†ä»»åŠ¡",
		})
		return
	}

	if req.Action == "pause" {
		pausedCorridorProcess[userID] = true
		corridorProcessMutex.Unlock()
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success": true,
			"message": "å¤„ç†å·²æš‚åœ",
		})
	} else if req.Action == "resume" {
		delete(pausedCorridorProcess, userID)
		corridorProcessMutex.Unlock()
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"success": true,
			"message": "å¤„ç†å·²æ¢å¤",
		})
	} else {
		corridorProcessMutex.Unlock()
		http.Error(w, "Invalid action, use 'pause' or 'resume'", http.StatusBadRequest)
	}
}

// getNoteImageHandler è·å–å•æ¡å¿«è®°çš„å›¾ç‰‡
func getNoteImageHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	// ä» URL è·å– note_id
	noteIDStr := r.URL.Query().Get("note_id")
	noteID, err := strconv.Atoi(noteIDStr)
	if err != nil {
		http.Error(w, "Invalid note_id", http.StatusBadRequest)
		return
	}

	dataMutex.RLock()
	defer dataMutex.RUnlock()

	// éªŒè¯å¿«è®°å±äºå½“å‰ç”¨æˆ·
	var noteFound bool
	for _, note := range data.Notes {
		if note.ID == noteID && note.UserID == userID {
			noteFound = true
			break
		}
	}

	if !noteFound {
		http.Error(w, "Note not found", http.StatusNotFound)
		return
	}

	var noteImage *NoteImage
	if data.NoteImages != nil {
		noteImage = data.NoteImages[noteID]
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(noteImage)
}

// getAllImagesHandler æ‰¹é‡è·å–ç”¨æˆ·æ‰€æœ‰å¿«è®°çš„å›¾ç‰‡ä¿¡æ¯
func getAllImagesHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "GET" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	dataMutex.RLock()
	defer dataMutex.RUnlock()

	// æ”¶é›†ç”¨æˆ·æ‰€æœ‰å¿«è®°çš„å›¾ç‰‡ä¿¡æ¯
	type NoteWithImage struct {
		NoteID    int        `json:"note_id"`
		Content   string     `json:"content"`
		CreatedAt string     `json:"created_at"`
		Image     *NoteImage `json:"image"`
	}

	var results []NoteWithImage
	for _, note := range data.Notes {
		if note.UserID == userID {
			var img *NoteImage
			if data.NoteImages != nil {
				img = data.NoteImages[note.ID]
			}
			// åªè¿”å›æœ‰å›¾ç‰‡ä¿¡æ¯çš„ï¼ˆä¸åŒ…æ‹¬æœªå¤„ç†çš„ï¼‰
			if img != nil && img.Status != "not_suitable" {
				results = append(results, NoteWithImage{
					NoteID:    note.ID,
					Content:   note.Content,
					CreatedAt: note.CreatedAt,
					Image:     img,
				})
			}
		}
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"images": results,
		"count":  len(results),
	})
}

// generateNoteImageHandler ä¸ºå•æ¡å¿«è®°ç”Ÿæˆå›¾ç‰‡
func generateNoteImageHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != "POST" {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	authHeader := r.Header.Get("Authorization")
	tokenString := strings.TrimPrefix(authHeader, "Bearer ")
	userID, _, err := validateToken(tokenString)
	if err != nil {
		http.Error(w, "Invalid token", http.StatusUnauthorized)
		return
	}

	var req struct {
		NoteID int `json:"note_id"`
	}
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request", http.StatusBadRequest)
		return
	}

	dataMutex.RLock()

	// æŸ¥æ‰¾å¿«è®°
	var targetNote *Note
	for i := range data.Notes {
		if data.Notes[i].ID == req.NoteID && data.Notes[i].UserID == userID {
			targetNote = &data.Notes[i]
			break
		}
	}

	if targetNote == nil {
		dataMutex.RUnlock()
		http.Error(w, "Note not found", http.StatusNotFound)
		return
	}

	content := targetNote.Content
	dataMutex.RUnlock()

	// å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡
	go func() {
		noteImage, err := processNoteImage(req.NoteID, content)
		if err != nil {
			log.Printf("Failed to generate image for note %d: %v", req.NoteID, err)
		}

		dataMutex.Lock()
		if data.NoteImages == nil {
			data.NoteImages = make(map[int]*NoteImage)
		}
		data.NoteImages[req.NoteID] = noteImage
		saveData()
		dataMutex.Unlock()
	}()

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(map[string]interface{}{
		"success": true,
		"message": "å›¾ç‰‡ç”Ÿæˆå·²å¼€å§‹",
	})
}

// serveNoteImageHandler æä¾›æœ¬åœ°å›¾ç‰‡è®¿é—®
func serveNoteImageHandler(w http.ResponseWriter, r *http.Request) {
	// ä»è·¯å¾„ä¸­æå–æ–‡ä»¶å
	path := strings.TrimPrefix(r.URL.Path, "/api/corridor/images/")
	if path == "" {
		http.Error(w, "Invalid path", http.StatusBadRequest)
		return
	}

	// å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†
	if strings.Contains(path, "..") {
		http.Error(w, "Invalid path", http.StatusBadRequest)
		return
	}

	filepath := "./images/" + path
	http.ServeFile(w, r, filepath)
}

// serveNoteThumbnailHandler æä¾›ç¼©ç•¥å›¾æœåŠ¡
func serveNoteThumbnailHandler(w http.ResponseWriter, r *http.Request) {
	// ä»è·¯å¾„ä¸­æå–æ–‡ä»¶å
	path := strings.TrimPrefix(r.URL.Path, "/api/corridor/thumbnails/")
	if path == "" {
		http.Error(w, "Invalid path", http.StatusBadRequest)
		return
	}

	// å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†
	if strings.Contains(path, "..") {
		http.Error(w, "Invalid path", http.StatusBadRequest)
		return
	}

	filepath := "./images/thumbnails/" + path

	// è®¾ç½®ç¼“å­˜å¤´
	w.Header().Set("Cache-Control", "public, max-age=31536000")
	http.ServeFile(w, r, filepath)
}

// ============ Main ============

func main() {
	// å‘½ä»¤è¡Œå‚æ•°
	reclusterFlag := flag.Bool("recluster", false, "Trigger recluster for user 2 on startup")
	userIDFlag := flag.Int("user", 2, "User ID for recluster")
	skipNameGenFlag := flag.Bool("skip-names", false, "Skip AI name generation (use default names)")
	flag.Parse()

	skipNameGen = *skipNameGenFlag

	loadData()

	// å¦‚æœæŒ‡å®šäº† recluster æ ‡å¿—ï¼Œæ‰§è¡Œé‡èšç±»
	if *reclusterFlag {
		log.Printf("Recluster flag set, triggering recluster for user %d...", *userIDFlag)
		dataMutex.Lock()

		// é‡ç½®åˆ†ç±»
		var newCategories []Category
		for _, cat := range data.Categories {
			if cat.UserID != *userIDFlag {
				newCategories = append(newCategories, cat)
			}
		}
		data.Categories = newCategories

		// é‡ç½®ç¬”è®°çš„åˆ†ç±»
		for i := range data.Notes {
			if data.Notes[i].UserID == *userIDFlag {
				data.Notes[i].CategoryID = 0
			}
		}

		// é‡æ–°èšç±»
		clusterUncategorizedNotes(*userIDFlag)

		saveData()
		dataMutex.Unlock()

		log.Printf("Recluster completed, exiting...")
		return
	}

	// API routes
	http.HandleFunc("/api/register", enableCORS(registerHandler))
	http.HandleFunc("/api/login", enableCORS(loginHandler))
	http.HandleFunc("/api/notes", enableCORS(func(w http.ResponseWriter, r *http.Request) {
		switch r.Method {
		case "GET":
			getNotesHandler(w, r)
		case "POST":
			createNoteHandler(w, r)
		case "OPTIONS":
			w.WriteHeader(http.StatusOK)
		default:
			http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		}
	}))
	http.HandleFunc("/api/notes/import", enableCORS(importNotesHandler))
	http.HandleFunc("/api/notes/starlight", enableCORS(starlightHandler))
	http.HandleFunc("/api/notes/migrate-embeddings", enableCORS(migrateEmbeddingsHandler))
	http.HandleFunc("/api/notes/cat-response", enableCORS(getCatResponseHandler))
	http.HandleFunc("/api/notes/", enableCORS(deleteNoteHandler))

	// åˆ†ç±»ç›¸å…³ API
	http.HandleFunc("/api/categories", enableCORS(getCategoriesHandler))
	http.HandleFunc("/api/categories/recluster", enableCORS(reclusterHandler))
	http.HandleFunc("/api/categories/regenerate-names", enableCORS(regenerateNamesHandler))

	// ä¸»é¢˜ç›¸å…³ API
	http.HandleFunc("/api/themes", enableCORS(func(w http.ResponseWriter, r *http.Request) {
		if r.Method == "GET" {
			getThemesHandler(w, r)
		} else if r.Method == "POST" {
			createThemeHandler(w, r)
		} else {
			http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		}
	}))
	http.HandleFunc("/api/themes/", enableCORS(func(w http.ResponseWriter, r *http.Request) {
		if r.Method == "PUT" {
			updateThemeHandler(w, r)
		} else if r.Method == "DELETE" {
			deleteThemeHandler(w, r)
		} else {
			http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		}
	}))
	http.HandleFunc("/api/notes/move-to-theme", enableCORS(moveNoteToThemeHandler))

	// æ´è§ API
	http.HandleFunc("/api/insights", enableCORS(getInsightsHandler))

	// æˆ‘çš„ä¼ å¥‡ API
	http.HandleFunc("/api/biography", enableCORS(getBiographyHandler))
	http.HandleFunc("/api/biography/generate", enableCORS(generateBiographyHandler))

	// æ—¶å…‰å›å»Š API
	http.HandleFunc("/api/corridor/status", enableCORS(getCorridorStatusHandler))
	http.HandleFunc("/api/corridor/start", enableCORS(startCorridorProcessHandler))
	http.HandleFunc("/api/corridor/pause", enableCORS(pauseCorridorProcessHandler))
	http.HandleFunc("/api/corridor/image", enableCORS(getNoteImageHandler))
	http.HandleFunc("/api/corridor/all-images", enableCORS(getAllImagesHandler))
	http.HandleFunc("/api/corridor/generate", enableCORS(generateNoteImageHandler))
	http.HandleFunc("/api/corridor/images/", enableCORS(serveNoteImageHandler))
	http.HandleFunc("/api/corridor/thumbnails/", enableCORS(serveNoteThumbnailHandler))

	// Serve static files
	fs := http.FileServer(http.Dir("../frontend"))
	http.Handle("/", fs)

	port := os.Getenv("PORT")
	if port == "" {
		port = "8080"
	}

	log.Printf("Jotmo server starting on port %s...", port)
	if dashscopeAPIKey != "" {
		log.Printf("DashScope API configured (embedding + text generation)")
	} else {
		log.Printf("Warning: DASHSCOPE_API_KEY not set, auto-categorization disabled")
	}
	log.Printf("Access the app at http://0.0.0.0:%s", port)
	log.Fatal(http.ListenAndServe("0.0.0.0:"+port, nil))
}
